{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"create_manual_labelling_dataset.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LTzKxHFblypQ"},"source":["To access the dataset of new manual human labels we generated as part of our study, please see the csv files in the *new_manual_labels* subfolder of the *4_reformulated_datasets* folder. The following notebook is what was used to generate a random subset of the data for manual labelling (400 scenario pairs from the hard test dataset and 400 scenario pairs from the easy test datasets)."]},{"cell_type":"markdown","metadata":{"id":"7isJEE2ITunt"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"4PoQCy47SovN"},"source":["import numpy as np\n","import os\n","import pandas as pd\n","from sklearn.utils import shuffle"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCCposG3TrCY"},"source":["### For Google Colab only\n","\n","Set path to root folder after change directory command"]},{"cell_type":"code","metadata":{"id":"x76ILXMnUIJ0"},"source":["# # mount google drive\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# # change to directory containing relevant files\n","# %cd 'INSERT_DIRECTORY/2_manual_labelling_preparation'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"whOrcNQRTyYr"},"source":["### Generate manual labelling dataset\n","\n","The original dataset csv files easy.csv (easy test dataset) and hard.csv (hard test dataset) consist of two columns, with each row a different scenario pair. The first column contains the lower utility sentence, and the second column contains the higher utility scenario (according to the original study labels).\n","\n","This code will shuffle the order of the scenario pairs, and shuffle the order of the scenarios within each pair, and then output two csv files.  The first will contain a copy of the shuffled dataset with the study labels included (the reference copy). The second will contain the shuffled dataset but not contain the study labels, so that it can then be used to setup a task for labellers."]},{"cell_type":"code","metadata":{"id":"tNJ0ul47WRnf"},"source":["DATASET = \"util_test\"  # specify \"util_test\" for easy test set, or \"util_test_hard\" for hard test dataset\n","\n","# load dataframe (csv file with col1: bad_sentence, col2: good_sentence)\n","df = pd.read_csv(f\"../1_original_study_datasets/{DATASET}.csv\", header=None, index_col=None)\n","\n","# shuffle all rows of dataframe\n","df = shuffle(df)\n","\n","# loop through rows in dataframe to randomly swap order of sentences\n","# append shuffled rows to a new dataframe: randomised_df\n","randomised_df = pd.DataFrame([])\n","for index, row in enumerate(df.iterrows()):\n","    # to randomise order or sentences in sentence pair\n","    order = np.random.choice([1,2])\n","\n","    if order == 1: # sentence1 is bad, sentence2 is good\n","        temp_dict = {\"original_index\": index,\n","                    \"sentence1\": row[0],\n","                    \"sentence2\": row[1],\n","                    \"study_label\": 5} # 5 = sentence2 is good\n","\n","    elif order == 2: # sentence1 is good, sentence2 is bad\n","        temp_dict = {\"original_index\": index,\n","                    \"sentence1\": row[1],\n","                    \"sentence2\": row[0],\n","                    \"study_label\": 1} # 1 = sentence 1 is good\n","\n","    randomised_df = randomised_df.append(temp_dict, ignore_index=True)\n","\n","# save randomised_df as csv file with study_labels included\n","randomised_df.to_csv(f\"labelled/{DATASET}_LABELLED_randomised.csv\")\n","\n","# save separate csv files for labellers, with study_labels removed\n","randomised_df = randomised_df.drop(columns=\"study_label\")\n","randomised_df.to_csv(f\"{name}/{DATASET}_{name}_randomised.csv\")"],"execution_count":null,"outputs":[]}]}