{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bayesian_transformers.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNILIIzYUrtNhL7DSrjfJzD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"81f1759b6c974e0aa255fcb78062bc0d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_01fdfd256c7f4912b17985a05e647dac","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aef8ef151f404531931360eabaf46dc8","IPY_MODEL_1395e865e3804d2b823dd284591cd336"]}},"01fdfd256c7f4912b17985a05e647dac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aef8ef151f404531931360eabaf46dc8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b44389d47e164aec942b0c65756130c1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_72a967bd33304e9483d8ee75d45ac8f7"}},"1395e865e3804d2b823dd284591cd336":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5f1da6608c9141baa752ed6af7eac084","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:27&lt;00:00, 20.5B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2cbe7f4d441d48f6bcf87103ec5472a2"}},"b44389d47e164aec942b0c65756130c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"72a967bd33304e9483d8ee75d45ac8f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f1da6608c9141baa752ed6af7eac084":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2cbe7f4d441d48f6bcf87103ec5472a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0eeb633a4014ed583c41f297673aefb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b7803d8aab7d45e49a63f7355cac7296","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_30f3ae42913f41e1ae7cb7506a5f7c6f","IPY_MODEL_a7eb31c82d7b45d2bad54d5f8386067e"]}},"b7803d8aab7d45e49a63f7355cac7296":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30f3ae42913f41e1ae7cb7506a5f7c6f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_951b8e20b9df4f13a41eba7be14ab529","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_36860f2af11742f1a4e6ad7b0ce93f1c"}},"a7eb31c82d7b45d2bad54d5f8386067e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0caec16381f74071bc4b002ce9763685","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:27&lt;00:00, 16.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9338d776f7054113b7d02ece8819162a"}},"951b8e20b9df4f13a41eba7be14ab529":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"36860f2af11742f1a4e6ad7b0ce93f1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0caec16381f74071bc4b002ce9763685":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9338d776f7054113b7d02ece8819162a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31dff63a8e264e1da67ffdcb4235e747":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8250e3e1d60f49ea8be92887a187a406","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_740e86d4824b43429398198a0f5347d3","IPY_MODEL_ecd556b49f4b4f9c8b56552a9168114c"]}},"8250e3e1d60f49ea8be92887a187a406":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"740e86d4824b43429398198a0f5347d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3905a60d9a354a5dbcd7ff91aa5878fd","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3f53a27f9e9d414eb188c3c601c7016c"}},"ecd556b49f4b4f9c8b56552a9168114c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c9c59a891c9d400eae295c17cb1b3d03","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:02&lt;00:00, 92.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a3b3e86f294b48e8948b9bfdd2bd727a"}},"3905a60d9a354a5dbcd7ff91aa5878fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3f53a27f9e9d414eb188c3c601c7016c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c9c59a891c9d400eae295c17cb1b3d03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a3b3e86f294b48e8948b9bfdd2bd727a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cf581b28d3d7475fbc3c05272b0bbdba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_84b3c80c03b54b89b7bb60a5e5b59a78","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_21b1019a1cc945e2a8886c824a6b20a8","IPY_MODEL_b9e07be2087b4752b6e54383644e1cb4"]}},"84b3c80c03b54b89b7bb60a5e5b59a78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21b1019a1cc945e2a8886c824a6b20a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_123fe26a46cc46429572414df13706a0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_628bcdde588e40c2b27f9769136f4c1d"}},"b9e07be2087b4752b6e54383644e1cb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a4a91dc550df4dc392e0931f0bfa8982","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:01&lt;00:00, 291kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e26acbc3b4b40c8aa46fbb54f81331b"}},"123fe26a46cc46429572414df13706a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"628bcdde588e40c2b27f9769136f4c1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4a91dc550df4dc392e0931f0bfa8982":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1e26acbc3b4b40c8aa46fbb54f81331b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c119f97ecf7466db3c78a3e2051695c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1f54c4092d424979b9d2f05cf9d41798","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6b79fffbe22046afb82d51db1d31b309","IPY_MODEL_ce397021879f44ccb468676bc256935d"]}},"1f54c4092d424979b9d2f05cf9d41798":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b79fffbe22046afb82d51db1d31b309":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4dd20cf2669244bf83519b9088f79e6d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_03e2717cd34d481f88d6e12927aed973"}},"ce397021879f44ccb468676bc256935d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_75087c8e6f9f48e4a3b479435ca28058","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 269B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_212fedd8c8d140fcaa1591f36f52b81e"}},"4dd20cf2669244bf83519b9088f79e6d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"03e2717cd34d481f88d6e12927aed973":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75087c8e6f9f48e4a3b479435ca28058":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"212fedd8c8d140fcaa1591f36f52b81e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d657b88c9823466bb8fb324d26eae32b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a230eefa2c154e1d802fe657134854b1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5ef60822c6ea4f2c8ec5e281cd33b1b1","IPY_MODEL_0b6bd8c115bf46afa48634f3034758cb"]}},"a230eefa2c154e1d802fe657134854b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ef60822c6ea4f2c8ec5e281cd33b1b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cd9e0f56beb8456caf12a5d6e9ea14a4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_72b0b02ccc364f28979d028ca0c58906"}},"0b6bd8c115bf46afa48634f3034758cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aef7ae20cd454b6b8a1a5a4441ec8967","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:09&lt;00:00, 59.0B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_272dc95bf98f4f95a5a8731595f97f63"}},"cd9e0f56beb8456caf12a5d6e9ea14a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"72b0b02ccc364f28979d028ca0c58906":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aef7ae20cd454b6b8a1a5a4441ec8967":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"272dc95bf98f4f95a5a8731595f97f63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a56b5b0fba64430b4dc7d4d2816d86d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_636965626e94478ab84bb563ee59f060","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c159d23c638e492ebcfd1c258f5de9bc","IPY_MODEL_815b0a7a5c49470793a05b6b148fe5a4"]}},"636965626e94478ab84bb563ee59f060":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c159d23c638e492ebcfd1c258f5de9bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_015057ac05464e40b9758aef3af21301","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4ac347182dc41fd8329d3872281bd6f"}},"815b0a7a5c49470793a05b6b148fe5a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b869ccbbc263480eb5fdf4ece8c2962f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:09&lt;00:00, 47.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2333f53c95cd4c3fa578c43c328ae3ce"}},"015057ac05464e40b9758aef3af21301":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e4ac347182dc41fd8329d3872281bd6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b869ccbbc263480eb5fdf4ece8c2962f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2333f53c95cd4c3fa578c43c328ae3ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5fa514e8865e4a58b8d309fd3f6e5f18":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c8741f9b806346ecb962af0b891f7117","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_91a9b7111f694119b5787c49fffacbf0","IPY_MODEL_8d1eeee2c21c4dc1b311476f11c41f5b"]}},"c8741f9b806346ecb962af0b891f7117":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91a9b7111f694119b5787c49fffacbf0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6f635b7112e9404eac781938d7d04c00","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4f7fe2633e05444298ce5793ac2767b0"}},"8d1eeee2c21c4dc1b311476f11c41f5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d1cafeb85c664e62b96a05de99e2faac","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 265kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_678f9192273d41a99019d61527e8d829"}},"6f635b7112e9404eac781938d7d04c00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4f7fe2633e05444298ce5793ac2767b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1cafeb85c664e62b96a05de99e2faac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"678f9192273d41a99019d61527e8d829":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44f2599de2c0490398553134d0f423ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ea8f54bf41ec4d49ae618907b8c819b9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a981cdcfc98a4f3689d47fb481eecdd6","IPY_MODEL_6b1aa89372e04377b54954af61ac033b"]}},"ea8f54bf41ec4d49ae618907b8c819b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a981cdcfc98a4f3689d47fb481eecdd6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_76597aa7bf7843e0945f56aa55158abe","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ed2bce559e7b492f9ff3a9b5fe22bb6d"}},"6b1aa89372e04377b54954af61ac033b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c63ce0fa04c14b9ca0b61dc71ad37a69","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:01&lt;00:00, 346kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_58f03e932df946ddb46c3fa474c2b00a"}},"76597aa7bf7843e0945f56aa55158abe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ed2bce559e7b492f9ff3a9b5fe22bb6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c63ce0fa04c14b9ca0b61dc71ad37a69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"58f03e932df946ddb46c3fa474c2b00a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17eda0384bdc4864bf5b2605f2a4b0ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_216dc91efa28485da2e2a6e647bdf30a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4d0c82c27d37431a84a99f28f92a77dc","IPY_MODEL_62e967906b784979bd1a0f2d8fed897d"]}},"216dc91efa28485da2e2a6e647bdf30a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4d0c82c27d37431a84a99f28f92a77dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_488d6672d6264b6d87fc997cb3f5e558","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_16aac18f400e4dcc936db780247a398b"}},"62e967906b784979bd1a0f2d8fed897d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_66bf974d12d048e5b328c41a784c5ace","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 235B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8531029814ef47cb863eba11458033b3"}},"488d6672d6264b6d87fc997cb3f5e558":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"16aac18f400e4dcc936db780247a398b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"66bf974d12d048e5b328c41a784c5ace":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8531029814ef47cb863eba11458033b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c70307208b84d698e5449b26148bb3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2a01d857e6d2486281fddca2e8ad3332","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e6e2924d3ced4085aba4baba689fb92f","IPY_MODEL_8dd8c2e71c2345ceac1458610e24b733"]}},"2a01d857e6d2486281fddca2e8ad3332":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6e2924d3ced4085aba4baba689fb92f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2f4ac25249f3489bbfe187a381b362c2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b5d3bd3f0b34b288f812f5542c0fc31"}},"8dd8c2e71c2345ceac1458610e24b733":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f538a352482f4b9ca1ec83ee7784d1cb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:02&lt;00:00, 423kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_45978ca965b24d4eb4269dc79cafae60"}},"2f4ac25249f3489bbfe187a381b362c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1b5d3bd3f0b34b288f812f5542c0fc31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f538a352482f4b9ca1ec83ee7784d1cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"45978ca965b24d4eb4269dc79cafae60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ff54f76d9304ff8be97fdc02d7b9085":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_48a18969428a4bf4ace98ac74c8212b6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8c6236bb7ffc4c10ab9816b7cd73c930","IPY_MODEL_cb129899590748c886a1048c6c1f9dda"]}},"48a18969428a4bf4ace98ac74c8212b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c6236bb7ffc4c10ab9816b7cd73c930":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b75ffe06cd3e43e7adccbab4c2612747","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a0af3c9a812f4217a4c8a390e939536c"}},"cb129899590748c886a1048c6c1f9dda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1e9aad32a5cc43e3acaf8126dce0bdd2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:01&lt;00:00, 438kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d98cbf5b1d0143b2a0a7fbed51deba66"}},"b75ffe06cd3e43e7adccbab4c2612747":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a0af3c9a812f4217a4c8a390e939536c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e9aad32a5cc43e3acaf8126dce0bdd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d98cbf5b1d0143b2a0a7fbed51deba66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c9346e864234645bb228ac76f0323ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_36e5f15541734779921dbe9d6cf6c43b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a509e5fe14a54e8186cf40c204c71c5d","IPY_MODEL_aeb565b1693443ed8bb2f406ef4819dc"]}},"36e5f15541734779921dbe9d6cf6c43b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a509e5fe14a54e8186cf40c204c71c5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9955919c10e14351be8b0532ed03246f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_346b25bf9f504db5a5d4988ef8e07935"}},"aeb565b1693443ed8bb2f406ef4819dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_970e90c2871d4b348ee1af1bcfb649d5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:01&lt;00:00, 769kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0fd247f2d8e44add8c234a75f11664d3"}},"9955919c10e14351be8b0532ed03246f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"346b25bf9f504db5a5d4988ef8e07935":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"970e90c2871d4b348ee1af1bcfb649d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0fd247f2d8e44add8c234a75f11664d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"A6vb_h_Mz26T"},"source":["# Doing Bayesian Deep Learning on Transformers"]},{"cell_type":"markdown","metadata":{"id":"HLY7D--Ee017"},"source":["In this notebook we describe the process that we took to train our models using Vadam [Emtiyaz Khan et. al, 2018](https://arxiv.org/pdf/1806.04854.pdf) and SGLD [Welling, Teh, 2011](https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf)"]},{"cell_type":"markdown","metadata":{"id":"qj1TpaoC0AFd"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"XbbETv7e0I85"},"source":["####For Colab only"]},{"cell_type":"markdown","metadata":{"id":"nxWS2YkbAIZh"},"source":["Set path root folder after change directory command"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhLKI85aDvcE","executionInfo":{"status":"ok","timestamp":1621450468861,"user_tz":-60,"elapsed":20934,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"e658d8da-356e-490a-cd52-6958fac583ad"},"source":["# # mount google drive\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","# # change to directory containing relevant files\n","#%cd INSERT DIRECTORY"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tWnwVaGefH1X"},"source":["#@title Run to check we're in the correct directory\n","\n","#try:\n","  #  f = open(\"check_directory.txt\")\n","  #  print('Success :)')\n","#except IOError:\n","  #  print(\"Wrong directory, please try again\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g4by-4SV0Nkd"},"source":["!pip install transformers\n","!pip install barbar"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5nGJu14jFPpO"},"source":["Importing Generic Libraries"]},{"cell_type":"code","metadata":{"id":"kcp_xeYiEr95"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","from barbar import Bar\n","from torch.optim.optimizer import Optimizer\n","from torch.nn.utils import parameters_to_vector, vector_to_parameters\n","import math\n","import pickle\n","import copy\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, AdamW\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IFKLTpGcFUAf"},"source":["Functions needed to load and preprocess data. Source:[https://github.com/hendrycks/ethics](https://github.com/hendrycks/ethics)"]},{"cell_type":"code","metadata":{"id":"2DcgIi9nE5m9"},"source":["def load_model(args, load_path=None, cache_dir=None):\n","    if cache_dir is not None:\n","        config = AutoConfig.from_pretrained(args.model, num_labels=1, cache_dir=cache_dir)\n","    else:\n","        config = AutoConfig.from_pretrained(args.model, num_labels=1)\n","    model = AutoModelForSequenceClassification.from_pretrained(args.model, config=config)\n","    if load_path is not None:\n","        model.load_state_dict(torch.load(load_path), strict=False)\n","\n","    model.cuda()\n","    model = torch.nn.DataParallel(model, device_ids=[i for i in range(args.ngpus)])\n","\n","    print('\\nPretrained model \"{}\" loaded'.format(args.model))\n","    no_decay = ['bias', 'LayerNorm.weight']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.named_parameters()\n","                    if not any(nd in n for nd in no_decay)],\n","         'weight_decay': args.weight_decay},\n","        {'params': [p for n, p in model.named_parameters()\n","                    if any(nd in n for nd in no_decay)],\n","         'weight_decay': 0.0}\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=1e-8)\n","\n","    return model, optimizer\n","\n","def load_process_data(args, data_dir, dataset, name=\"train\"):\n","    load_fn = load_util_sentences\n","    sentences, labels = load_fn(data_dir, name=name)\n","    sentences = [\"[CLS] \" + s for s in sentences]\n","    tokenizer = get_tokenizer(args.model)\n","    ids, amasks = get_ids_mask(sentences, tokenizer, args.max_length)\n","    within_bounds = [ids[i, -1] == 0 for i in range(len(ids))]\n","    if np.mean(within_bounds) < 1:\n","        print(\"{} fraction of examples within context window ({} tokens): {:.3f}\".format(name, args.max_length, np.mean(within_bounds)))\n","    inputs, labels, masks = torch.tensor(ids), torch.tensor(labels), torch.tensor(amasks)\n","\n","    even_mask = [i for i in range(inputs.shape[0]) if i % 2 == 0]\n","    odd_mask = [i for i in range(inputs.shape[0]) if i % 2 == 1]\n","    even_inputs, odd_inputs = inputs[even_mask], inputs[odd_mask]\n","    even_labels, odd_labels = labels[even_mask], labels[odd_mask]\n","    even_masks, odd_masks = masks[even_mask], masks[odd_mask]\n","    inputs = torch.stack([even_inputs, odd_inputs], axis=1)\n","    labels = torch.stack([even_labels, odd_labels], axis=1)\n","    masks = torch.stack([even_masks, odd_masks], axis=1)\n","\n","    data = TensorDataset(inputs, masks, labels)\n","    return data\n","\n","def load_util_sentences(data_dir, name=\"train\"):\n","    path = os.path.join(data_dir, \"{}.csv\".format(name))\n","    df = pd.read_csv(path, header=None)\n","    sentences = []\n","    for i in range(df.shape[0]):\n","        sentences.append(df.iloc[i, 0])\n","        sentences.append(df.iloc[i, 1])\n","    labels = [-1 for _ in range(len(sentences))]\n","    return sentences, labels\n","\n","def get_tokenizer(model):\n","    tokenizer = AutoTokenizer.from_pretrained(model)\n","    return tokenizer\n","\n","def get_ids_mask(sentences, tokenizer, max_length):\n","    tokenized = [tokenizer.tokenize(s) for s in sentences]\n","    tokenized = [t[:(max_length - 1)] + ['SEP'] for t in tokenized]\n","\n","    ids = [tokenizer.convert_tokens_to_ids(t) for t in tokenized]\n","    ids = np.array([np.pad(i, (0, max_length - len(i)),\n","                           mode='constant') for i in ids])\n","\n","    amasks = []\n","    for seq in ids:\n","        seq_mask = [float(i > 0) for i in seq]\n","        amasks.append(seq_mask)\n","    return ids, amasks\n","  \n","def flatten(tensor):\n","    tensor = torch.cat([tensor[:, 0], tensor[:, 1]])\n","    return tensor\n","\n","def unflatten(tensor):\n","    tensor = torch.stack([tensor[:tensor.shape[0] // 2], tensor[tensor.shape[0] // 2:]], axis=1)\n","    return tensor\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nnFxe4dYFoWT"},"source":["The Optimizers that we use. Sources:\n","\n"," Vadam: [https://github.com/emtiyaz/vadam](https://github.com/emtiyaz/vadam)\n","\n"," SGLD: [https://github.com/noahgolmant/SGLD/blob/master/sgld/optimizers.py](https://github.com/noahgolmant/SGLD/blob/master/sgld/optimizers.py) "]},{"cell_type":"code","metadata":{"id":"haxFKV74FSrb"},"source":["#@title\n","class Vadam(Optimizer):\n","    \"\"\"Implements Vadam algorithm.\n","    Arguments:\n","        params (iterable): iterable of parameters to optimize or dicts defining\n","            parameter groups\n","        train_set_size (int): number of data points in the full training set \n","            (objective assumed to be on the form (1/M)*sum(-log p))\n","        lr (float, optional): learning rate (default: 1e-3)\n","        beta (Tuple[float, float], optional): coefficients used for computing\n","            running averages of gradient and its square (default: (0.9, 0.999))\n","        prior_prec (float, optional): prior precision on parameters\n","            (default: 1.0)\n","        prec_init (float, optional): initial precision for variational dist. q\n","            (default: 1.0)\n","        num_samples (float, optional): number of MC samples\n","            (default: 1)\n","    \"\"\"\n","\n","    def __init__(self, params, train_set_size, lr=1e-3, betas=(0.9, 0.999), prior_prec=1.0, prec_init=1.0, num_samples=1):\n","        if not 0.0 <= lr:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if not 0.0 <= prior_prec:\n","            raise ValueError(\"Invalid prior precision value: {}\".format(prior_prec))\n","        if not 0.0 <= prec_init:\n","            raise ValueError(\"Invalid initial s value: {}\".format(prec_init))\n","        if not 0.0 <= betas[0] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n","        if not 0.0 <= betas[1] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n","        if num_samples < 1:\n","            raise ValueError(\"Invalid num_samples parameter: {}\".format(num_samples))\n","        if train_set_size < 1:\n","            raise ValueError(\"Invalid number of training data points: {}\".format(train_set_size))\n","            \n","        self.num_samples = num_samples\n","        self.train_set_size = train_set_size\n","\n","        defaults = dict(lr=lr, betas=betas, prior_prec=prior_prec, prec_init=prec_init)\n","        super(Vadam, self).__init__(params, defaults)\n","\n","    def step(self, closure):\n","        \"\"\"Performs a single optimization step.\n","        Arguments:\n","            closure (callable): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        if closure is None:\n","            raise RuntimeError('For now, Vadam only supports that the model/loss can be reevaluated inside the step function')\n","            \n","        grads = []\n","        grads2 = []\n","        for group in self.param_groups:\n","                for p in group['params']:\n","                    grads.append([])\n","                    grads2.append([])\n","        \n","        # Compute grads and grads2 using num_samples MC samples\n","        for s in range(self.num_samples):\n","            \n","            # Sample noise for each parameter\n","            pid = 0\n","            original_values = {}\n","            for group in self.param_groups:\n","                for p in group['params']:\n","    \n","                    original_values.setdefault(pid, p.detach().clone())\n","                    state = self.state[p]\n","                    # State initialization\n","                    if len(state) == 0:\n","                        state['step'] = 0\n","                        # Exponential moving average of gradient values\n","                        state['exp_avg'] = torch.zeros_like(p.data)\n","                        # Exponential moving average of squared gradient values\n","                        state['exp_avg_sq'] = torch.ones_like(p.data) * (group['prec_init'] - group['prior_prec']) / self.train_set_size\n","    \n","                    # A noisy sample\n","                    raw_noise = torch.normal(mean=torch.zeros_like(p.data), std=1.0)\n","                    p.data.addcdiv_(1., raw_noise, torch.sqrt(self.train_set_size * state['exp_avg_sq'] + group['prior_prec']))\n","                    \n","                    pid = pid + 1\n","    \n","            # Call the loss function and do BP to compute gradient\n","            loss = closure()\n","            \n","            # Replace original values and store gradients\n","            pid = 0\n","            for group in self.param_groups:\n","                for p in group['params']:\n","                    \n","                    # Restore original parameters\n","                    p.data = original_values[pid]\n","    \n","                    if p.grad is None:\n","                        continue\n","                        \n","                    if p.grad.is_sparse:\n","                        raise RuntimeError('Vadam does not support sparse gradients')\n","                    \n","                    # Aggregate gradients\n","                    g = p.grad.detach().clone()\n","                    if s==0:\n","                        grads[pid] = g\n","                        grads2[pid] = g**2\n","                    else:\n","                        grads[pid] += g\n","                        grads2[pid] += g**2\n","                        \n","                    pid = pid + 1\n","        \n","        # Update parameters and states\n","        pid = 0\n","        for group in self.param_groups:\n","            for p in group['params']:\n","\n","                if grads[pid] is None:\n","                    continue\n","                \n","                # Compute MC estimate of g and g2\n","                grad = grads[pid].div(self.num_samples)\n","                grad2 = grads2[pid].div(self.num_samples)\n","                \n","                tlambda = group['prior_prec'] / self.train_set_size\n","\n","                state = self.state[p]\n","\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","\n","                beta1, beta2 = group['betas']\n","\n","                state['step'] += 1\n","\n","                # Decay the first and second moment running average coefficient\n","                exp_avg.mul_(beta1).add_(1 - beta1, grad + tlambda * original_values[pid])\n","                exp_avg_sq.mul_(beta2).add_(1 - beta2, grad2)\n","\n","                bias_correction1 = 1 - beta1 ** state['step']\n","                bias_correction2 = 1 - beta2 ** state['step']\n","\n","                numerator = exp_avg.div(bias_correction1)\n","                denominator = exp_avg_sq.div(bias_correction2).sqrt().add(tlambda)\n","                \n","                # Update parameters\n","                p.data.addcdiv_(-group['lr'], numerator, denominator)\n","                \n","                pid = pid + 1\n","\n","        return loss\n","\n","    def get_weight_precs(self, ret_numpy=False):\n","        \"\"\"Returns the posterior weight precisions.\n","        Arguments:\n","            ret_numpy (bool): If true, the returned list contains numpy arrays,\n","                otherwise it contains torch tensors.\n","        \"\"\"\n","        weight_precs = []\n","        for group in self.param_groups:\n","            weight_prec = []\n","            for p in group['params']:\n","                state = self.state[p]\n","                prec = self.train_set_size * state['exp_avg_sq'] + group['prior_prec']\n","                if ret_numpy:\n","                    prec = prec.cpu().numpy()\n","                weight_prec.append(prec)\n","            weight_precs.append(weight_prec)\n","\n","        return weight_precs\n","  #Change in the mc prediction function to adapt it to our inputs\n","    def get_mc_predictions(self, forward_function, inputs_ids, inputs_masks, mc_samples=1, ret_numpy=False, *args, **kwargs):\n","        \"\"\"Returns Monte Carlo predictions.\n","        Arguments:\n","            forward_function (callable): The forward function of the model\n","                that takes inputs and returns the outputs.\n","            inputs (FloatTensor): The inputs to the model.\n","            mc_samples (int): The number of Monte Carlo samples.\n","            ret_numpy (bool): If true, the returned list contains numpy arrays,\n","                otherwise it contains torch tensors.\n","        \"\"\"\n","\n","        predictions = []\n","\n","        for mc_num in range(mc_samples):\n","\n","            pid = 0\n","            original_values = {}\n","            for group in self.param_groups:\n","                for p in group['params']:\n","                    \n","                    original_values.setdefault(pid, torch.zeros_like(p.data)+p.data)\n","\n","                    state = self.state[p]\n","                    # State initialization\n","                    if len(state) == 0:\n","                        raise RuntimeError('Optimizer not initialized')\n","\n","                    # A noisy sample\n","                    raw_noise = torch.normal(mean=torch.zeros_like(p.data), std=1.0)\n","                    p.data.addcdiv_(1., raw_noise, torch.sqrt(self.train_set_size * state['exp_avg_sq'] + group['prior_prec']))\n","\n","                    pid = pid + 1\n","\n","            # Call the forward computation function\n","            outputs = forward_function(inputs_ids, inputs_masks, *args, **kwargs)\n","            if ret_numpy:\n","                outputs = outputs.data.cpu().numpy()\n","            predictions.append(outputs)\n","\n","            pid = 0\n","            for group in self.param_groups:\n","                for p in group['params']:\n","                    p.data = original_values[pid]\n","                    pid = pid + 1\n","\n","        return predictions\n","\n","    def _kl_gaussian(self, p_mu, p_sigma, q_mu, q_sigma):\n","        var_ratio = (p_sigma / q_sigma).pow(2)\n","        t1 = ((p_mu - q_mu) / q_sigma).pow(2)\n","        return 0.5 * torch.sum((var_ratio + t1 - 1 - var_ratio.log()))\n","\n","    def kl_divergence(self):\n","        \"\"\"Returns the KL divergence between the variational distribution \n","        and the prior.\n","        \"\"\"\n","        kl = 0\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                state = self.state[p]\n","                prec0 = group['prior_prec']\n","                prec = self.train_set_size * state['exp_avg_sq'] + group['prior_prec']\n","                kl += self._kl_gaussian(p_mu = p, \n","                                        p_sigma = 1. / torch.sqrt(prec), \n","                                        q_mu = 0., \n","                                        q_sigma = 1. / math.sqrt(prec0))\n","\n","        return kl\n","\n","#Taken from https://github.com/noahgolmant/SGLD/blob/master/sgld/optimizers.py\n","class SGLD(Optimizer):\n","    r\"\"\"Implements stochastic gradient descent (optionally with momentum).\n","    Nesterov momentum is based on the formula from\n","    `On the importance of initialization and momentum in deep learning`__.\n","    Args:\n","        params (iterable): iterable of parameters to optimize or dicts defining\n","            parameter groups\n","        lr (float): learning rate\n","        momentum (float, optional): momentum factor (default: 0)\n","        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n","        dampening (float, optional): dampening for momentum (default: 0)\n","        nesterov (bool, optional): enables Nesterov momentum (default: False)\n","        noise_scale (float, optional): variance of isotropic noise for langevin\n","    Example:\n","        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n","        >>> optimizer.zero_grad()\n","        >>> loss_fn(model(input), target).backward()\n","        >>> optimizer.step()\n","    __ http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf\n","    .. note::\n","        The implementation of SGD with Momentum/Nesterov subtly differs from\n","        Sutskever et. al. and implementations in some other frameworks.\n","        Considering the specific case of Momentum, the update can be written as\n","        .. math::\n","                  v = \\rho * v + g \\\\\n","                  p = p - lr * v\n","        where p, g, v and :math:`\\rho` denote the parameters, gradient,\n","        velocity, and momentum respectively.\n","        This is in contrast to Sutskever et. al. and\n","        other frameworks which employ an update of the form\n","        .. math::\n","             v = \\rho * v + lr * g \\\\\n","             p = p - v\n","        The Nesterov version is analogously modified.\n","    \"\"\"\n","\n","    def __init__(self, params, lr, momentum=0, dampening=0,\n","                 weight_decay=0, nesterov=False,\n","                 noise_scale=0.1):\n","        if lr < 0.0:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if momentum < 0.0:\n","            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n","        if weight_decay < 0.0:\n","            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n","\n","        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n","                        weight_decay=weight_decay, nesterov=nesterov)\n","        if nesterov and (momentum <= 0 or dampening != 0):\n","            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n","        super(SGLD, self).__init__(params, defaults)\n","        self.noise_scale = noise_scale\n","\n","    def __setstate__(self, state):\n","        super(SGLD, self).__setstate__(state)\n","        for group in self.param_groups:\n","            group.setdefault('nesterov', False)\n","\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        returns norm of the step we took for variance analysis later\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            weight_decay = group['weight_decay']\n","            momentum = group['momentum']\n","            dampening = group['dampening']\n","            nesterov = group['nesterov']\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                d_p = p.grad.data\n","\n","                if weight_decay != 0:\n","                    d_p.add_(weight_decay, p.data)\n","                if momentum != 0:\n","                    param_state = self.state[p]\n","                    if 'momentum_buffer' not in param_state:\n","                        buf = param_state['momentum_buffer'] = torch.zeros_like(p.data)\n","                        buf.mul_(momentum).add_(d_p)\n","                    else:\n","                        buf = param_state['momentum_buffer']\n","                        buf.mul_(momentum).add_(1 - dampening, d_p)\n","                    if nesterov:\n","                        d_p = d_p.add(momentum, buf)\n","                    else:\n","                        d_p = buf\n","\n","                p.data.add_(-group['lr'], d_p)\n","                p.data.add_(np.sqrt(self.noise_scale), torch.randn_like(p.data))\n","        return loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zryzl5EXF_88"},"source":["Functions to train the models. Source of train: [https://github.com/hendrycks/ethics](https://github.com/hendrycks/ethics). Train_variational is an adaptation of train to handle Vadam"]},{"cell_type":"code","metadata":{"id":"xj0F2D8ZF-2H"},"source":["def train(model, optimizer, train_dataloader, epoch, *args, track_validation_loss = False, log_interval = 50, verbose=False):\n","    # Set model to training mode\n","    model.train()\n","    criterion = torch.nn.BCEWithLogitsLoss()\n","    ntrain_steps = len(train_dataloader)\n","\n","    results_validation = []\n","\n","    # Loop over each batch from the training set\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Copy data to GPU if needed\n","        batch = tuple(t.cuda() for t in batch)\n","\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # reshape\n","        b_input_ids = flatten(b_input_ids)\n","        b_input_mask = flatten(b_input_mask)\n","\n","        # Zero gradient buffers\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        output = model(b_input_ids, attention_mask=b_input_mask)[0]  # dim 1\n","        output = unflatten(output)\n","        diffs = output[:, 0] - output[:, 1]\n","        loss = criterion(diffs.squeeze(dim=1), torch.ones(diffs.shape[0]).cuda())\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Update weights\n","        optimizer.step()\n","\n","        if step % log_interval == 0 and step > 0 and verbose:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, step, ntrain_steps, 100. * step / ntrain_steps, loss))\n","        \n","        if step % log_interval == 0 and track_validation_loss:\n","          results_validation.append(evaluate(model, validation_dataloader))\n","\n","    if track_validation_loss:\n","      return results_validation\n","\n","def train_variational(model, optimizer, train_dataloader, epoch, track_validation_loss = False, log_interval = 10, verbose=False, *args):\n","    # Set model to training mode\n","    model.train()\n","    criterion = torch.nn.BCEWithLogitsLoss()\n","    ntrain_steps = len(train_dataloader)\n","\n","    results_validation = []\n","\n","    # Loop over each batch from the training set\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Copy data to GPU if needed\n","        batch = tuple(t.cuda() for t in batch)\n","\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # reshape\n","        b_input_ids = flatten(b_input_ids)\n","        b_input_mask = flatten(b_input_mask)\n","\n","        def closure():\n","          optimizer.zero_grad()\n","          output = model(b_input_ids, attention_mask=b_input_mask)[0]  # dim 1\n","          output = unflatten(output)\n","          diffs = output[:, 0] - output[:, 1]\n","          loss = criterion(diffs.squeeze(dim=1), torch.ones(diffs.shape[0]).cuda())\n","          loss.backward()\n","          return loss\n","\n","        loss = optimizer.step(closure)\n","\n","        if step % log_interval == 0 and step > 0 and verbose:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, step, ntrain_steps, 100. * step / ntrain_steps, loss))\n","            \n","        if step % log_interval == 0 and track_validation_loss:\n","          results_validation.append(evaluate(model, validation_dataloader))\n","\n","    if track_validation_loss:\n","      return results_validation"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C99qwCXoHRoV"},"source":["Functions to evaluate the models ant their uncertainties. Source of evaluate: [https://github.com/hendrycks/ethics](https://github.com/hendrycks/ethics). variational_inference_uncertainties_roberta is an adaptation of evaluate to do predict from samples of a posterior distribution and do certainty estimation"]},{"cell_type":"code","metadata":{"id":"92k3EokzF9uL"},"source":["def evaluate(model, dataloader):\n","    model.eval()\n","    cors = []\n","\n","    for step, batch in enumerate(dataloader):\n","        # Copy data to GPU if needed\n","        batch = tuple(t.cuda() for t in batch)\n","\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # reshape\n","        b_input_ids = flatten(b_input_ids)\n","        b_input_mask = flatten(b_input_mask)\n","\n","        # Forward pass\n","        with torch.no_grad():\n","            output = model(b_input_ids, attention_mask=b_input_mask)[0]  # dim 1\n","            output = unflatten(output)\n","            diffs = output[:, 0] - output[:, 1]\n","            diffs = diffs.squeeze(dim=1).detach().cpu().numpy()\n","        cors.append(diffs > 0)\n","\n","    cors = np.concatenate(cors)\n","    acc = np.mean(cors)\n","\n","    print('Acc {:.3f}'.format(acc))\n","    return acc\n","\n","\n","def variational_inference_uncertainties_roberta(model, std_weights, std_bias, dataloader, mc_samples = 2):\n","\n","    model_sampled = copy.deepcopy(model)\n","    model_sampled.eval()\n","\n","    vi_pred = {}\n","    \n","    for i in range(mc_samples):\n","      #print(i)\n","      cors = []\n","      model_sampled.module.classifier.out_proj.weight = copy.deepcopy(torch.nn.Parameter(torch.normal(model.module.classifier.out_proj.weight, std_weights)))\n","      model_sampled.module.classifier.out_proj.bias = copy.deepcopy(torch.nn.Parameter(torch.normal(model.module.classifier.out_proj.bias, std_bias)))\n","      model_sampled.eval()\n","\n","      for step, batch in enumerate(dataloader):\n","        # Copy data to GPU if needed\n","        batch = tuple(t.cuda() for t in batch)\n","\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # reshape\n","        b_input_ids = flatten(b_input_ids)\n","        b_input_mask = flatten(b_input_mask)\n","\n","        # Forward pass\n","        with torch.no_grad():\n","            output = model_sampled(b_input_ids, attention_mask=b_input_mask)[0]  # dim 1\n","            output = unflatten(output)\n","            diffs = output[:, 0] - output[:, 1]\n","            diffs = diffs.squeeze(dim=1).detach().cpu().numpy()\n","        cors.append(diffs > 0)\n","\n","      cors = np.concatenate(cors)\n","      vi_pred[i] = cors\n","\n","    final_predictions = np.zeros((mc_samples, vi_pred[0].shape[0]))\n","    for i in range(mc_samples):\n","      final_predictions[i] = vi_pred[i]\n","\n","    #Calculate the means and variances\n","    mean = np.mean(final_predictions, axis = 0)\n","    variance = np.var(final_predictions, axis = 0)\n","\n","    # Finding the variance for the instances that were correctly and wrongly classified\n","    correct_variance = variance[mean>=0.5]\n","    wrong_variance = variance[mean<0.5]\n","\n","    # Get binary predictions\n","    predictions = np.copy(mean)\n","    predictions[mean>0.5] = 1\n","    predictions[mean<0.5] = 0\n","    #We do it unifromly at random when the uncertainty because otherwise we would artificiaslly be counting all those cases as successes\n","    for j in range(predictions.shape[0]):\n","      if predictions[j] == 0.5:\n","        predictions[j] = np.round(np.random.rand())\n","\n","    # Calculate the confidence in each prediction  \n","    confidence = np.copy(mean)\n","    confidence[mean<0.5] = 1 - confidence[mean<0.5] # For the instances where we're classifying as 0, the confidence is the opposite\n","\n","    results = {'predictions': predictions,\n","          'confidence': confidence,\n","          'mean': mean,\n","          'variance': variance,\n","          'avg_correct_variance': np.mean(correct_variance),\n","          'avg_wrong_variance': np.mean(wrong_variance)}\n","\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qxlT9wYv8Fr4"},"source":["Functions needed to plot the cerrtainty calibration and compute the expected callibration error (ECE) [Guo et. al, 2017](https://arxiv.org/pdf/1706.04599.pdf) of each model"]},{"cell_type":"code","metadata":{"id":"zKiqob8V8eru"},"source":["def split_in_bins(predictions, confidence):\n","    num_bins = 5\n","    l = np.linspace(0.5,1,num_bins+1)\n","    bins = np.linspace(0.5,.9,num_bins)+.05\n","\n","    conf = []\n","    acc = []\n","    num_in_bins = []\n","\n","    for ind, (lower,upper) in enumerate(zip(l[:-1], l[1:])):\n","        indxs = np.where((confidence<=upper) & (confidence>lower)) # B_m\n","\n","        this_bin_pred = predictions[indxs]\n","        this_bin_conf = confidence[indxs]\n","\n","        # Get average confidence\n","        avg_conf = np.mean(this_bin_conf)\n","\n","        # Get average accuracy\n","        avg_acc = np.mean(this_bin_pred)\n","        conf.append(avg_conf)\n","        acc.append(avg_acc)\n","        num_in_bins.append(len(this_bin_pred))\n","    \n","    return conf, acc, bins, num_in_bins\n","\n","def get_ECE(confidence, accuracy, num_in_bins):\n","  '''\n","  condifence: list of conf(B_m)\n","  accuracy: list of acc(B_m)\n","\n","  num_in_bins: number of samples in each bin\n","  '''\n","  assert len(confidence) == len(accuracy)\n","\n","  num_in_bins = np.asarray(num_in_bins)\n","  n = num_in_bins.sum() # Tot number of samples\n","  ECE = 0\n","  for i in range(len(confidence)):\n","    ECE += (num_in_bins[i]/(n)) * np.abs(accuracy[i] - confidence[i])\n","\n","  return ECE\n","\n","def plot_reliability_diagram_rerelease(accuracy_easy, bins_easy, accuracy_hard, bins_hard,accuracy_unmatched, bins_unmatched, figure_file): #accuracy_unmatched, bins_unmatched, figure_file):\n","    accuracy = (accuracy_easy, accuracy_hard, accuracy_unmatched)\n","    bins = (bins_easy, bins_hard, bins_unmatched)\n","    width=0.1\n","    fig, ax = plt.subplots(figsize=(13,5), nrows=1, ncols=3)\n","    fig.suptitle(\"Assessing calibration of model certainty against accuracy\\n(Vadam-optimised RoBERTa-large)\", fontsize=14, fontweight='bold')\n","    for i in range(3):\n","        ax[i].bar(bins[i], accuracy[i], width=width, color='k', edgecolor='black')\n","        ax[i].plot(np.linspace(0.5,1,6),np.linspace(0.5,1,6),linestyle='--', color='red')\n","        ax[i].set_ylabel(\"Accuracy\")\n","        ax[i].set_xlabel(\"Model certainty\")\n","        if i==0:\n","            ax[i].set_title(\"Easy reformulated test dataset\")\n","        if i==1:\n","            ax[i].set_title(\"Hard reformulated test dataset\")\n","        if i == 2:\n","            ax[i].set_title(\"Unmatched reformulated test dataset\")\n","    fig.tight_layout(rect=[0, 0, 1, 0.90])\n","    fig.legend(['Perfect certainty','Model certainty'],loc=(0.75,0.15), facecolor=\"white\")\n","    fig.savefig(figure_file, dpi=250)\n","    fig.show()\n","\n","def plot_reliability_diagram_original(accuracy_easy, bins_easy, accuracy_hard, bins_hard, figure_file): #accuracy_unmatched, bins_unmatched, figure_file):\n","    accuracy = (accuracy_easy, accuracy_hard)\n","    bins = (bins_easy, bins_hard)\n","    width=0.1\n","    fig, ax = plt.subplots(figsize=(8,5), nrows=1, ncols=2)\n","    #Change the suptitle with each model accordingly\n","    fig.suptitle(\"Assessing calibration of model certainty against accuracy\\n(Vadam-optimised RoBERTa-large)\", fontsize=14, fontweight='bold')\n","    for i in range(2):\n","        ax[i].bar(bins[i], accuracy[i], width=width, color='k', edgecolor='black')\n","        ax[i].plot(np.linspace(0.5,1,6),np.linspace(0.5,1,6),linestyle='--', color='red')\n","        ax[i].set_ylabel(\"Accuracy\")\n","        ax[i].set_xlabel(\"Model certainty\")\n","        if i==0:\n","            ax[i].set_title(\"Easy test dataset\")\n","        if i==1:\n","            ax[i].set_title(\"Hard test dataset\")\n","    fig.tight_layout(rect=[0, 0, 1, 0.90])\n","    fig.legend(['Perfect certainty','Model certainty'],loc=(0.75,0.15), facecolor=\"white\")\n","    fig.savefig(figure_file, dpi=250)\n","    fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8SJfDYODH7s8"},"source":["A class needed to specify the model and the training parameters we use (lr, epochs...)"]},{"cell_type":"code","metadata":{"id":"w1jjAcOXH4iw"},"source":["class MyArgs:\n","  def __init__(self, model = None, ngpus = 1, save = True, verbose = True, weight_decay=0.01, learning_rate=2e-5, nepochs=2, batch_size=16, max_length=64,\n","               nruns=1):\n","    self.model = model\n","    self.ngpus = ngpus\n","    self.weight_decay = weight_decay\n","    self.learning_rate = learning_rate\n","    self.nepochs = nepochs\n","    self.batch_size = batch_size\n","    self.max_length = max_length\n","    self.nruns = nruns\n","    self.save = save\n","    self.verbose = verbose"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Imdv-7Gx1jnY"},"source":["# SGLD Experiments"]},{"cell_type":"markdown","metadata":{"id":"E0lrJfWXKSEN"},"source":["We start by fine-tuning a BERT-base model using AdamW. Once we have converged to a local optima, we start using SGLD, in order to try to draw samples from the posterior distribution"]},{"cell_type":"code","metadata":{"id":"etxN3sEYIJkX"},"source":["args = MyArgs()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iyY_CC9iLdd0"},"source":["data_dir = '1_original_study_datasets'\n","train_name = \"util_train\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["81f1759b6c974e0aa255fcb78062bc0d","01fdfd256c7f4912b17985a05e647dac","aef8ef151f404531931360eabaf46dc8","1395e865e3804d2b823dd284591cd336","b44389d47e164aec942b0c65756130c1","72a967bd33304e9483d8ee75d45ac8f7","5f1da6608c9141baa752ed6af7eac084","2cbe7f4d441d48f6bcf87103ec5472a2","f0eeb633a4014ed583c41f297673aefb","b7803d8aab7d45e49a63f7355cac7296","30f3ae42913f41e1ae7cb7506a5f7c6f","a7eb31c82d7b45d2bad54d5f8386067e","951b8e20b9df4f13a41eba7be14ab529","36860f2af11742f1a4e6ad7b0ce93f1c","0caec16381f74071bc4b002ce9763685","9338d776f7054113b7d02ece8819162a","31dff63a8e264e1da67ffdcb4235e747","8250e3e1d60f49ea8be92887a187a406","740e86d4824b43429398198a0f5347d3","ecd556b49f4b4f9c8b56552a9168114c","3905a60d9a354a5dbcd7ff91aa5878fd","3f53a27f9e9d414eb188c3c601c7016c","c9c59a891c9d400eae295c17cb1b3d03","a3b3e86f294b48e8948b9bfdd2bd727a","cf581b28d3d7475fbc3c05272b0bbdba","84b3c80c03b54b89b7bb60a5e5b59a78","21b1019a1cc945e2a8886c824a6b20a8","b9e07be2087b4752b6e54383644e1cb4","123fe26a46cc46429572414df13706a0","628bcdde588e40c2b27f9769136f4c1d","a4a91dc550df4dc392e0931f0bfa8982","1e26acbc3b4b40c8aa46fbb54f81331b","3c119f97ecf7466db3c78a3e2051695c","1f54c4092d424979b9d2f05cf9d41798","6b79fffbe22046afb82d51db1d31b309","ce397021879f44ccb468676bc256935d","4dd20cf2669244bf83519b9088f79e6d","03e2717cd34d481f88d6e12927aed973","75087c8e6f9f48e4a3b479435ca28058","212fedd8c8d140fcaa1591f36f52b81e"]},"id":"FEFTxEjd2oJV","executionInfo":{"status":"ok","timestamp":1621454018705,"user_tz":-60,"elapsed":3519157,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"467f9bad-bc13-4a79-cfca-ab066793424c"},"source":["#We now prepare the plots for the accuracy with the SGLD optimizer\n","\n","gaussian_noise = [1e-4, 1e-5, 1e-6, 1e-8]\n","accuracy_graphs = {}\n","for noise in gaussian_noise:\n","  #First we train the model using adamw\n","\n","  args.model = \"bert-base-uncased\"\n","  args.learning_rate = 1e-5\n","  args.batch_size = 8\n","  args.nepochs = 2\n","  model, optimizer = load_model(args)\n","  train_data = load_process_data(args, data_dir, \"util\", train_name)\n","  train_set, validation_set = torch.utils.data.random_split(train_data, [int(0.8*len(train_data)), \\\n","                                      len(train_data) - int(0.8*len(train_data))], generator=torch.Generator().manual_seed(42))\n","\n","  train_dataloader = DataLoader(train_set, batch_size=args.batch_size // 2, shuffle=True)\n","  validation_dataloader = DataLoader(validation_set, batch_size=args.batch_size // 2, shuffle = False)\n","\n","  for epoch in range(1, args.nepochs + 1):\n","    train(model, optimizer, train_dataloader, epoch,  verbose=False)\n","\n","  accuracy_graphs[noise] = [evaluate(model, validation_dataloader)]\n","  no_decay = ['bias', 'LayerNorm.weight']\n","  optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters()\n","                if not any(nd in n for nd in no_decay)],\n","      'weight_decay': args.weight_decay},\n","    {'params': [p for n, p in model.named_parameters()\n","                if any(nd in n for nd in no_decay)],\n","      'weight_decay': 0.0}\n","  ]\n","\n","  optimizer_sgld = SGLD(optimizer_grouped_parameters,\n","  lr = args.learning_rate,\n","  noise_scale = noise)\n","\n","  #We only train for one epoch\n","  accuracy_graphs[noise] += train(model, optimizer_sgld, train_dataloader,  epoch, validation_dataloader, track_validation_loss=True, verbose=False)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81f1759b6c974e0aa255fcb78062bc0d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0eeb633a4014ed583c41f297673aefb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31dff63a8e264e1da67ffdcb4235e747","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf581b28d3d7475fbc3c05272b0bbdba","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c119f97ecf7466db3c78a3e2051695c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","train fraction of examples within context window (64 tokens): 1.000\n","Acc 0.868\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n"],"name":"stderr"},{"output_type":"stream","text":["Acc 0.799\n","Acc 0.505\n","Acc 0.496\n","Acc 0.489\n","Acc 0.499\n","Acc 0.500\n","Acc 0.495\n","Acc 0.487\n","Acc 0.508\n","Acc 0.497\n","Acc 0.485\n","Acc 0.502\n","Acc 0.510\n","Acc 0.496\n","Acc 0.506\n","Acc 0.497\n","Acc 0.483\n","Acc 0.500\n","Acc 0.503\n","Acc 0.487\n","Acc 0.485\n","Acc 0.505\n","Acc 0.507\n","Acc 0.529\n","Acc 0.504\n","Acc 0.509\n","Acc 0.494\n","Acc 0.520\n","Acc 0.517\n","Acc 0.493\n","Acc 0.500\n","Acc 0.508\n","Acc 0.489\n","Acc 0.511\n","Acc 0.497\n","Acc 0.482\n","Acc 0.482\n","Acc 0.499\n","Acc 0.512\n","Acc 0.504\n","Acc 0.493\n","Acc 0.504\n","Acc 0.484\n","Acc 0.502\n","Acc 0.505\n","Acc 0.507\n","Acc 0.495\n","Acc 0.504\n","Acc 0.500\n","Acc 0.505\n","Acc 0.502\n","Acc 0.503\n","Acc 0.527\n","Acc 0.491\n","Acc 0.513\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n","train fraction of examples within context window (64 tokens): 1.000\n","Acc 0.876\n","Acc 0.874\n","Acc 0.556\n","Acc 0.512\n","Acc 0.480\n","Acc 0.492\n","Acc 0.499\n","Acc 0.505\n","Acc 0.509\n","Acc 0.496\n","Acc 0.517\n","Acc 0.496\n","Acc 0.507\n","Acc 0.495\n","Acc 0.484\n","Acc 0.510\n","Acc 0.512\n","Acc 0.515\n","Acc 0.505\n","Acc 0.501\n","Acc 0.492\n","Acc 0.502\n","Acc 0.504\n","Acc 0.501\n","Acc 0.510\n","Acc 0.503\n","Acc 0.504\n","Acc 0.505\n","Acc 0.514\n","Acc 0.484\n","Acc 0.507\n","Acc 0.503\n","Acc 0.493\n","Acc 0.495\n","Acc 0.518\n","Acc 0.500\n","Acc 0.508\n","Acc 0.485\n","Acc 0.509\n","Acc 0.499\n","Acc 0.491\n","Acc 0.513\n","Acc 0.485\n","Acc 0.504\n","Acc 0.521\n","Acc 0.503\n","Acc 0.506\n","Acc 0.504\n","Acc 0.500\n","Acc 0.491\n","Acc 0.480\n","Acc 0.499\n","Acc 0.488\n","Acc 0.500\n","Acc 0.505\n","Acc 0.492\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n","train fraction of examples within context window (64 tokens): 1.000\n","Acc 0.878\n","Acc 0.880\n","Acc 0.877\n","Acc 0.858\n","Acc 0.838\n","Acc 0.806\n","Acc 0.728\n","Acc 0.686\n","Acc 0.640\n","Acc 0.580\n","Acc 0.591\n","Acc 0.548\n","Acc 0.508\n","Acc 0.491\n","Acc 0.504\n","Acc 0.477\n","Acc 0.515\n","Acc 0.508\n","Acc 0.512\n","Acc 0.490\n","Acc 0.535\n","Acc 0.503\n","Acc 0.501\n","Acc 0.498\n","Acc 0.516\n","Acc 0.500\n","Acc 0.509\n","Acc 0.480\n","Acc 0.507\n","Acc 0.500\n","Acc 0.497\n","Acc 0.505\n","Acc 0.511\n","Acc 0.483\n","Acc 0.490\n","Acc 0.509\n","Acc 0.508\n","Acc 0.500\n","Acc 0.488\n","Acc 0.505\n","Acc 0.487\n","Acc 0.504\n","Acc 0.503\n","Acc 0.482\n","Acc 0.483\n","Acc 0.495\n","Acc 0.492\n","Acc 0.499\n","Acc 0.497\n","Acc 0.496\n","Acc 0.489\n","Acc 0.499\n","Acc 0.505\n","Acc 0.501\n","Acc 0.495\n","Acc 0.495\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n","train fraction of examples within context window (64 tokens): 1.000\n","Acc 0.892\n","Acc 0.892\n","Acc 0.892\n","Acc 0.892\n","Acc 0.893\n","Acc 0.892\n","Acc 0.891\n","Acc 0.890\n","Acc 0.892\n","Acc 0.893\n","Acc 0.895\n","Acc 0.893\n","Acc 0.896\n","Acc 0.894\n","Acc 0.896\n","Acc 0.896\n","Acc 0.896\n","Acc 0.898\n","Acc 0.897\n","Acc 0.897\n","Acc 0.896\n","Acc 0.897\n","Acc 0.897\n","Acc 0.897\n","Acc 0.898\n","Acc 0.898\n","Acc 0.899\n","Acc 0.898\n","Acc 0.899\n","Acc 0.899\n","Acc 0.898\n","Acc 0.897\n","Acc 0.896\n","Acc 0.898\n","Acc 0.898\n","Acc 0.899\n","Acc 0.899\n","Acc 0.898\n","Acc 0.899\n","Acc 0.899\n","Acc 0.900\n","Acc 0.898\n","Acc 0.901\n","Acc 0.902\n","Acc 0.903\n","Acc 0.903\n","Acc 0.902\n","Acc 0.903\n","Acc 0.903\n","Acc 0.904\n","Acc 0.901\n","Acc 0.903\n","Acc 0.901\n","Acc 0.901\n","Acc 0.903\n","Acc 0.902\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"4AzyYxUWtmM5","executionInfo":{"status":"ok","timestamp":1622452673148,"user_tz":-60,"elapsed":334,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"e87324aa-0a37-4dcd-f800-d9c58ee635c4"},"source":["plt.figure()\n","plt.plot(accuracy_graphs[1e-4])\n","plt.ylabel('Validation accuracy. Noise 1e-4')\n","plt.xlabel('SGLD_step/50')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"bfYMfR6ItxNX","executionInfo":{"status":"ok","timestamp":1622452686681,"user_tz":-60,"elapsed":469,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"1112f74c-bd61-470d-d074-74bb4b273c7a"},"source":["plt.figure()\n","plt.plot(accuracy_graphs[1e-5])\n","plt.ylabel('Validation accuracy. Noise 1e-5')\n","plt.xlabel('SGLD_step/50')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9fnA8c+TQS57hg0hQNgiSkSGExe1KooL68BVqlVrtdbRuoparfVXbetERdSiqNSBiIOpVvaeIiGsRCCBsEfm8/vjnMAl3NycQG5yyXner9d95Z79nBDuc7/jfL+iqhhjjDElxVR1AMYYY6KTJQhjjDEhWYIwxhgTkiUIY4wxIVmCMMYYE1JcVQdQUZo0aaLt2rWr6jCMMea4Mn/+/K2qmhhqW7VJEO3atWPevHlVHYYxxhxXRGR9adusiskYY0xIliCMMcaEZAnCGGNMSJYgjDHGhGQJwhhjTEiWIIwxxoRkCcIYY0xI1eY5iKNVUFjE2zPX07RuAs3qBWhaN4Gm9RKoVcP3vxpjjM/5/lNw6548npiw4oj1dRLiOK1jE169vncVRGWMMVXP9wmiWb0EFj5yHlt2HyBrVy5Zu3PJ2n2Ab5ZvYcqPW6o6PGOMqTK+TxAiQsPaNWhYuwZdmh9an1dQxKKNOygsUmJjpOoCNMaYKmKN1KUIxMcCcCC/sIojMcaYqmEJohSBOOdXk1tQVMWRGGNM1bAEUQorQRhj/M4SRCksQRhj/M4SRCkC8c6v5kC+VTEZY/zJEkQpEopLEAVWgjDG+JMliFIE4qyKyRjjbxFNECIySERWiUiaiDwYYntbEZkmIgtFZImIXOiubyci+0Vkkft6NZJxhlJcxZRrVUzGGJ+K2INyIhILvAScB2QAc0VkvKoGj2vxMPChqr4iIt2AiUA7d9saVe0VqfjKYo3Uxhi/i2QJog+QpqrpqpoHjAUGl9hHgXru+/rAzxGMp1wS3OcgrA3CGONXkUwQrYCNQcsZ7rpgjwPXiUgGTunhrqBtyW7V07cicnqoC4jIcBGZJyLzsrOzKzD04BKEVTEZY/ypqhuprwFGq2pr4ELgXRGJATYBbVX1JOBe4D0RqVfyYFUdqaqpqpqamJhYoYFZFZMxxu8imSAygTZBy63ddcFuAT4EUNWZQABooqq5qrrNXT8fWAN0imCsRzjYSG1DbRhjfCqSCWIukCIiySJSAxgKjC+xzwbgHAAR6YqTILJFJNFt5EZE2gMpQHoEYz2CdXM1xvhdxHoxqWqBiNwJfA3EAqNUdbmIjADmqep44A/A6yJyD06D9Y2qqiJyBjBCRPKBIuA2Vc2JVKyhxMQINWJjrA3CGONbEZ0PQlUn4jQ+B697NOj9CmBAiOP+C/w3krF5kRAfYyUIY4xvVXUjdVQLxMeSa91cjTE+ZQkijEC8VTEZY/zLEkQYgbhYq2IyxviWJYgwAvGWIIwx/uU5QbjdVYeISJdIBhRNrIrJGONnpSYIEfk06P1gYCpwMfCZiNwY+dCqXkJcrI3FZIzxrXDdXJOC3j8ADFTVtSLSBJgCjI5kYNEgEB/Dtr1WgjDG+FO4KiYNeh+nqmsBVHUrzsNr1V6CdXM1xvhYuBLEiSKyCxAgQURaqOomd9iM2MoJr2oF4mJtwiBjjG+VmiBUtbQkUAv4TWTCiS4Be5LaGONj5ermKiIXqeoOd+TVas+6uRpj/Ky8z0GMiEgUUSoQH8MBG+7bGONT5U0QEpEoolQgLpbCIiW/0JKEMcZ/ypsgfNH2UMxmlTPG+FmZCUJEaonIIyLyuqrOEZEUEbmoMoKrasWzytnT1MYYP/JSgngLyAX6ucuZwJMRiyiKJFgJwhjjY14SRAdVfRbIB1DVfXhsixCRQSKySkTSROTBENvbisg0EVkoIktE5MKgbQ+5x60SkQs83k+FSogrnpfaEoQxxn+8zCiXJyI1cZ+sFpEOOCWKsNw5pV8CzgMygLkiMt6dRa7Yw8CHqvqKiHTDmX2unft+KNAdaAlMFpFOqlqpn9SH2iCsiskY4z9eShCPAV8BbURkDM44TPd7OK4PkKaq6aqaB4wFBpfYR4F67vv6wM/u+8HAWFXNdYf4SHPPV6mskdoY42dlliBUdZKILAD64lQt3e2Ox1SWVsDGoOUM4NQS+zwOfCMidwG1gXODjp1V4thWJS8gIsOB4QBt27b1EFL5BA5WMVkJwhjjP566uarqNlX9QlUnqOrWCpwT4hpgtKq2Bi4E3hURz11vVXWkqqaqampiYmIFhXSIlSCMMX52tDPKfeNhn0ygTdBya3ddsFuADwHc4TsCQBOPx0actUEYY/ys1ComEflXaZuABh7OPRdIEZFknA/3ocCvSuyzATgHGC0iXXESRDYwHnhPRP6B00idAszxcM0Kdeg5CCtBGGP8J1wbxE3AHwjdY+mask6sqgUicifwNc7w4KNUdbmIjADmqep49/yvi8g9OA3WN6qqAstF5ENgBVAA3FHZPZggqARh3VyNMT4ULkHMBZap6oySG0TkcS8nV9WJOF1Xg9c9GvR+BTCglGOfAp7ycp1ICcRZFZMxxr/CJYgrgAOhNqhqcmTCiS4JVsVkjPGxcBMG5VRmINEoIS4GEci1BGGM8aGj7cXkCyJCQpzNCWGM8SdLEGVIiLNZ5Ywx/uQ5QYhIrUgGEq1sXmpjjF95mQ+iv4isAH50l08UkZcjHlmUCMTH2lAbxhhf8lKCeB64ANgGoKqLgTMiGVQ0CVgVkzHGp7yOxbSxxCrffGI6VUxWgjDG+I+X+SA2ikh/QEUkHrgbWBnZsKJHQryVIIwx/uSlBHEbcAfOcNuZQC932RcC8bHWzdUY40te5oPYClxbCbFEpUBcDFlWgjDG+JCXXkzPikg9EYkXkSkiki0i11VGcNEgYFVMxhif8lLFdL6q7gIuAtYBHYE/RjKoaGKN1MYYv/KSIIqroX4JfKSqOyMYT9Rx2iCsBGGM8R8vvZgmiMiPwH7gdhFJpJRRXqujhDh7ktoY409lliBU9UGgP5CqqvnAXmBwpAOLFk4bRBHOPEbGGOMf4aYcHaiqU0VkSNC64F0+LuvkIjII+CfOjHJvqOozJbY/D5ztLtYCmqpqA3dbIbDU3bZBVS8p+3YqXvGscnmFRSS4EwgZY4wfhKtiOhOYClwcYptSRoIQkVjgJeA8IAOYKyLj3VnknJOo3hO0/13ASUGn2K+qvcq8gwhLiCueNMgShDHGX8JNGPSY+/Omozx3HyBNVdMBRGQsTtXUilL2vwZ47CivFTHFJYjc/EKoGV/F0RhjTOXx8hxEfRH5h4jMc1//JyL1PZy7FRA8hlOGuy7UNZKAZJwSS7GAe71ZInJpKccNL44rOzvbQ0jlV5wgrKurMcZvvHRzHQXsBq5yX7uAtyo4jqHAOFUN7i6UpKqpwK+AF0SkQ8mDVHWkqqaqampiYmIFh+QIFM9LbV1djTE+46WbawdVvTxo+S8issjDcZlAm6Dl1u66UIZSYnwnVc10f6aLyHSc9ok1Hq5boQJxxSUISxDGGH/xUoLYLyKnFS+IyACcZyLKMhdIEZFkEamBkwTGl9xJRLoADYGZQesaikiC+74JMIDS2y4iyqqYjDF+5aUEcTvwttvuIEAOcGNZB6lqgYjcCXyN0811lKouF5ERwDxVLU4WQ4GxeviDBl2B10SkCCeJPRPc+6kyHaxishKEMcZnvIzmugg4UUTqucu7vJ5cVScCE0use7TE8uMhjpsBnOD1OpF0qARhCcIY4y/hHpS7oZT1AKjqOxGKKaocaqS2KiZjjL+EK0GcUsr6S3C6q/oiQSRYI7UxxqfCPSh3V/F7cYoN1wIPALOApyIfWnRIcEsQuZYgjDE+E7YNQkTicBqk78NJDFeo6qpKiCtqHHyS2qqYjDE+E64N4g7gbmAKMEhV11VWUNHEnoMwxvhVuBLEv4Es4DRgQNBIrgKoqvaMcGxRIT5WiBF7DsIY4z/hEkRypUURxUTE5qU2xvhSuEbq9ZUZSDSzaUeNMX7kZagN3wvExVgVkzHGdyxBeGBVTMYYP7IE4UGCOy+1Mcb4yVElCBF5vILjiGqB+BhyrQ3CGOMzXmaUu0tEGpZYPT9C8USlhLgYq2IyxviOlxJEM2CuiHwoIoNERFT180gHFk0CVsVkjPGhMhOEqj4MpABv4gy7sVpE/hpqCtDqKhAXa1VMxhjf8dQG4U7ms9l9FeDMADdORJ6NYGxRIxBv3VyNMf7jpQ3ibhGZDzwL/ACcoKq3A72By8s4dpCIrBKRNBF5MMT250Vkkfv6SUR2BG0bJiKr3dewct9ZBbJursYYP/Iy5WgjYEjJJ6tVtUhELirtIBGJBV4CzgMycNoxxgdPHaqq9wTtfxdwkvu+EfAYkAooMN89drvnO6tAliCMMX7kpYrpS5x5qAEQkXoiciqAqq4Mc1wfIE1V01U1DxgLDA6z/zXA++77C4BJqprjJoVJwCAPsUZEQnyMzShnjPEdLwniFWBP0PIed11ZWgEbg5Yz3HVHEJEknMEBp5bnWBEZLiLzRGRedna2h5COTiAulryCIoqKNGLXMMaYaOMlQYjbSA04VUt4q5oqj6HAOFUtVz2Oqo5U1VRVTU1MTKzgkA6xSYOMMX7kJUGki8jvRCTefd0NpHs4LhNoE7Tc2l0XylAOVS+V99iIC7jTjlo7hDHGT7wkiNuA/jgf0BnAqcBwD8fNBVJEJFlEauAkgfEldxKRLjjdZmcGrf4aOF9EGrpPcZ/vrqsSxSUIG/LbGOMnZVYVqWoWzod7uahqgYjcifPBHguMUtXlIjICmKeqxcliKDC2RDVWjog8gZNkAEaoag5VJCGuuARhVUzGGP8oM0GISAC4BegOBIrXq+rNZR2rqhOBiSXWPVpi+fFSjh0FjCrrGpXhYAnCqpiMMT7ipYrpXaA5TtfTb3HaA3ZHMqhoU9wGYY3Uxhg/8ZIgOqrqI8BeVX0b+CVOO4RvBOKsBGGM8R8vCSLf/blDRHoA9YGmkQsp+iRYFZMxxoe8PM8w0u1J9DBOL6Q6wCMRjSrKHOrmalVMxhj/CJsgRCQG2OUOd/Ed0L5Soooyhx6UsxKEMcY/wlYxuU9N319JsUQt68VkjPEjL20Qk0XkPhFpIyKNil8RjyyKBOw5CGOMD3lpg7ja/XlH0DrFR9VNVoIwxviRlyepkysjkGh2KEFYCcIY4x9enqS+IdR6VX2n4sOJTrExQnys2FhMxhhf8VLFdErQ+wBwDrAA8E2CAEiIs1nljDH+4qWK6a7gZRFpgDM7nK8E4mOsiskY4yteejGVtBdn9jdfSYiLtecgjDG+4qUN4nOcXkvgJJRuwIeRDCoaBeJjyLUShDHGR7y0QTwX9L4AWK+qGRGKJ2oF4q0NwhjjL14SxAZgk6oeABCRmiLSTlXXRTSyKBOIj7VeTMYYX/HSBvEREFy3UuiuK5OIDBKRVSKSJiIPlrLPVSKyQkSWi8h7QesLRWSR+zpiqtLKZo3Uxhi/8VKCiFPVvOIFVc1z55gOS0RigZeA83Dmsp4rIuNVdUXQPinAQ8AAVd0uIsHDiO9X1V5ebyTSAnGx7NiXX/aOxhhTTXgpQWSLyCXFCyIyGNjq4bg+QJqqprsJZiwwuMQ+vwZeckeLLZ7/OipZG4Qxxm+8JIjbgD+JyAYR2QA8APzGw3GtgI1ByxnuumCdgE4i8oOIzBKRQUHbAiIyz11/aagLiMhwd5952dnZHkI6eglWxWSM8RkvD8qtAfqKSB13eU8FXz8FOAtnruvvROQEVd0BJKlqpoi0B6aKyFI3luDYRgIjAVJTU5UICsTbcxDGGH8pswQhIn8VkQaqukdV94hIQxF50sO5M4E2Qcut3XXBMoDxqpqvqmuBn3ASBqqa6f5MB6YDJ3m4ZsQkxFkJwhjjL16qmH7hfqMHwG0vuNDDcXOBFBFJdhu1h+JMWRrsU5zSAyLSBKfKKd1NQglB6wcAK6hC1gZhjPEbLwkitvjDGpznIICEMPsDoKoFwJ3A18BK4ENVXS4iI4Iavb8GtonICmAa8EdV3QZ0BeaJyGJ3/TPBvZ+qQiAuloIipaDQShHGGH/w0s11DDBFRN5yl28C3vZyclWdCEwsse7RoPcK3Ou+gveZAZzg5RqVJRDv5NLcgiLiYo9mCCtjjDm+eGmk/puILMEZ5hvgCVX9OrJhRZ/gWeVqJ3jJq8YYc3zz9Emnql8CX0Y4lqhWXII4UGBVTMYYf/DSi6mviMwVkT0ikucOgbGrMoKLJjYvtTHGb7xUpr8IXAOsBmoCt+IMoeErCXGWIIwx/uKptVVV04BYVS1U1beAQWUdU90crGKyZyGMMT7hpQ1in/scwyIReRbYxNHNRHdcK65iyrUShDHGJ7x80F/v7ncnznSjbYDLIxlUNDrYBmHDbRhjfMJLN9f17tsDwF8iG070siomY4zf+K6q6GhZI7Uxxm8sQXgU/CS1Mcb4gSUIjwJWgjDG+EyZbRAi0gn4I5AUvL+qDoxgXFHn0INyVoIwxviDl26uHwGvAq8Dvv36nBBX3Ejt21+BMcZnvCSIAlV9JeKRRLmYGKFGXIx1czXG+IaXNojPReS3ItJCRBoVvyIeWRQKxMWQa1VMxhif8FKCGOb+/GPQOgXaV3w40c1mlTPG+EmZJQhVTQ7x8pQcRGSQiKwSkTQRebCUfa4SkRUislxE3gtaP0xEVruvYaGOrWyWIIwxfuKlF1M8cDtwhrtqOvCaquaXcVwszqiv5wEZwFwRGR88daiIpAAPAQNUdbuINHXXNwIeA1JxSivz3WO3l/P+KlQgPsZ6MRljfMNLG8QrQG/gZffV211Xlj5Amqqmq2oeMBYYXGKfXwMvFX/wq2qWu/4CYJKq5rjbJhEFI8gG4mOtkdoY4xte2iBOUdUTg5anishiD8e1AjYGLWcAp5bYpxOAiPwAxAKPq+pXpRzbquQFRGQ4MBygbdu2HkI6NglxMVbFZIzxDS8liEIR6VC8ICLtqbjnIeKAFOAsnEmJXheRBl4PVtWRqpqqqqmJiYkVFFLpAvGxNtSGMcY3vJQg/ghME5F0QHCeqL7Jw3GZOEODF2vtrguWAcx22zPWishPOAkjEydpBB873cM1IyohLpate/KqOgxjjKkUXob7nuI2Jnd2V61S1VwP554LpIhIMs4H/lDgVyX2+RSn5PCWiDTBqXJKB9YAfxWRhu5+5+M0ZlepQHyMTRhkjPGNUhOEiAxU1akiMqTEpo4igqp+HO7EqlogIncCX+O0L4xS1eUiMgKYp6rj3W3ni8gKnGqrP6rqNvf6T+AkGYARqppzVHdYgaybqzHGT8KVIM4EpgIXh9imQNgEAaCqE4GJJdY9GvRegXvdV8ljRwGjyrpGZQrEx3DA2iCMMT5RaoJQ1cfctyNUdW3wNrfayHcCcVaCMMb4h5deTP8NsW5cRQdyPCiuYnIKPsYYU72Fa4PoAnQH6pdoh6gHBCIdWDQKxMdQpJBfqNSIk6oOxxhjIipcG0Rn4CKgAYe3Q+zGeQLadw5OGlRQSI04m4zPGFO9hWuD+Az4TET6qerMSowpaiXEH5p2tF4gvoqjMcaYyPLyoNxCEbkDp7rpYNWSqt4csaiiVMAtNdicEMYYP/BST/Iu0BxnAL1vcZ5q3h3JoKJVcAnCGGOqOy8JoqOqPgLsVdW3gV9y5KB7vnCwBGHPQhhjfMBLgiie92GHiPQA6gNNIxdS9ApYCcIY4yNe2iBGumMiPQKMB+oAj4Y/pHo6lCCsBGGMqf68DNb3hvv2W3w4D3WwQLxT4LIShDHGD8I9KHfE+EjBVPUfFR9OdAt+DsIYY6q7cCWIuu7PzsApONVL4Dw0NyeSQUWrQJxVMRlj/CPcg3J/ARCR74CTVXW3u/w48EWlRBdlrIrJGOMnXnoxNQOCp1HLc9f5jj0HYYzxEy+9mN4B5ojIJ+7ypcDoiEUUxYpLEPvzLEEYY6q/MksQqvoUzhzU293XTar6tJeTi8ggEVklImki8mCI7TeKSLaILHJftwZtKwxaP77ksVUhIS6WVg1qsmLTrqoOxRhjIi5cL6Z6qrpLRBoB69xX8bZGZU0BKiKxwEvAeUAGMFdExqvqihK7fqCqd4Y4xX5V7eXtNirPqe0bMX1VNkVFSkyMDfltjKm+wpUg3nN/zgfmBb2Kl8vSB0hT1XRVzQPGAoOPIdao0K99Y3L25vFTli+HozLG+EipCUJVL3J/Jqtq+6BXsqp6eWCuFbAxaDnDXVfS5SKyRETGiUiboPUBEZknIrNE5NJQFxCR4e4+87Kzsz2EdOz6tm8MwKw12yrlesYYU1VKTRAicnK4VwVd/3Ognar2BCYBbwdtS1LVVOBXwAsi0qHkwao6UlVTVTU1MTGxgkIKr02jWrRuWJOZ6ZYgjDHVW7heTP8XZpsCA8s4dyYQXCJo7a47dBLV4E/ZN4Bng7Zluj/TRWQ6cBKwpoxrVoq+7RszeeUWa4cwxlRr4R6UO/sYzz0XSBGRZJzEMBSnNHCQiLRQ1U3u4iXASnd9Q2CfquaKSBNgAEHJo6r1a9+YcfMzWLVlN11b1KvqcIwxJiK8PAeBO8x3Nw6fUe6dcMeoaoGI3Al8DcQCo1R1uYiMAOap6njgdyJyCVAA5AA3uod3BV4TkSKcarBnQvR+qjJ9OzjtEDPXbLMEYYyptkRVw+8g8hhwFk6CmAj8Avifql4R8ejKITU1VefN89K5qmKc8ew0ujSvy8gbUivtmsYYU9FEZL7b3nsEL0NtXAGcA2xW1ZuAE3EmDfK1vu0bMXttDkVF4ROsMcYcr7wkiP2qWgQUiEg9IIvDG599qV+Hxuzcn8/KzfZUtTGmevKSIOaJSAPgdZyH5BYAMyMa1XHg1ORD7RDGGFMdhXsO4iURGaCqv1XVHar6Ks6wGcPcqiZfa9mgJkmNazErPeyII8YYc9wKV4L4CXhORNaJyLMicpKqrlPVJZUVXLTr174xc9Zuo9DaIYwx1VC4oTb+qar9gDOBbcAoEflRRB4TkU6VFmEU69u+MbsOFLDSRnc1xlRDXob7Xq+qf1PVk4BrcOaDWBnxyI4DB8dlsmE3jDHVUJkJQkTiRORiERkDfAmsAoZEPLLjQPP6AZKb1LaGamOixIH8QjbvPFDVYVQb4RqpzxORUTijsP4aZx7qDqo6VFU/q6wAo13f9o2ZszbH2iGMqWJFRcqNb83h3H98y8879ld1ONVCuBLEQ8AMoKuqXqKq76nq3kqK67jRt30jducWsOLn6GyH2Lk/n5378qs6DBMlVJU/f7KUCUt+rupQKtzYuRuZlZ7D3rwCHv1sGWWNEmHKFq6ReqCqvqGq2yszoONNP7cdYmb61iqO5Ej5hUVc/soMLnvlB/ILi6o6nMPsPpDP96uz2bEvr6pD8ZVvf8pmzOwN3D9uCZnV6Fv25p0HeHriSvp3aMxDv+jC5JVZfLlsc1WHddzz8qCcCaNpvQDtE2tH5fMQH8zdSFrWHtKz9/Lf+RlVHQ5rt+7lje/TufaNWZz8xCSuf3MOF/37f6ze4o/Z+b5Ysol+T09hRlrVfZl4edoamtZNQBUe+TT6vmWv2ry73DGpKg9/upT8oiKeHnICNw9Ipkerejw2frmVno+RJYgK0M9th8griJ5v6XtzC3hh8mpOadeQXm0a8M8pqzmQX1gp1y4qUjbm7GPKyi28+u0a/vDhYgY+N52zn5vOk1+sJGtXLjeflsw/h/Yit6CIIS/P4PvVlTMjYFUoKCzirxNXcsd7C9i08wBvzVhXJXHMWZvDnHU5/PasDvzh/E5M/TGLL5ZuKvvASjL1xy1c8MJ3fLIws+ydg0xYsonJK7O47/zOJDWuTVxsDM8M6cm2Pbk889WPEYrWHzwN923CG9ilKWNmb+B/adkM7NIsotfafSCf6auySW5Smx6tSh8z8Y3v17J1Ty6vXd+b3PxCfvXGbP4zaz23nu5lttijcyC/kNv/M5+Z6ds4kH8oWTarl0DXFvUY1r8dA7s0pU2jWge3pbZrxC2j53LjW3N58tIeXNOnbcTi82pG2lZenJbGzQOSObfbsf17btuTy53vLWRm+jau75tEbIzwn1nrydmbR6PaNSooYm9enp5G49o1uPqUtsTHCp8t+pnHx6/g9I6J1K8Vf8znX5Kxg9gYoXvL8o/lqar83zc/ATBm9gaGnNza03E5e/N4fPxyTmzTgJsGJB9c36NVfW45LZnXv1/LZSe1ok9yo3LHZCxBVIjTUxJpUCuezxb9HJEEsXNfPpNXbuHLZZv47qet5BUWUTchjo9u70eX5kfOR7F1Ty4jv1vDoO7N6Z3UEIDTOjbh5elrGNqnLXUSQv+zz0rfxo59eQzq0eKo4hy/6Gemrcrmmj5t6dWmPh2b1qVj0zrUr1n6h0+rBjX56LZ+3PneQh76eClrt+7lwUFdqmSmPlXl3Vnr+cvnK4gRmLFmG4N7teTxi7vT8Cg+zBdv3MHt/5nP1r15/P2KnlyZ2oYfN+9i9Ix1fL74Z4b1bxc2lndmrqdlg5qc2SmRGnHHVthflrmT6auy+eMFnalZIxaAZy4/gUte/IGnv1zJM5f3POKYHfvy+PfUNFKTGvKLE8L/TezLK+CGUXPYl1vIv67pVe6/oW9WbGH5z7vo1aYB89dv56ctu+nUrG6Zxz0xYQU79+cz5vITiC3xN3PPeZ34ctlmHvp4CRPvPp2EuNhyxWQsQVSIGnEx/KJHCz5blMm+vAJq1aiYX+us9G28+u0afkjbSn6h0qpBTW7ol0T/jo156OOl3PzWXD65YwDN6gUOO+5fU1ZzoKCI+wd1Prjuvgs6c+lLP/Dm92u5+9yUI6717U/Z3Pr2XPIL9eCHWXmoKqNnrKNzs7r89bIeiHj/gK8biOfNYan85fMVjPwunbSsPfzh/E5H9U30aOUVFPHY+OW8P2cD53Rpyt+vPJF3Zq7jxalp/JC2lRGDe3BhmA/JPbkFbMzZx4acfWzM2ce6bXv5cG4GiXUT+Pj2/gdLe12a16Nbi3p8vCAjbIKYviqbx8YvB6BhrXgu6tmSy05uxUltGpTrd1vslelrqJsQx3V9kw6u696yPnT6GYIAABoTSURBVLeensxr36Zz6UmtDj74CfD18s08/Okysnfn8unCTM7q3PRgYgll3PwMduzLp31ibX47ZgF/vewEhnosDRYVKc9P+onkJrUZeX1vBvxtKmPnbOTRi7uFPW7aj1l8sjCT352TEvKLUq0acTx5aQ9ufGsuL09bwz3ndSKvoIhlP+9kwfrtzFu3nU27DtC6QU1aN6pJ20a1Dnsdze85kvIKili1eTc9WtWrtNgimiBEZBDwT5wZ5d5Q1WdKbL8R+DuH5qp+UVXfcLcNAx521z+pqm9HMtZjNbhXS96fs4HJK7O45MSWx3Su9Ow9PP3lj0xasYVm9RK4eUAyvzihBSe2rn/wD2PUjQGuenUmN701lw9v63ewVLB2617em72Ba/q0oX1inYPn7NWmARd0b8br36dzQ7+kw74Rz07fxm/enUdK07o0ql2DBz9eSv2a8ZzfvbnnmBds2M6KTbt4qpzJoVhcbAwjBnenQ2Jt/vbVKn75r/9xSruG3Ng/mfO7NyM+tnzfoFWVrN25rN6yh9VZu1mdtYfs3bn0atOAAR2bcEKr+ge/cW7bk8vtYxYwZ21x/XxnYmOE35/biQu6N+f+cUv47ZgF/KJHc67p05afd+xn4/Z9bMjZfzAh5Ow9vDdWnYQ4zu6SyDNDeh5R+hhyciue/GIlaVm76dj0yG/JqsqL09Jo1aAmf7mkO58t/pkP523k3Vnrade4FteemsQtpyV7LmWlZ+9h4rJN3H5mhyNKc78/pxNfLt3Mnz5eysS7T2dvbgGPjV/OhCWb6NqiHr87J4VHPl3G+3M2cPNpySHPX1ikvPH9Wk5q24Axt57K7f9ZwIMfLyVnXx63n9mhzL+Hr5Zv5sfNu3nh6l40rRfg/O7N+XhhBvcP6kwgPnRS2ptbwJ8/WUpK0zrccXaHUs99VuemDO7VkpenpzFzzTYWZ+wg120rbNuoFm0a1WTFpl18s2Iz+YWHGsfbJ9ZmWL92XN67dakl7sqStfsA78/eyJjZ68nancvvzknh3vMqZ7SjMmeUO+oTi8TiDPh3Hs7DdnOBa4KnDnUTRKqq3lni2EbAPCAVUJxhxnuH63Jb2TPKlVRUpPR/Zio9WtXjjWGnHNU5cvbm8a8pq/nPrPUE4mO5/awO3HJacqn/SaatyuLWt+dxRkoTXr8hlbjYGH47Zj7TV2Xz7R/PJrFuwmH7/7RlNxe88B3DT2/PQxd2BZxqkGvfmE2zegl8+Jt+BOJjufaN2azYtIu3b+pDvw6NQ136CHe9v5Dpq7KY9dA51D7G/1A79+Xz4byNvDNrHRtz9tO8XoDr+rbl+n7twlZXgfPB8eDHS5m+KovdBwoOrq9fM57GtWuQvtV5lKduII6+7RtzSruGvD1jPVv35PLsFT0Z3KvVEecsKCzi9e/X8vzknw52RIiNEVo1qHnwQ6aN+62zTUPnZ4Na8aV+MGbtPkC/p6fymzPac/+gLkdsn52+jatHzuIvl3Q/WMrYfSCfr5ZtZtz8DGavzeGq1NY8PaTnEdUqodw/bjGfLfqZHx4cSJM6CUds/351Nte/OYfzujVj/vrt7D6Qz+8GpnDbWR2Ij43h6tdmsm7bXr67/+yQ1TQTl27it2MW8Op1JzOoRwvyCoq476PFjF/8M7eelsyfLuxaajIrLFIGvfAdRap8c8+ZxMYI/1u9levenM0/h/YK+e8B8LevfuSV6Wv47+396J0Uvn1h655cho6cRZ2EOHonNSQ1qSG9kxrSNKjkXVikbNl1gA05+0jL2sNH8zNYvHEHdRLiuKJ3a4b1b0dyk9phr1PRFm7Yztsz1vHF0k3kFypndkokIS6Gb1Zs4YWre3HpSaF/N+UVbka5SKbGPkCaqqa7QYwFBgNe5pa+AJikqjnusZOAQcD7EYr1mMXECBef2ILRM9axY18eDWp5r7POLyxi9A/r+NfU1ezNLeCaPm2557xOIf8zBzu7c1OeGNyDP32ylEfHL+fK3q2ZuHQzd5+TckRyAOjUrC6X9WrF6BnruGlAMtv35XHDqDk0rB3PmFv70ti93ls3nsJVr83k1+/MY+zwvmEbwwGydh3gy6WbGNa/3TEnB4D6teL59Rntufm0ZKb+mMXbM9bx3Dc/8dH8DF6/IbXUuunte/O4cfRclmbs4KrUNnRtUY+UpnXo2KwOiXUSEBG27sllxpptzEjbyg9rtjJpxRaa1wvw0W396Nm6QcjzxsXGcPtZHbioZws25uyjTaNatKgfIK6cpZpiTesGOCOlCZ8szOS+8zsf8eH50vQ1NKlTg6tPOVTNVzcQz5Wpbbiid2uen7yaf01Zzb68Qp6/ulfY0lXmjv18vCCTa09tW+rf0+kpiQw5qRUfL8zkxNb1+fuVfQ/7Hd81MIXr3pzNuPkZXHtq0mHHqiqvfZdOUuNanNfNKXHWiIvhhat70bBWPG/8by05+/J4ZkjPkO0oXyzdxOqsPfz7mpMOJrv+HRrTplFN3p+zIWSCWLt1L29+v5YhJ7cqMzkANKmTwOR7zwy7T2yM0LJBTVo2qEnf9o25rm/SwQ/oMbPXM3rGOs7t2oy/DulB07qBsOcqzU9bdlMnIY6WDWqG3S+3oJA7xixk8sot1EmI49pTk7ihXxLtE+uQV1DEdW/O5v5xS2jTqKan+z8mqhqRF85UpW8ELV+PU4UUvM+NwCZgCTAOaOOuvw94OGi/R4D7QlxjOE5JY17btm21qi3N2KFJD0zQ92av93zM/PU5esHz32rSAxN02KjZ+tPmXeW+7jNfrtSkByboSSO+0d5PTNLdB/JL3XfDtr3a8U9f6C2j52rvJybpqU9N1g3b9h6x36Yd+7X/01P05BHf6Jqs3WGv//ykVZr0wARdm72n3LF7NW/dNk19cpJ2f/QrnbR88xHbM7fv03P+b7qm/Hmifr1sk+fzZmzfp3tzS/99Rcr4RZma9MAE/WF19mHri/+GXpq2Ouzxr05P06QHJugto+fo/ryCUvd77LNl2uGhL3RjzpH/xsH25ubrpOWbNb+g8IhtRUVFOvjF/+mAZ6ZoXonts9O3adIDE/SdGWtDHvfCpJ806YEJevG/v9f0En8fBYVFevZz0/S8f0zXwsKiw7a9OHW1Jj0wIeTf3s1vzdHuj36lW3buD3tPFWXLrv36/KRV2vnhidrnqUk6b13OUZ2j2yNfaq+/fK1LM3aUul9eQaHe+vZcTXpggr44dXXI/8s5e3L1zGen6skjvgn5f7e8gHlayud4VT8H8TnQTlV7ApOAcrUzqOpIVU1V1dTExMSIBFge3VvWo31ibcYvKnsYg53783n406Vc/soMdu7P57XrezP6pj6keOi5UdIfz+/MxSe2JGdvHnefmxK2zrRNo1oMPaUtk1duQVX5z62nHtbttFjz+gHevaUPANe/OafUsW3yCooYM3sDZ3VOpF0Ei+C9kxox/s4BJDepza/fncfL09MOPlCVlrWHK16ZweadB3jn5j7lajtp1aBmhXUqKI/zujWjbkIc/11weJ//l6enUTdweGNyKL85swNPDO7O5JVZ3PL2XPblFRyxT8b2fYydu4FLT2pF64ZH/hsHq1UjjnO7NQtZKhIR7hrYkYzt+4/42x75XToNa8VzRe8jOzWICHefm8Kr1/Vm/bZ9/PJf3zNufsbBf7fxizNJz97LPed2OqIUdWXv1sTGCB/M3XjY+mk/ZjHlxyx+d07Hw6qIIqlp3QC/P7cTn/x2AIH4WIaOnMm7s9aX64G+575eRV5hEYH4WK55fRbz1x/5YG1hkfKHDxczacUWRgzuzh1ndwz5f7lh7Rq8eeMp5BcWcfPouew6ELmHASOZIDI5fO7q1hxqjAZAVbepaq67+AbQ2+ux0UhEuOTElsxau63UESVVlQlLfubcf3zLe7M3cFP/ZCbdeyYXlONDraSYGOG5K3vyzs19uNZDz5G7z03hspNa8e4tp9KxaZ1S92ufWIe3b+7Drv35XPfGbLJ35x6xz1fLN5O9Ozdsj5yK0qK+0yX24p4tefarVdw9dhFz1uZw1WszySssYuzwvof1xIlmgfhYftmzBV8u23Twwz0taw9fLtvMsH7tqBco+7mE6/u147krT2Tmmm3c8OYc3pm5jkc+XcbQkTNJfXISp/1tGnkFRdx2ZumNuF4N7NKUri3q8dL0tIMDU67J3sPklVu4vl+7sD2cBvVozle/P50TWtXnvo8Wc/fYRWzfm8c/J6+ma4t6If/2m9YLcE6Xpoybn3Gw3SevoIgRE1bQvkltbuwfusE8krq2qMf4O07jtI5NeOTTZdz30RJPD58uzdjJR/MzuGlAMuNu70+TOglc/+acw56oLypS/vTxUsYv/pkHBnXhhn7twp6zQ2IdXr2+N2u37uWOMQsoiNBQOpFMEHOBFBFJFpEawFBgfPAOIhLcb/ASDs0z8TVwvog0FJGGwPnuuqh3yYktUSXkYGiqyl8nruTO9xbSrF4Cn91xGo9e3K1CekkkxMVyRqdETz1bmtRJ4Pmre9Gt5ZFdA0vq0ao+o246hU07D3D9m7OPGDvpnRnrSGpcizNTKqcEF4iP5Z9De3H/oM58vuRnrnptJrVqxPLRbf3LbCuJNped1Ip9eYV8vdwZM+jVb9eQEBfDTQPaeT7HFb1b8+KvTmbRxh08+tlyPl2YSW5BEQO7NOXPF3blsztOC/slwCsR4c6zO5KevZcvlzlPX7/xfToJcTHc0C98aQec5P7er/ty3/md+GLpJs74+zTWbdvHPeemlPo3e82pbdm2N4/JK7cA8NYPa1m7dS+PXtztmJ8LOVr1a8Xz5rBT+P25Kfx3QQaXvzKDjO37St1fVfnL58tpVKsGdw7sSKsGNfngN31p07AWN46ey9QfnZL8iAkr+GDeRu4a2JHbz/KW0Pt3aMKTl/bg+9VbGTHBS9Nu+UWsbK2qBSJyJ84HeywwSlWXi8gInDqv8cDvROQSoADIwWmTQFVzROQJnCQDMELdButo1z6xDj1b13d6cJR4avnl6Wt4/fu1XN83iccu7nbUjZyV7ZR2jXj9hlRuHj2XYW/NZcytp1InIY5lmTuZt347D/+y9F4qkSAi/PasjnRuVpdPFmbyyEXdjngW5HhwSrtGtG5Yk48XZNInuTGfLszkur5JBzsLeHXhCS1ITWpIkTpPrUeqj/ygHs3pkFibF6em0Se5Ef9dkMkVvVuX2ZmiWGyMcOfAFPp1aMLvP1hIp2Z1OS/Mk+pnpCTSqoHTWJ2a1JB/TVnNuV2bclbnphV1S0clxu0C3bN1fe4eu4irX5vF2OF9Q1bVTliyiXnrt/P0kBMOlgqb1g0wdnhfhr01h+HvzOfcrs34avlmbh6QXO7uq0P7tCV96152H8insEg99Worj4h1c61sVd3NNdgb36fz5BcrmXbfWQe7xr03ewN/+mQpg3u15PmrelXJk8LHatKKLdz2n/n0TmrI2zf14fHxyxm/+Gdm/emcMrufmtD+8c0q/j0tjUHdmzNpxRa+u//sMnu5VKWPF2Rw74eLObltAxZu3MGUe8887HkbrwqLlIKiojKfbn5h8k+8MHk1p3Vswpy1OXxzzxkRbesqr2WZO/nV67OoXyueD4b3O+zf7kB+Ief837fUrxnP53eddsSH9+4D+dw8ei5z121n6ClteHrICUeV3IuKFBGO+otBuG6ux8dX2OPMRT1bIsLBBr2JSzfx50+XclbnRJ678sTjMjmA07D6j6tOZO66HG59Zy6fLsrkspNbWXI4Bped3BpV+HLZZoac3CqqkwM4VahtGtVkwYYdnNe12VElB3BKE16GvrgqtQ0xAv9L28qtpydHVXIApwr2P7eeyo59+Vzz+qzD2h5HfpdO5o79PHZxt5Df7OsG4nnn5lMZdWMqT112dMkBnBJNpEqNliAioHn9AH2TG/PZ4ky+X53N3WMX0rttQ165tne5nwiONoN7teKZISfwQ9o2cguKPNU/m9IlN6nNyW0bIEKFNCZHWlxsDHee3RER+M2ZkRv4sVjLBjU5p2szWtQPcMfZHSN+vaPRs3UD3rm5D9v25HHN67PI2nWATTv388r0NVx4QnNODdNxomaNWAZ2aVbhVUMVxaqYIuT9ORt46OOl1IiLoX2T2nwwvF+FjJgZLcbNz2DDtr3ce37nsnc2YS3J2EFa1h7PI5hWNVUlc8f+MrvOVpS9uQXkFRQd1YCJlWn++hxueHOOO1d9Hb5bnc2Ue88M2TYRTcJVMVmCiJAd+/Lo89QUmtcPMO62fpXWZ9sYU3XmrM1h2Kg57M8v5I6zO/DHC44cSiXaVNVQG77WoFYN/nt7f5rXD4Qc9sIYU/30SW7E2zf34cN5G/ntWdFZJVYeliAi6ITWx1e/fGPMseuT3KjaTFB0fLeYGmOMiRhLEMYYY0KyBGGMMSYkSxDGGGNCsgRhjDEmJEsQxhhjQrIEYYwxJiRLEMYYY0KqNkNtiEg2sP4YTtEE2FrmXscnu7fjV3W+P7u36JCkqiFn/Ko2CeJYici80sYjOd7ZvR2/qvP92b1FP6tiMsYYE5IlCGOMMSFZgjhkZFUHEEF2b8ev6nx/dm9RztogjDHGhGQlCGOMMSFZgjDGGBOS7xOEiAwSkVUikiYiD1Z1PMdKREaJSJaILAta10hEJonIavdnw6qM8WiJSBsRmSYiK0RkuYjc7a4/7u9PRAIiMkdEFrv39hd3fbKIzHb/Pj8QkeiemDkMEYkVkYUiMsFdrk73tk5ElorIIhGZ56477v8ufZ0gRCQWeAn4BdANuEZEulVtVMdsNDCoxLoHgSmqmgJMcZePRwXAH1S1G9AXuMP996oO95cLDFTVE4FewCAR6Qv8DXheVTsC24FbqjDGY3U3sDJouTrdG8DZqtor6PmH4/7v0tcJAugDpKlquqrmAWOBwVUc0zFR1e+AnBKrBwNvu+/fBi6t1KAqiKpuUtUF7vvdOB82ragG96eOPe5ivPtSYCAwzl1/XN4bgIi0Bn4JvOEuC9Xk3sI47v8u/Z4gWgEbg5Yz3HXVTTNV3eS+3ww0q8pgKoKItANOAmZTTe7PrYJZBGQBk4A1wA5VLXB3OZ7/Pl8A7geK3OXGVJ97AyeZfyMi80VkuLvuuP+7jKvqAEzlUlUVkeO6b7OI1AH+C/xeVXc5X0Ydx/P9qWoh0EtEGgCfAF2qOKQKISIXAVmqOl9EzqrqeCLkNFXNFJGmwCQR+TF44/H6d+n3EkQm0CZoubW7rrrZIiItANyfWVUcz1ETkXic5DBGVT92V1eb+wNQ1R3ANKAf0EBEir/IHa9/nwOAS0RkHU417kDgn1SPewNAVTPdn1k4yb0P1eDv0u8JYi6Q4vamqAEMBcZXcUyRMB4Y5r4fBnxWhbEcNbfe+k1gpar+I2jTcX9/IpLolhwQkZrAeThtLNOAK9zdjst7U9WHVLW1qrbD+T82VVWvpRrcG4CI1BaRusXvgfOBZVSHv0u/P0ktIhfi1I/GAqNU9akqDumYiMj7wFk4ww1vAR4DPgU+BNriDIl+laqWbMiOeiJyGvA9sJRDddl/wmmHOK7vT0R64jRkxuJ8cftQVUeISHucb92NgIXAdaqaW3WRHhu3iuk+Vb2outybex+fuItxwHuq+pSINOZ4/7v0e4IwxhgTmt+rmIwxxpTCEoQxxpiQLEEYY4wJyRKEMcaYkCxBGGOMCckShDHGmJAsQZhqT0T+7A6hvcQdjvlUEYkTkb+6QzEvcl9/DjpmT4jzPC4ime6+q0Xk46MZ/VdELq2IUYPdcX8SRGS6O2R98X00dbcnuMNop7nDarc71msaf7EEYao1EekHXAScrKo9gXNxBmh8EmgJnKCqvYDTcUZQLcvz7pDOKcAHwFQRSSxnWJfiDC9/1EQkGcgMerDsWjeuXu5wD+AMn73dHU77eZzhtY3xzBKEqe5aAFuLP0hVdSuwA/g1cJeqHnDX71bVx8tzYlX9APgG+FVp+4jIM+4ER0tE5DkR6Q9cAvzd/bbfwX195ZYIvheRLu6xo0XkVRGZJyI/uYPeFRsEfFVGiMHDTY8DzpHgkQ2NKYON5mqqu2+AR0XkJ2Ayzrf+7cAGd06JY7WAUkZddYdauAzo4o7m2UBVd4jIeGCCqo5z95sC3Kaqq0XkVOBlnAHtANrhDPzWAZgmIh3dpDYIuCfocm+JSCHOQIZPqjNEwsHh7FW1QER24gyzvbUC7tv4gJUgTLXmTsLTGxgOZOMkiLOC9xGRm9xv8xtFpM2RZwkr3DfyncAB4E0RGQLsO+JgZ+jy/sBH7lwQr+GUeop9qKpFqroaSAe6uANLtlbVdHefa1X1BJxqstOB68t5D8aEZAnCVHuqWqiq01X1MeBO4GKgbfEInKr6ltsOsRNnsLzyOInDp9EMvm4Bzrf/cTjtIKGqhGJwJs7pFfTqGnyakqfFSQL/C7pO8VDTu4H33GtC0HD27rDa9YFt5bo742uWIEy1JiKdRSQlaFUvYBXOsOEvikjA3S8WqFHOc1+OM7Tz+6VsrwPUV9WJONVBJ7qbdgPFyWkXsFZErnSPERE5Meg0V4pIjIh0ANq7sQ8CvnT3jxORJu77eJxEtMw9Nni46Stwhtm20TmNZ9YGYaq7OsC/3bkWCoA0nOqmncATwDIR2Q3sx2nQ/dk9rpaIZASdp3j+iXtE5DqgNs4H8UBVzS7l2nWBz9wkJMC97vqxwOsi8jucD+5rgVdE5GGcnlRjgcXuvhuAOUA9nHaKA+6Q2Y+62xOAr93kEIvTzvK6u+1N4F0RScOZp3yoh9+XMQfZcN/GRCkRGU1QY7a7rjXwuqr+osoCM75hJQhjjiOqmgFYcjCVwkoQxlQAEfkESC6x+gFV/boq4jGmIliCMMYYE5L1YjLGGBOSJQhjjDEhWYIwxhgTkiUIY4wxIf0/u3qm9w8dC5gAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"ffXzoqjkt0vU","colab":{"base_uri":"https://localhost:8080/","height":280},"executionInfo":{"status":"ok","timestamp":1622452693996,"user_tz":-60,"elapsed":289,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"a4a6f67b-e455-4985-da99-bf7582429d82"},"source":["plt.figure()\n","plt.plot(accuracy_graphs[1e-6])\n","plt.ylabel('Validation accuracy. Noise 1e-6')\n","plt.xlabel('SGLD_step/50')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"fX3-wzXrt2l_","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1622452701516,"user_tz":-60,"elapsed":648,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"c558cf1e-528e-4383-f332-0ba744e92097"},"source":["plt.figure()\n","plt.plot(accuracy_graphs[1e-8])\n","plt.ylabel('Validation accuracy. Noise 1e-8')\n","plt.xlabel('SGLD_step/50')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAY4AAAEICAYAAABI7RO5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXiU5bn48e+djZCFANkICTsECCSKIqBYN1BQqLa2p+o5rbt0cal29Zxaba3taXu6WHvUlvbnWpeqrUdrVFxAaxWUTRJACGHPQlay75n798e8EydhkkxCJuv9ua65MvO8yzyv5srN89zPIqqKMcYY46+gga6AMcaYocUChzHGmB6xwGGMMaZHLHAYY4zpEQscxhhjesQChzHGmB4JCeTNRWQl8DsgGPizqv68w/EpwCNAPFAOfFlV85xj1wB3Oafep6qPd7j2ZWC6qs7vrh5xcXE6derUk3waY4wZWbZu3VqqqvEdywMWOEQkGHgQuBDIAzaLyMuqutvrtF8BT6jq4yJyAfDfwFdEZDxwD7AQUGCrc+1x596XAzX+1mXq1Kls2bKlT57LGGNGChE57Ks8kF1Vi4BcVT2gqk3As8BlHc5JA9Y77zd4HV8BvKmq5U6weBNYCSAiUcC3gPsCWHdjjDGdCGTgSAaOen3Oc8q87QAud95/HogWkdhurv0J8Gugrq8rbIwxpnsDnRz/DnCuiGwHzgXygdbOThaRU4EZqvpidzcWkTUiskVEtpSUlPRZhY0xZqQLZODIByZ5fU5xytqoaoGqXq6qC4AfOGUVXVx7JrBQRA4B/wJSReQdX1+uqmtVdaGqLoyPPyG3Y4wxppcCGTg2A7NEZJqIhAFXAi97nyAicSLiqcN/4h5hBbAOuEhExonIOOAiYJ2qPqyqE1V1KnA2kKOq5wXwGYwxxnQQsMChqi3ALbiDwCfAc6q6S0TuFZFLndPOA/aKSA6QCPzUubYcdy5js/O61ykzxhgzwGQkLKu+cOFCteG4xhjTMyKyVVUXdiwf6OS4McYMO4fLatmZXznQ1QgYCxzGGNOHWl3KDY9v4dZntg90VQImoEuOGGPMSPNKVgG5xTWIQH1TK6PDgge6Sn3OWhzGGNNHWl3K797eR2iwoAq5xX6vjDSkWOAwxpg+8vKOfA6U1HL78lQAcoqqB7hGgWGBwxhj+kBLq4sH3s5lzoRo1pwznbDgIHKKLXAYY4zpxEsfF3Cw1N3aCA0OYnp8JPuKrKvKGGOMDy2tLn6/fh9pSWNYMS8RgNTEaOuqMsYY49uL2/M5VFbH7ctnISIApCZGkXe8ntrGlgGuXd+zwGGMMSehudXF79fnMj95DBemJbaVz0yIBobnyCoLHMYYcxJe3JbPkfI6bl+W2tbaAHeLA4bnyCqbAGiMGfbqmlr427Z8WlpdJxw7a0YcsydEd3uPnfmVbD504lqrf37vIBkpMSybm9CufEpsJGEhQezrpsWRX1FPUVUDp00e120dOvOvfaWkTRzD+MiwXt+jJyxwGGOGvd+vz+Xhd/b7PBYRFsyj157B4umxnV7/bk4JNz2xhaaWEwOPCPz35entWhsAwUHCjPioblsc972ym40Hytj+wwtPuIc/KuubufqRD7ly0WR+9vn0Hl/fGxY4jDHDWllNI49/cIhV6Un89PPz2x2rqGvmhsc3c+2jm3n0ujNY4iN4vLO3mDVPbmVGfBR/uvp0oka1/7MZGhxE5Cjff0pTE6PYcuh4p3VzuZSNB8qoqGumqKqRCTHhPX6+XfmVuBRe33mMey+dR0hw4DMQluMwxgxra987QH1zK7cvn8XYiLB2r6lxkTyzZgnJ40Zz3aOb2bi/rN21G/YUs+aJrcxKiOLpGxeTMi7ihHt0FjTAPSQ3v6Kemk5GVu0tqqairhnofS4ky1mFt7y2iU0H+mfbIgscxphhq7SmkSc+OMxnMyYyK9F3HiMhOpxnblpCyrjRXPfYR3yQWwrA+j1FfPXJraROiOKpGxczrhf5g1kJ7gT5vk6Cgneg6m3gyM6vZMKYcKJGhZCZXdCre/SUBQ5jzLC19p8HaGxp5bZls7o8Lz56FM+sWcLk8RFc//hm7n8rh68+uZXZE6J56oYljI3oXdI51QlWnc0g33SgjEnjRxMbGdbrWebZeZWcNmUsy+cm8NrOYzT7GADQ1yxwGGOGpZLqRp7YeIhLT5nITOdf/l2JixrFMzctYWpsJPe/5Z4F/pcbFxMTEdrrOkwaH8GokCCfrQmXS/nwYDlnTo9lVmJUr9a1qqhr4kh5HfOTY1iVMZGKumY+6NDdFgiWHDfGDEt/fHc/TS2ublsb3mKjRvH0TUt4fstRrlw0mZjRvQ8a4B5ZNTMhihwfQ3I/OVZFZX0zS6bHEh4azIvb8lHVHo2s2plfBUBG8lgWTh1H9KgQMrMKODc1/qTq3R1rcRhjhp3i6gb+8uFhPndqMtPju29teBsfGcZXz51x0kHDIzUx2meOw5PfWDI9llmJ0VQ3tlBY2dCje2flVwAwP3kM4aHBXJiWyLpdRT6HDfclCxzGmGHnD+8coLlVubUHrY1AmZUYRWFlA1UNze3KNx0oZ0psBBPHjiY1oXezzHfmVzJ5fERbDmZVRhKV9c28v7+0byrfiYAGDhFZKSJ7RSRXRO70cXyKiLwtIlki8o6IpHgdu0ZE9jmva5yyCBHJFJE9IrJLRH4eyPobY4ae4qoGnnJaG9PiIge6OqQmnJggb3UpHx4s40xn3kh3SfTOZOVVkp4S0/b57FlxRIeHkJlVeLLV7lLAAoeIBAMPAhcDacBVIpLW4bRfAU+oagZwL/DfzrXjgXuAxcAi4B4R8czH/5WqzgEWAEtF5OJAPYMxZuh56J39tLiU25bNHOiqAN5B4dPWxCeFVVQ3tLRNOBwXGUZc1KgetTiO1zaRd7ye9ORPA8eokGAuSpvAul3HAtpdFcgWxyIgV1UPqGoT8CxwWYdz0oD1zvsNXsdXAG+qarmqHgfeBFaqap2qbgBw7rkNSMEYY4BjlQ08/dERLl+QzJTYgW9tAKSMG83o0GByvFoT3vkNj9RE30n0zmQ7E/8yvAIHwOqMJKobWvhXbsnJVLtLXQYOETlHRGY775eKyHdEZJWf904Gjnp9znPKvO0ALnfefx6IFpFYf64VkbHAZ4G3/ayPMWaYe/idXFwu5dYLBj634RHkjKza5zXcdtOBMqbFRbZbYiQ1MZrcompU1a/7egLHvA6BY+nMOMaEh/BKALurOg0cInI/8HPgSRH5CfA/wGjgDhH5nz76/u8A54rIduBcIB9o7e4iEQkBngEeUNUDnZyzRkS2iMiWkpLARV5jzOBQWFnPMx8d5QunpTA5NmKgq9POrMRPFztsaXXx0cHyE9bFmpUYRW1TK/kV9X7dMzuvkqmxESeM/goLCWLFvAm8uauIxpZu/5z2SlctjguBpcB5wC3AclX9Ce6chT95hXxgktfnFKesjaoWqOrlqroA+IFTVuHHtWuBfap6f2dfrqprVXWhqi6Mjw/smGZjzMB7aMN+XKrccsHgyG14S02Mpqiqkcr6ZnYXVlHd2MKS6eNPOAf8T5Bn51eSnjLW57FVGUlUN7bwXk5gRld1FThU3W0mT4bF035ydXOdx2ZglohME5Ew4ErgZe8TRCRORDz3+k/gEef9OuAiERnnJMUvcsoQkfuAGOB2P+pgjBkBCirq+evmo/zbwhQmjR9crQ34dFOnfUXVbfmNMzu0ODyjr/xJkJfVNJJfUU968hifx5fOjCNmdCiZ2YHpruoqAGSKyHvAe8CfgedE5AfAa8A/u7uxqrbgbqmsAz4BnlPVXSJyr4hc6px2HrBXRHKAROCnzrXlwE9wB5/NwL2qWu4M1/0B7qT6NhH5WERu7OlDG2OGlwc35KIoN58/+FobALPagkINmw6UMT0+koQx7ZdQj4kIJSF6VLskemc8+Y30ZN8tjtDgIFbOm8Cbu4toaO777qpOlxxR1e+LyJnut7pJRGbgTmD/GXjBn5ur6qvAqx3K7vZ6/0Jn91LVR/i0BeIpywN6vtOJMWbYyjtex3NbjvKlhZNIGTf4WhsAyWNHExEWzCeFVWw+dJzLTp3o87zUxOh2SfTOZOd5EuO+WxwA/7YwhcQxo2hqdREeGty7ineiy7WqVHWj1/v9IrJHVV/p0xoYY8xJeHDDfgQZtK0NcI+smpUQRWZ2ITWNLT43jAJ3gvzZj47icilBQZ3/Gzk7v5LpcZGMCe98WZSFU8ezcOr4To+fjJ7O47g3ILUwxpheOFpex/NbjnLFGZOYOHb0QFenS7MSoymvbQLoNHCkJkZT39z9yCp3Yjymy3MCqaeBw7qJjDGDxoMbcgkS4RvnzxjoqnTLkyCfmRBFfPSoLs/pKkFeUt1IYWVDuxnj/a2ngeOrAamFMcb00NHyOl7YmsdViyaRFDO4WxtA2w6EHUdTeZvplUTvzM62xPjABY5u9+MQkQjg28BkVb1JRGYBsy3XYYwZSG/uLqLFpdx0zvSBropfTkkZS3z0KC5On9DpOTGjQ5kwJrzTrWbBvbChyIkzxvuTPxs5PQpsBc50PucDzwMWOIwxA6agop7RocEkD/Lchsf4yDA2/2B5t+d1txugJzEeNWrg9uHzp6tqhqr+EmgGUNU6LNdhjBlghZUNJMWE92jHvKEgNTGa3OIaXC7fa1Zl51eQ0cmM8f7iT+BoEpHRODPHnfkcjQGtlTHGdKOgsp6kseHdnzjEpCZG0dDs4ujxuhOOFVc1UFTVyPwB7KYC/wLHPcDrwCQReQr3arTfC2itjDGmG8cqG4ZEUrynPEl0XwnytqXUB3AoLviR41DVN0VkG7AEdxfVN1U1sPsSGmNMF1paXRRVubuqhptZXtvIXpiW2FauqvxjRwFBAmlJnc8Y7w9+ZVdUtQzI9HwWkTmquidgtTLGmC4UVzfiUoZliyM6PJSJMe1HVrlcyt0v7+T/Pi7gG+fNIHIAE+PQ+x0A3+jTWhhjTA8UVjYADMscB7i7qzxdVS6X8sOXdvKXTUf46rnT+e6K2QNcuy5aHCLyQGeHgIFN6RtjRrTCSveSHMOxqwrcCfJNB8pobnVx90u7eOajI3z9vBl8b8XsQTGKrKv2znW4J/75GkF1VWCqY4wx3SuscFocw7CrCtwtjsYWF199civr9xRz8/kz+M5FgyNoQNeBYzOwU1U/6HhARH4UsBoZY0w3CisbiAwLZkz4wPb1B4pnN8D1e4q59YKZfOvC1EETNKDrwPFFoMHXAVWdFpjqGGNM9wor65kwDCf/ecxOjGZiTDhXnDGZ25bNHHTP2dVGTuX9WRFjjPFXQWXDoF9G/WSMDgvm/TsvGHQBw6O3o6qMMWbAHKusH7aJcY/BGjTAAocxZohpbnVRXN3IhGGaGB8K/A4czvLqxhgzoIqqGlCFicO8xTGYdRs4ROQsEdkN7HE+nyIiDwW8ZsYY48Oxtsl/1uIYKP60OH4LrADKAFR1B3BOICtljDGdKfAEDmtxDBi/uqpU9WiHolZ/rhORlSKyV0RyReROH8eniMjbIpIlIu+ISIrXsWtEZJ/zusar/HQRyXbu+YAM5gySMabPFVYM71njQ4E/geOoiJwFqIiEish3gE+6u0hEgoEHgYuBNOAqEUnrcNqvgCdUNQO4F/hv59rxuJdzXwwsAu4RkXHONQ8DNwGznNdKP57BGDNMFFY2ED0qhOjw0IGuyojlT+D4GnAzkIx729hTnc/dWQTkquoBVW0CngUu63BOGrDeeb/B6/gK4E1VLVfV48CbwEoRSQLGqOomVVXgCeBzftTFGDNMeCb/mYHTbeBQ1VJV/Q9VTVTVBFX9srPMeneSAe8urjynzNsO4HLn/eeBaBGJ7eLaZOd9V/cEQETWiMgWEdlSUlLiR3WNMQPtWGUDL+8o6PKcwsoGS4wPMH9GVf1SRMY43VRvi0iJiHy5j77/O8C5IrIdOBd3i8av/El3VHWtqi5U1YXx8fF9cUtjTIDd9X/Z3PbMdkqqO9+duqCigaQx1uIYSP50VV2kqlXAauAQMBP4rh/X5QOTvD6nOGVtVLVAVS9X1QXAD5yyii6uzXfed3pPY8zQlJVXwVufFAOw09kitaOmFhelNY3Ddh+OocKfwOFZz2oV8Lyq+v4/eqLNwCwRmSYiYcCVwMveJ4hInIh46vCfwCPO+3XARSIyzkmKXwSsU9VCoEpEljijqa4GXvKzPsaYQez+t/YRMzoUEcjK8/1npqjKPRR3os0aH1D+BI5XRGQPcDrwtojE08mqud5UtQW4BXcQ+AR4TlV3ici9InKpc9p5wF4RyQESgZ8615YDP8EdfDYD93otuvgN4M9ALrAfeM2fBzXGDF4fH61g/Z5i1pwznRnxUWR30uIocIbiWnJ8YHW7mL2q3ikivwQqVbVVRGo5cXRUZ9e+Crzaoexur/cvAC90cu0jfNoC8S7fAsz35/uNMUPD/W/lMC4ilGvOmkpucQ0f7C/1ed4xT4vDuqoGVFdbx16gqutF5HKvMu9T/h7IihljRoZtR47zzt4SvrdyNlGjQkhPjuHF7fkUVzWQ0CEJXuDs/GcLHA6srloc5+KeY/FZH8cUCxzGmD5w/1v7GB8ZxjVnTgUgIyUGgOz8SpZ1CByFlfVEh4cQNWp47vw3VHS1kdM9zs/r+q86xpiRZOvhcv6ZU8KdF88h0gkGaRPHEOQkyJfNTWx3fmFlgyXGBwF/5nHEiMhvPJPpROTXIhLTH5Uzxgxvv31zH7GRYVx95pS2soiwEGYmRPkckltYWW9DcQcBf0ZVPQJUA19yXlXAo4GslDFm+Nt8qJx/5Zby1XOnExHWvvNjfnIMWb4CR0WDLW44CPgTOGao6j3OmlMHVPXHwPRAV8yYoe6VrAL2l9T0+vqS6kae33IUl0v7sFY909Lq4q+bj3Q5k7s3XC7lN2/kEBcVxpeXTDnheEZyDCXVjW3zNgAamlspq20iybqqBpw/gaNeRM72fBCRpUB94KpkzNBXXNXArc9s5zvP78C9HmfPFFU1cMUfN/LdF7J4d9/ArbX29+35fP9v2Vzxx43t/oifDJdL+cH/7WTjgTJuWzbrhNYGQLqTIPeeCOj5fmtxDDx/AsfXgQdF5JCIHAb+F/eKucaYTry28xiqsP1IBe/m9OwP/7HKBq5cu4miqgYiw4J5NaswQLXsWnOri/9dn8vU2AiKqtx18uy+11sul/JfL2bzzEdH+MZ5M/iKj9YGQFpSDEEC2XkVbWWeobjW4hh4/qyO+7GqngJkAOmqusDZBdAY04nMrEJmJkSRPHY0v31rn9+tjsLKeq5cu5HiqgYev34RK+ZPYN2uYzS1uAJc4xO9uC2fI+V1/HB1Gk/csIiS6kauXLuRwsredTi4XMqdf8/i2c1HueX8mXx3xeyOc8PajA4LZlZCdLsZ5MeqnA2cLDk+4DoNHCJytfcL974Xn/P6bIzx4VhlA5sPl3PpKRO5+fyZ7DhawTt7u291FFTUc+XaTZTWNPHEDYtYOHU8qzOSqGpo4f1c3zOpA6W51cXvN+zjlJQYLpiTwOlTxvP49YsorWniyrWbehw8XC7l+3/L4rktedx2wUy+fVFqp0HDIz0lhuz8yrag+2mLwwLHQOuqxXFGJ6+f4GMpEGOM22s7C1GFS9KT+OLpKaSMG81v38rpstWR7wSNcidonD5lPABnz4wnOjyEV/q5u+pvW/M4Wl7P7cs//QN/+pRxPHHDIsqd4OFZN6o7rS7le3/L4vmtedy+fBbfuqjzloa3jJQYSmua2pYZKaysJ2Z0qM+ciOlfnQYOVb3V8wJuAz7EvSjhJuC0/qmeMUNPZlYhcyZEMzMhirCQIG69YCZZeZWs31Ps83x30NjI8Vp30Dht8ri2Y2EhQayYN4E3dh+jsaVPtqrpVlOLi9+vz+XUSWM5b3b7vWxOmzyOJ29cTHltE1es3Uh+N8Gj1aV894UdvLA1jzuWp3L78lS/6zE/uX2C3IbiDh5d5jhEJEREbsS9uu1y4IuqeoWqZvVL7YwZYgor69ly+DirM5Layi4/LYXJ4yO430eu42h5HVf8cSMVdc08eeNiFngFDY9VGUlUN7Twr3390131wtY88ivquX35LJ8tg1MnjeUvNyymoq6ZK9duJO94nc/7tLqUbz/3MX/fls+3L0zlm8tn9ageaUljCA6StomAhZUNTLSd/waFrnIcNwO7cS+nvlJVr1XVvf1WM2OGoFezjwHubiqP0OAgbrlgJtn5lW0bFYE7aFy5dhNV9c08deNiTp001uc9l86II2Z0KJn90F3V1OLiwQ25LJg8lnNTO98585RJY3nqxsVU1jVzxR83cbS8ffBoaXXxrec+5v8+LuC7K2Zz67KeBQ2A8NBgZiVEfdrisL3GB42uWhy/B8YAZwMvi0iW88oWEWtxGONDZlYBaUljmB4f1a788gXJTImN4H4n1+EJGjWNLTx14xIyUnwHDfB0VyXy5u4iGpoD21313Jaj5FfUc8fy7pPXGSljefqmJdQ0tnDl2k+DR0urizue28FLHxfwvZWzufn8mb2uT4aTIK9vauV4XTMTLXAMCl0FjmnAYtxbxn7W6+X5bIzxkl9Rz7YjFazy6qbyCAkO4tYLZrGroIr/96+DXPHHjU7QWNw22a0rqzImUt3YwnsB7K5qbGnlwQ25nD5lHJ+ZFefXNfOTY3jqxsXUNrVwxR83cqCkhm/+9WP+saOAOy+ewzfO633QAEhPjqG8toltR44Dtpz6YNHV6riH+7Mixgx1r2W7u5JWpZ8YOAA+d+pEHtyQy32ZnzA2IpSnb1rMvIn+rRd61oxYxkaEkplVwIVpid1f0IWmFhd/eHc/tY0t7cqPHq+jsLKB//niKX6NevLwBI//+POHrLj/nzS3Kv91yRzWnDPjpOoJkO60xN7Y5e4CtBbH4GDj2ozpI69kFTI/eQxT4yJ9Hg8JDuK/LpnL/6zbw/1XLCBt4hi/7x0aHMTKeRP4x44CGppbCQ8N7nU9Nx0o4zdv5hAWEkRQh/iwfG4iS2fG9vie8ybG8PSNS7j1mW38x+IpXH/2tF7Xz9ucCdGEBAlv7C4CIMmS44OCBQ5j+sDR8jo+PlrB91fO6fK8C9MSe91iWJWRxLObj/JuTgkr5k3o1T0AcoqqAdh45wXERo3q9X06Sps4hre/fV6f3Q/cCfLUxGh2F1YBMGGMtTgGA3/WqjLGdOO1nV13U/WFM6fHMi7i5EdX5RRVExsZ1qdBI5A8OwKOiwhldFjvW1qm7/QqcIjIj/q4HsYMaZlZhWSkxDA5NiJg3xESHMTK+Um89cnJja7KKaphVmJU9ycOEp6JgLa44eDhzw6At4pIx1lJW/25uYisFJG9IpIrInf6OD5ZRDaIyHZnqO8lTnmYiDzqDP3dISLneV1zlWdIsIi8LiL+Df8wpg80t7qoaWxp99pXVM2OvMqAtjY8VmckUdfUyjt7fc9C746qkltcQ2pidB/XLHA8LQ6bNT54+JPjSAQ2i8g23GtUrVPVf3R3kYgEAw8CFwJ5zj1eVtXdXqfdBTynqg+LSBrwKjAVuAlAVdNFJAF4TUTOwB3ofgekqWqpiPwSuAX4kV9Pa4aE25/dTqvC769aMNBVaaeironlv3mX0pomn8cv6YfAsXjaeGIjw3hhaz4r5/f8+woqG6hpbGHWEAocsydEExYSRMo4a3EMFt0GDlW9S0R+CFwEXAf8r4g8B/w/Vd3fxaWLgFxVPQAgIs8Cl+Gejd52e9yTDAFigALnfRqw3vn+YhGpABYC2wEBIkWkzLk2158HNUODqrJ+TzG1Ta3ce+k8xkWGDXSV2vz5vYOU1TbxrQtTGd1hVNOk8aOZND5w3VQeIcFB/MeSKTzw9j52FVT6PZzXw5MYT00YOl1Vo0KCeeL6RUyN9T1azfQ/v0ZVqaqKyDHgGNACjANeEJE3VfV7nVyWDBz1+pyHe0Khtx8Bb4jIrUAk7vWwAHYAl4rIM8Ak3MueTFLVj0Tk60A2UAvsA2729eUisgZYAzB58mR/HtMMAkfK66hqcM8vWLfrGFcuGhz/747XNvHo+we5JD2J23qxfEZfumHpNB59/yAPvL2PP35lYY+u3ecJHEOoxQGwZHrPhwibwPEnx/FNEdkK/BJ4H/dmTl/H/cf8Cyf5/VcBj6lqCnAJ8KSIBOHuEssDtgD3Ax8ArSISintHwgXARCAL+E9fN1bVtaq6UFUXxsd3vuaOGVw86xKNDg0mM3tgdr7z5U/vHaCuuZVvDnDQAIiJCOX6pdNYt6uIXQWV3V/gJaeohrioUYOqJWeGHn9GVY0HLlfVFar6vKo2A6iqC/fyI53Jx91a8EhxyrzdADzn3G8jEA7EqWqLqt6hqqeq6mXAWCAHONU5d7+6lxl9DjjLj2cwQ8TO/ErCgoP48pLJfLC/jLKaxoGuEuW1TTz+wSFWpScNmn+pX3/2NKLDQ7j/rX09um5fUTWpQ2hElRmc/AkcrwHlng8iMkZEFgOo6iddXLcZmCUi00QkDLgSeLnDOUeAZc595+IOHCUiEiEikU75hUCLk1TPB9JExNOEuBD3ku9mmMjKq2ROUjSfW5BMq0tZt6tooKvE2n8OntaGR8zoUG48ezpv7i5qW3a8Oy6Xsm+Ijagyg5M/geNhoMbrc41T1iVVbcE94mkd7j/uz6nqLhG5V0QudU77NnCTiOwAngGudVoSCcA2EfkE+D7wFeeeBcCPgX86K/SeCvzMj2cwQ4DLpewsqCQ9OYa0pDFMi4skM7ug+wsDqKymkSc2HuKzGRMH3Uik686eypjwEO5/K8ev8/Mr6qlrah1SczjM4ORPclzUa/cZVXWJiL9J9VdxD7H1Lrvb6/1uYKmP6w4Bszu55x+AP/jz/WZoOVxeR3VDCxkpMYgIq9KTeOidXEprGokboFnOa/95gIbm1gFPiPsyJjyUmz4znV+/mUNWXkWXS7MD7CsemolxM/j40+I4ICK3iUio8/omcCDQFTMjT1ZeBfDpTOFVGUm4FF7feWxA6lNa08gTGw9z6SkTmTlIh69eu3QqYyNC/cp15BS5Ow5SEyxwmJPjT+D4Gu4EdErRjUEAACAASURBVD6fDqldE8hKmZFpZ34lYSFBbf8injMhmunxkf2y850vf3x3P40tg7O14RHttDrW7ynm46MVXZ6bU1RNQvQoYiJC+6l2ZrjqNnCoarGqXqmqCaqaqKr/rqq9W+/AmC5k5VUyN2kMocHuX0sRYXV6Eh8eLKOkun9HVxVXN/DkpsN87tTkE3bzG2yuOWsq4yJCu8117CuyxLjpG/7M4wgXkZtF5CERecTz6o/KmZHD5VJ2FVSRkdx+JvSqjInu7qpd/ddd1dzq4q4Xd9Lcqr3aK7u/RY0K4aZzpvPO3pJO53W4XO41qiwxbvqCP11VTwITgBXAu7jnY1QHslJm5DlYVktNY8sJ26imJkYxMyGKzKz+GV3V3Ori1qe388buIv7rkrlM62RTpsHmqjMmExIk/GOH7269vOP11De3WovD9Al/AsdMVf0hUKuqjwOrOHHpEGNOimcuQnqHFodndNWHB8sprm4IaB2aWlzc8vQ2Xt91jLtXp3FDH+1i1x/GRYaxdGYcmdkFeA2CbNO2RpW1OEwf8CdwNDs/K0RkPu7FCBMCVyUzEmXlVTIqJIhZPkYvrcpIQgM8uqqpxcXNT29j3a4ifvTZtD7b+rQ/rcpI4mh5Pdk+JgTmOENxZ9qIKtMH/Akca539OO7CPfN7N/CLgNbKjDjZeZXMmziGkOATfyVTE6NJTYzilQCNrmpsaeUbT23lzd1F3HvZPK5dOvSCBsCKtAmEBovPUWj7imqYMCacmNE2osqcvC4n8jkLDlap6nHgn8D0fqmVGVFaXcqugkq+eHpKp+esSp/I/W/ncNf/ZRMk0u7Ykumxvd4Lo7GllW/8ZRtv7ynmJ5fN4ytnTu3VfQaDmIhQzp4ZxytZhdx58RzE679TTlG1JcZNn+kycDizxL+HsxChMYFwsLSG2qZW0ruY+Xz5ack8t+XoCf+arm9u5cXt+Sybm8CokJ7tR93Q3MrX/7KVDXtLuO9z8/nykim9qv9gsipjIhue38GOvEpOneT+79nqjKgaDs9nBgd/lg55S0S+A/wV9x4YAKhqeeeXGOO/7E4S494mjY/g/TsvOKF8w95irnt0M//aV8qyuYl+f2dDcytf+8tW3tlbws8+n86/Lx4c+36crAvTEp3uqoK2wHG0vI7GFpclxk2f8SfHcQXuzZL+iXuv8a2498kwpk9k5VUyOjSYGfE9H/q6dEYcMaNDezS7vKG5lTVPuoPGzy8fPkED3KvmnjMrnsyswrbRVZ4RVYNtkUYzdPkzc3yaj5flOkyf2ZnfeWK8O2EhQayYl8ibu4toaG7t9vyG5lZuemIL7+0r4ZdfyBg0Owz2pVUZSRRUNrDdWYJkX7F7jSpfI9aM6Q1/Zo5f7evVH5Uzw1+rS9mZX9W2sGFvrMqYSHVjC+/tK+3yvPqmVm58fAv/yi3lF1/I4EtnTOry/KFqeVoiYcFBba2wnKJqJsaEEx1uI6pM3/Dnn3hneL0+g3uf8Eu7usAYf+0vqaG+uZWMlN4HjrNmxDI2IrTb2eX3vLyT9/eX8j9fPIUvLRyeQQPcy62fkxrPq9mFuFxKTlGNdVOZPtVtclxVb/X+LCJjgWcDViMzomTndZ8Y705ocBAr503gHzsKaGhuJTz0xNFVB0pqeGFrHtcvndblsN/hYnVGEm99UsSWw8fZX1LD2TNjB7pKZhjpeaeye2TV0JwhZQad7PxKIsKCT3oF2lUZSdQ2tfJuTonP479fn0tYSBBfO3fGSX3PULFsbgJhIUE89E4uTS0ua3GYPtVti0NE/gF4Fr8JAtKweR2mj2TnVzJ/YgzBQdL9yV04c3os4yLco6tWzJvQ7tj+khpe+jifGz8znfjogdlJsL9Fh4dyXmo8b+x279luixuavuTPPI5feb1vAQ6ral6A6mNGkJZWF7sKKvn3RSc/MS0kOIiV85N46eP8E7qrHnh7H6NCgllzzsgaDLgqI6ktcNiIKtOX/OmqOgJ8qKrvqur7QJmITA1orcyIkFtSQ0Oz66QS495WZyRR19TKO3s/3Wcst7ial3cUcPVZUwZs3/KBsnxuIqNCgkgeO5rIUf78G9EY//gTOJ4HXF6fW50yY07K81vyCA4Szpg2vk/ut3jaeGIjw9othnj/W/sYHRrMV88ZGbkNb5GjQrj+7Gl8fkHyQFfFDDP+BI4QVW3yfHDeh/lzcxFZKSJ7RSRXRO70cXyyiGwQke0ikiUilzjlYSLyqIhki8gOETnP65owEVkrIjkiskdEvuBPXczgUlzVwF82HebzC5JJHju6T+7p7q6awNufFFPf1EpOUTWZ2YVcc9ZUxkf69Ss77Hx/5Ry+s2L2QFfDDDP+BI4SEWmbtyEilwFdz7RynxcMPAhcjDuhfpWIpHU47S7gOVVdAFwJPOSU3wSgqunAhcCvnZV6AX4AFKtqqnPfd/14BjPIPPzuflpcyq0XzOzT+67KSKK+uZUNe4v53Vv7iAgNZs1nRlZuw5hA86fj82vAUyLyv87nPMCfmeOLgFxVPQAgIs8Cl+Hez8NDgTHO+xjAM4MrDVgPoKrFIlIBLAQ+Aq4H5jjHXPgRxMzgUlTVwFMfHuELpyUzJbZvt2ZdPC2WuKgwHnonl535Vdx8/gzGjdDWhjGB4s9aVftVdQnuP+ZpqnqWqub6ce9k4KjX5zynzNuPgC+LSB7wKuCZbLgDuFREQkRkGnA6MMmZfAjwExHZJiLPi4j/S6KaftHS6ury+MPv7MflUm69YFaff3dwkHDx/CR25lcRNSqEm6y1YUyf82etqp+JyFhVrVHVGhEZJyL39dH3XwU8pqopwCXAk06X1CO4A80W4H7gA9xJ+RAgBfhAVU8DNtJ+uLB3vdeIyBYR2VJS4ntSmOl77+aUkP6jNzpdrfZYZQNPf3SEL56ewqTxEQGpw+oM96ZO1y+dytgIa20Y09f8yXFcrKoVng/OboCX+HFdPuC9IFCKU+btBpzJhKq6EQgH4lS1RVXvUNVTVfUyYCyQA5QBdcDfneufB07z9eWqulZVF6rqwvj4eD+qa/rC6zsLqW9u5bZnt/OKj7WjHnonF5dLufn8vs1teFs0bTyPXncGN/dx/sQY4+ZP4AgWkbYB8CIyGvBnQPxmYJaITBORMNzJ75c7nHMEWObcdy7uwFEiIhEiEumUXwi0qOpudW8w8A/gPOf6ZbTPmZgBtulAOWfNiOW0yWP55rMf8/KOT4NHQUU9z350lH9bGLjWBoCIcP7snu8IaIzxjz/J8aeAt0XkUefzdcDj3V2kqi0icguwDggGHlHVXSJyL7BFVV8Gvg38SUTuwJ0ov1ZVVUQSgHUi4sLdSvmK162/j7tL636gxKmPGQSOVTZwsLSW/1g8masWTea6xzZz+7PbUVUuOzWZh97JRQlsa8MYE3j+rI77CxHJwmkZAD9R1XX+3FxVX8Wd9PYuu9vr/W5gqY/rDgE+B5+r6mHgHH++3/SvTQfKAFgyPZbIUSE8dt0ZXP/YZu7468cUVjbw181H+beFk0gZF7jWhjEm8PxaHVdVX1PV7zgvv4KGGT7yK+rbRkJ1ZeP+MsaEhzA3yT3COiIshEeuPYPF02L5+Wt7AKy1Ycww4M+oqiUisllEakSkSURaRaSqPypnBofnNh/lF6/vYeuR412et+lgGYunx7Zb6dYTPC49ZSK3L0/ts1nixpiB40+O439xJ7afxz0J72ogNZCVMoPLvuJqADKzCjljqu91pQoq6jlcVsfVZ0494djosGAeuGpBIKtojOlH/nZV5QLBqtqqqo8CKwNbLTOY5BTVAPBqdiGtnXRXefIbZ063neaMGe78CRx1znDaj0Xkl84IqN7sHGiGoKYWF4dKa5keF0lxdSNbDpX7PG/j/jLGRoQyZ4JtGGTMcOdPAPiKc94tuLeNnQTYirRDnKrS2NLa7XkHS2tpcSk3nTOd8NAgMrN9zwjfdLCMxdPGE3SSO/kZYwY/f9aqOqyqDapapao/VtVv+blWlRnE/vLhEZb+fANNLV2vK5VT5M5vnJIylgvmJPBq9rETuqvyjtdxtLyeJdZNZcyIYF1OI9T2I8cprWlsCwyd2VdUTZDA9PhIVqVPpLSmkY8Otu+u2nTA/fnMGRY4jBkJLHCMUIdKawHIyqvs8rycohqmxkYSHhrM+XPiGR0aTGZ2+zWoNu4vY1xEKKkJlt8wZiSwwDFCHSqrAyA7v5vAUVzNrMQowD0n44K5Cby+81i7pdM3HShj8bRYy28YM0L4MwEwVUT+JCJviMh6z6s/KmcCo7K+mfJa927A2fkVnZ7X2NLK4bI6UhM/bUmsTk+itKaprbvqaHkd+RX11k1lzAjizwTA54E/AH/CvSeGGeIOl7m7qWbER7L3WDWNLa0+V5I9UFJLq0uZ5RU4zpudQERYMK9kF3LWzDg2eq1PZYwZGfzpqmpR1YdV9SNV3ep5BbxmJmAOOvmNz54ykeZWZe8x3wlyT+I81emqAvcs8GVzE9u6qzbtL2N8ZFi7c4wxw5s/geMfIvINEUkSkfGeV8BrZgLmUGkdIrA6YyLQeYJ8X1ENwUHCtLj2+4KvSk+ivLaJjQfK2HSgjCXTxyNi+Q1jRgp/uqqucX5+16tMAdvMeYg6VFbLxJjRzIiPZGxEKDs7SZDnFFUzNTbihG6s82bHExkWzMPv7KegsoGvWzeVMSOKP/txTOuPipj+c7C0lqlxEYgI6ckxnbc4imt8LiESHhrM8rREXvrYPSzX8hvGjCz+jKoKFZHbROQF53WLiIT2R+VMYBwqq2VKrLv7KT05hpyiahqa2497aGhu5XBZbbvEuDdPN1dcVBgzEyy/YcxI4k+O42HgdOAh53W6U2aGoIq6JirqmpnmBI6MlBhaXMqeDgny/SU1uJROk96fmRVHdHgIZ82Is/yGMSOMPzmOM1T1FK/P60VkR6AqZALLM/FvqpPwTk8ZC0B2XgWnThrbdt4+Zyn11E5aHOGhwbzwtbMYHxkWyOoaYwYhfwJHq4jMUNX9ACIyHZvPMWR5lhqZFufe93tiTDjjI8NOmEGeU1RNSJAwNTbyhHt4zLYl1I0ZkfwJHN8FNojIAUCAKcB1Aa2VCZiDpbUECUwa7w4cnSXIc4pqmBYXSViIrUpjjGnPn2XV3wZmAbcBtwKzVXWDPzcXkZUisldEckXkTh/HJ4vIBhHZLiJZInKJUx4mIo+KSLaI7BCR83xc+7KI7PSnHuZTh8pqmTh2dLshtunJMewrrmmXIN9XXN1pN5UxZmTrNHCIyAXOz8uBVcBM57XKKeuSiAQDDwIXA2nAVSKS1uG0u4DnVHUB7n3NH3LKbwJQ1XTgQuDXItJWV+f7a/x5QNPeodLaEyb0pafE0OpSdhdWAVDf1MqR8rq2xQ2NMcZbVy2Oc52fn/XxWu3HvRcBuap6QFWbgGeByzqco8AY530M4FmvOw1YD6CqxUAFsBBARKKAbwH3+VEH40VVOVhay5TYiHblGSkxAGQ73VX7S2pQ7TwxbowZ2TrNcajqPc7be1X1oPcxEfFnUmAycNTrcx6wuMM5PwLeEJFbgUhguVO+A7hURJ7BvVXt6c7Pj4CfAL8G6vyog/FyvK6ZqoaWExLeE8aEExf1aYLc1xpVxhjj4U/m828+yl7oo++/CnhMVVOAS4AnnS6pR3AHmi3A/cAHuEd3nQrMUNUXu7uxiKwRkS0isqWkpKSPqju0HSrzjKhqHzg8CXJPiyOnqIbQYGmbJGiMMd46bXGIyBxgHhDTIacxBgj34975uFsJHilOmbcbgJUAqrpRRMKBOKd76g6vunwA5ODuPlsoIoecuieIyDuqel7HL1fVtcBagIULF2rH4yORZyju1LgTA0J6cgzv5pRQ19TCvqJqpsdFERpsI6qMMSfqajjubNy5jLG48xoe1TjJ625sBmY53Vr5uJPf/97hnCPAMuAxEZmLOyCViEgEIKpaKyIX4l7afTewG2fWuohMBV7xFTSMb4c8Q3HHRZxwLD1lLC6FTwqryCmu5pSUsT7uYIwxXec4XgJeEpEzVXVjT2+sqi0icguwDggGHlHVXSJyL7BFVV8Gvg38SUTuwJ0ov1ZVVUQSgHUi4sIddL7S80czHR0sqyNlXITPuRmeBPmHB8s5Wl7Pv50+6YRzjDEG/JsAuF1EbsbdbdXWRaWq13d3oaq+Crzaoexur/e7gaU+rjuEu8XT1b0PAfO7q4P51KHSWp/dVACJY8KJjx7Fi9vcvYmWGDfGdMafTuwngQnACuBd3LkK31vGmUFLVd2BI/bEbiqPDGciINDpqrjGGONP4Jipqj8EalX1cdyTATsOqzWDXHltE9WNJw7F9TY/2d1dFRYcxJTxnQcYY8zI5k/gaHZ+VojIfNwT9RICVyUTCJ0NxfXmyXNMj48kxEZUGWM64U+OY62IjAN+CLwMRAF3d32JGWwOlrZfTt2XdKfFYTPGjTFd8Wfr2D87b9/F9hkfsg6V1hIcJKSMG93pOQljwvnSwhRWzJvQjzUzxgw1XU0A/FZXF6rqb/q+OiZQDpbVMmnc6G4n9f3yi6d0edwYY7pqcXj6K2YDZ+DupgL3ZMCPAlkp0/cOldbaEiLGmD7R1QTAHwOIyD+B01S12vn8IyCzX2pn+oRnKO4ZU8cPdFWMMcOAP0NnEoEmr89NTpnppYbmVmobW/rt+0prmqhtau1yDocxxvjLn1FVTwAfiYhnRdrPAY8FrEYjwG3PbKeoqoGXbjm7X77PMxS3qxFVxhjjL39GVf1URF4DPuMUXaeq2wNbreHreG0T6/cU0+JScourmZkQ+KGvB0u7n8NhjDH+6mrr2DHOz/HAIdxLjzwJHHbKTC+8sfsYLS73Ku+ZWcf65TsPldYSEiQkj+18KK4xxvirqxzH087Prbg3VPK8PJ9NL7ySVciU2AgWTR1PZnZB9xf0gUNltUweH2GzwY0xfaLTvySqutr5OU1Vp3u9pqmqTQTshfLaJj7YX8aq9CRWZSSRU1TDvqLArxd5sLTuhH3GjTGmt7rqqjqtq1d/VnK4WLfrGK0uZVVGEhfPn4AIZGYXBvQ7VZXDZZ0vp26MMT3VVXL8110cU+CCPq7LsJeZVci0uEjSksYgIu7uqqxCbl+eGrDv/PhoBXVNrW3rUBljzMnqagLg+f1ZkeGurKaRD/aX8o3zZiIiAKzOSOKHL+0ip6g6YAsLZmYVEhYcxLK5NvXGGNM3/MqWish8EfmSiFzteQW6YsPN67uO4VJYlZHUVrZi/gSCxJ0wDwSXS3k1u5BzUuOIGR0akO8wxow83QYOEbkH+L3zOh/4JXBpgOs17GRmFTI9PpI5Ez5tWSREh7N4WiyZWQWoap9/5/ajFRRUNrQLVsYYc7L8aXF8EVgGHFPV64BTcG/mZPxUUt3IpgNlrE5Pauum8liVkcT+klr2BmB0VWZWIWEhQSy3bipjTB/yJ3DUq6oLaHEmBRYDkwJbreHl026qiSccW+l0V2X2cXeVp5vq3NR4osOtm8oY03f8CRxbRGQs8Cfck/+2ARv9ubmIrBSRvSKSKyJ3+jg+WUQ2iMh2EckSkUuc8jAReVREskVkh4ic55RHiEimiOwRkV0i8nN/H3QgZWYVMDMhitTEqBOOxUWN4swZsWRmFfZpd9W2I8c5VtXAauumMsb0sa7mcTwoIktV9RuqWqGqfwAuBK5xuqy6JCLBwIPAxUAacJWIpHU47S7gOVVdAFwJPOSU3wSgqunOd/5aRDx1/ZWqzgEWAEtF5GJ/H3YgFFc38OHBclb56KbyWJU+kQOltXxS2HfdVa843VQ2msoY09e6anHkAL8SkUMi8ksRWaCqh1Q1y897LwJyVfWAqjYBzwKXdThHgTHO+xjAswZHGrAeQFWLgQpgoarWqeoGp7wJd+snxc/6DIjXdx5DO4ym6mjFvESCg6TPliDxdFOdPzueqFH+LIBsjDH+62rJkd+p6pnAuUAZ8IjTRXSPiPgzYy0ZOOr1Oc8p8/Yj4Msikge8CtzqlO8ALhWREBGZBpxOh7yK0332WeBtP+rSK33RdfRKViGpiVFdztOIjRrFWX3YXbX5UDnF1Y0+cyrGGHOy/FlW/TDwC+AXIrIAeAS4Gwjug++/CnhMVX8tImcCT4rIfOc75uJeTPEw8AHQ6rlIREKAZ4AHVPWArxuLyBpgDcDkyZN7XDGXS7nrpZ1Mj4vkxs90vTSXqvL//nWQD/aXnVC++VA5ty/rPs6uSk/izr9ns6ugivknOcs7M7uQ8NAgls1JOKn7GGOML/7M4wgRkc+KyFPAa8Be4HI/7p1P+1ZCilPm7QbgOQBV3QiEA3Gq2qKqd6jqqap6GTAWd9eZx1pgn6re39mXq+paVV2oqgvj4+P9qG57LlWO1zZxX+Yn/Pk9n7HJ8z38/PU93Jf5CUfK6yipbmx7ldY0sXDKOL64sPvetBXzJjjdVSc3uqrVpbyafYwL5iQQad1UxpgA6PQvi4hciLtFcAnwEe4cxRpVrfXz3puBWU5XUz7u5Pe/dzjnCO45Io+JyFzcgaNERCIAUdVapx4tqrrbqdd9uPMhN/pZj14JCQ7igasW8M1nt3Nf5ie4VFlzzox256gqP3v1E/703kGuPnMKP750XqcJ8O6Miwxj6cw4MrMK+d6K2b2+z0cHyymtaWRVunVTGWMCo6sWx3/i7iKaq6qXqurTPQgaqGoLcAuwDvgE9+ipXSJyr4h4Zp5/G7hJRHbg7nq6Vt2d/AnANhH5BPg+8BUAEUkBfoA7eb5NRD4WkYAFkNDgIH535QJWZSTxs1f38Id393s/H/dluoPGtWdNPamg4bE6PYkj5XXszK/q9T0yswsYHRrM+XN63soyxhh/dLXI4Umvfquqr+JOenuX3e31fjew1Md1h4DZPsrzgJP769xDocFB/O6KUwkS4eev7cGlytfPncG9r+zm0fcPcd3Sqdy9Ou2kgwbARfMS+a8XhVeyC0hP6Xmeo6XVxes7j3HB3AQiwqybyhgTGPbXxQ8hwUH89kunIMAvX9/L258Us/Xwca5fOo0frp7bJ0EDYGxEGGfPcndX3blyTo/v6+6mamJ1uk36M8YEju0l6qeQ4CB+86VTuOzUiWw9fJwbzu7boOGxKj2JvOP1ZOVV9vjaV7ILiQgL5rzZNprKGBM4Fjh6wB08TiXztrO5a1XfBw2Ai9ImEBrc89FVnm6qZXMTGR3WFyOljTHGNwscPRQcJMybGBOQoAEQExHKZ2bF93gy4KYD5ZTXNrHKuqmMMQFmgWMQWpWeRH5FPR8frfD7mszsAiLDgjlvto2mMsYElgWOQWh5WiJhwUF+L7Xe7NVNFR5q3VTGmMCywDEIxYwO5ZzUODKzC3G5uu+u2ri/jON1zbbTnzGmX1jgGKRWZSRRWNnA9qPHuz03M6uQyLBgzk21bipjTOBZ4Bikls9NJCwkiFe66a5qbnXx+q5jXJhm3VTGmP5hgWOQig4P5dzUeF7tprvq/dxSKuubbQl1Y0y/scAxiK3OSKKoqpGtRzrvrsrMKiR6VAifmRXXjzUzxoxkFjgGsWVOd1Vno6uaWlyss24qY0w/s8AxiEWNCmHZnASe33KUrYfLTzj+fm4pVQ0tNprKGNOvLHAMcvd8dh4JY8K5+v99xJZD7YPHK1mFRIeHcLZ1Uxlj+pEFjkFuQkw4z9y0hMQx4VzzyEdsdoJHY0srb+w+xkVpExgVYt1Uxpj+Y4FjCJgQE84za5aQGOMOHh8dLOf93FKqG1pYbd1Uxph+ZoFjiEgcE86zNy0hKSacax/9iAfezmVMeAhLZ1o3lTGmf1ngGEISxrhbHhPHjubjoxWsmDeBsBD7X2iM6V/2V2eISYh25zy+cFoKa86ZPtDVMcaMQLZ17BAUHz2KX3/plIGuhjFmhLIWhzHGmB4JaOAQkZUisldEckXkTh/HJ4vIBhHZLiJZInKJUx4mIo+KSLaI7BCR87yuOd0pzxWRByRQW/EZY4zxKWCBQ0SCgQeBi4E04CoRSetw2l3Ac6q6ALgSeMgpvwlAVdOBC4Ffi4inrg87x2c5r5WBegZjjDEnCmSLYxGQq6oHVLUJeBa4rMM5Coxx3scABc77NGA9gKoWAxXAQhFJAsao6iZ1b8j9BPC5AD6DMcaYDgIZOJKBo16f85wybz8CviwiecCrwK1O+Q7gUhEJEZFpwOnAJOf6vG7uaYwxJoAGOjl+FfCYqqYAlwBPOl1Sj+AOCluA+4EPgNae3FhE1ojIFhHZUlJS0sfVNsaYkSuQw3HzcbcSPFKcMm834OQoVHWjiIQDcU731B2ek0TkAyAHOO7cp6t74txvLbAWYOHChd1v3G2MMcYvgWxxbAZmicg0EQnDnfx+ucM5R4BlACIyFwgHSkQkQkQinfILgRZV3a2qhUCViCxxRlNdDbwUwGcwxhjTgbhzzAG6uXt47f1AMPCIqv5URO4Ftqjqy84oqz8BUbgT5d9T1TdEZCqwDnDhblHcoKqHnXsuBB4DRgOvAbdqNw8hIiXA4V4+RhxQ2strB7vh/GwwvJ/Pnm3oGkrPN0VV4zsWBjRwDAciskVVFw50PQJhOD8bDO/ns2cbuobD8w10ctwYY8wQY4HDGGNMj1jg6N7aga5AAA3nZ4Ph/Xz2bEPXkH8+y3EYY4zpEWtxGGOM6RELHJ3obmXfoUZEHhGRYhHZ6VU2XkTeFJF9zs9xA1nH3hKRSc4qy7tFZJeIfNMpH/LPJyLhIvKRs0r0LhH5sVM+TUQ+dH4//+rMlRqSRCTYWSH7FefzcHq2Q85q3h+LyBanbMj/Xlrg8MHPlX2Hmsc4cSXhO4G3VXUW8LbzeShqAb6tqmnAEuBm5//XcHi+RuACVT0FOBVYKSJLgF8Av1XVmbhXVLhhAOt4sr4JfOL1eTg9G8D5qnqq1xDcIf97aYHDN39W9h1SVPWfQHmH4suAx533yXAlAwAABdNJREFUjzNEVxpW1UJV3ea8r8b9RyiZYfB86lbjfAx1XgpcALzglA/JZwMQkRRgFfBn57MwTJ6tC0P+99ICh2/+rOw7HCQ6y7gAHAMSB7IyfcFZdWAB8CHD5PmcrpyPgWLgTWA/UKGqLc4pQ/n3837ge7hXiQCIZfg8G7iD/BsislVE1jhlQ/730vYcN4D7X7YiMqSH2P3/9u4txKoqjuP495ealZpSKRQmXpKmB3UqSDQFsQgDCyuNaAzpoeihIiOIMlRKIiiSKLogohB5y7QkSq1UsKfoaoKlYmFO4CV0nCgD7d/DWsd2OqOzdWo65/w+cJgz+76GPee/914zvyWpN/AO8EhEHC4ODlnN7YuIY0CjpH7AaqChiw+pU0iaDOyLiC+Ko3zWmHER0SxpAPCRpO+KM6v1vPQdR9s6kuxbC/bmwbHIX/d18fGcMUk9SEXjrYhYlSfXTPsAIuIQsBEYA/STVLnwq9bz83rSuDs/kh4HTwReojbaBkBENOev+0hF/zpq4Lx04WhbR5J9a8EaYEZ+P4MqTRrOz8UXAtsi4sXCrKpvn6T++U4DSeeThlLeRiogU/NiVdm2iHgiIgZGxGDS79iGiGiiBtoGIKmXpD6V98BNwFZq4bz0PwC2ra1k3y4+pLMiaSkwgZTMuReYA7wLrAAGkdKD74yIEzvQ//ckjQM2A9/y97PyJ0n9HFXdPkkjSR2o3UgXeisi4mlJQ0lX6RcBXwHTI+KPrjvSs5MfVT0WEZNrpW25Havzt92BJTkh/GKq/bx04TAzszL8qMrMzEpx4TAzs1JcOMzMrBQXDjMzK8WFw8zMSnHhMDOzUlw4rG5JmpWjyrfk2OvRkrpLejZHXn+dX7MK6/zaxnbmSmrOy+6QtOpM0pQlTemMFOaci9RT0qY8NEClHQPy/J45rnxnji8ffLb7tPriwmF1SdIYYDJwTUSMBG4kBVvOAy4DRkREIzCelEh7OvNzdPZwYDmwQVL/koc1hRTjf8YkDQGaC/8w15SPqzHHXkCKKT+YY8vnk2LMzTrMhcPq1aXAgcoHbEQcAA4B9wEPRcSRPL01IuaW2XBELAfWA3e3t4yk5/LAU1skvSBpLHAr8Hy+OxiWX2vzHcRmSQ153cWSXpf0uaTtOSywYhKw9jSHWIz1XgncoGIipNlpOB3X6tV6YLak7cDHpLuEg8DuPKbH2fqSdlJsc+TEbUBDTkftFxGHJK0B3o+IlXm5T4AHImKHpNHAq6QgQIDBpMC8YcBGSVfkYjcJmFnY3SJJx0gBkPMiRUUcHzYgIo5KaiHFmR/ohHZbHfAdh9WlPDjStcD9wH5S4ZhQXEbSvfnq/ydJl5+8lVM61RV8C3AEWCjpduC3k1ZOEfFjgbfzWBxvkO6SKlZExJ8RsQPYBTTkQM6BEbErL9MUESNIj9vGA/eUbINZm1w4rG5FxLGI2BQRc4AHgVuAQZVE04hYlPs5Wkghg2VczT+HQy3u9yjpbmElqZ+lrUdL55AGNGosvK4qbubEzZKKw6eF/VQivVuBJXmfUBg2IMeX9wV+KdU6q2suHFaXJF0paXhhUiPwPSme/RVJ5+XlugHnltz2HaQI7aXtzO8N9I2ID0iPlUblWa1ApWgdBn6QNC2vI0mjCpuZJukcScOAofnYJwEf5uW7S7okv+9BKlBb87rFWO+ppDhzp51ah7mPw+pVb+DlPNbFUWAn6bFVC/AMsFVSK/A7qSP557zeBZL2FLZTGf9jpqTpQC/SB/TEiNjfzr77AO/l4iTg0Tx9GbBA0sOkD/Qm4DVJT5H+smsZ8E1edjfwGXAhqR/kSI4mn53n9wTW5aLRjdSPsyDPWwi8KWknaRz6uzrw8zI7zrHqZlVG0mIKneh52kBgQUTc3GUHZnXDdxxmNSAi9gAuGvaf8B2H2b9I0mpgyAmTH4+IdV1xPGadwYXDzMxK8V9VmZlZKS4cZmZWiguHmZmV4sJhZmaluHCYmVkpfwFicWYQdFs7AwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"seQJcSg-3e3Q"},"source":["As we can see, our BERT model is very sensitive to the amount of noise added in the SGLD. Unless the noise added is very small, it quickly falls off the optimum and it isn't able to learn. A reason for the behaviour we observe with SGLD is that, even though we are perturbing every weight by a very little amount, the total number of weights that we are perturbing is very big, so the total perturbation to the model could be significant. "]},{"cell_type":"markdown","metadata":{"id":"atQa2hhm3gaP"},"source":["# Vadam: Approximating the posterior of the full model"]},{"cell_type":"markdown","metadata":{"id":"gGvB8i-I3rzk"},"source":["We then try to train a full pretrained BERT model using variational Adam. We do a hyperparameter search over the prior precisions and posterior initializations but we don't observe any meaningful learning in any case. To give a better understanding of the quality of the results, we calculate tha accuracy of the pretrained BERT model without further fine tuning"]},{"cell_type":"code","metadata":{"id":"DsCiCmZq2xhg"},"source":["args = MyArgs()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Ot6Ju5D2xkX"},"source":["data_dir = '1_original_study_datasets'\n","train_name = \"util_train\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HC-Jz1V9Kiqm","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d657b88c9823466bb8fb324d26eae32b","a230eefa2c154e1d802fe657134854b1","5ef60822c6ea4f2c8ec5e281cd33b1b1","0b6bd8c115bf46afa48634f3034758cb","cd9e0f56beb8456caf12a5d6e9ea14a4","72b0b02ccc364f28979d028ca0c58906","aef7ae20cd454b6b8a1a5a4441ec8967","272dc95bf98f4f95a5a8731595f97f63","1a56b5b0fba64430b4dc7d4d2816d86d","636965626e94478ab84bb563ee59f060","c159d23c638e492ebcfd1c258f5de9bc","815b0a7a5c49470793a05b6b148fe5a4","015057ac05464e40b9758aef3af21301","e4ac347182dc41fd8329d3872281bd6f","b869ccbbc263480eb5fdf4ece8c2962f","2333f53c95cd4c3fa578c43c328ae3ce","5fa514e8865e4a58b8d309fd3f6e5f18","c8741f9b806346ecb962af0b891f7117","91a9b7111f694119b5787c49fffacbf0","8d1eeee2c21c4dc1b311476f11c41f5b","6f635b7112e9404eac781938d7d04c00","4f7fe2633e05444298ce5793ac2767b0","d1cafeb85c664e62b96a05de99e2faac","678f9192273d41a99019d61527e8d829","44f2599de2c0490398553134d0f423ae","ea8f54bf41ec4d49ae618907b8c819b9","a981cdcfc98a4f3689d47fb481eecdd6","6b1aa89372e04377b54954af61ac033b","76597aa7bf7843e0945f56aa55158abe","ed2bce559e7b492f9ff3a9b5fe22bb6d","c63ce0fa04c14b9ca0b61dc71ad37a69","58f03e932df946ddb46c3fa474c2b00a","17eda0384bdc4864bf5b2605f2a4b0ac","216dc91efa28485da2e2a6e647bdf30a","4d0c82c27d37431a84a99f28f92a77dc","62e967906b784979bd1a0f2d8fed897d","488d6672d6264b6d87fc997cb3f5e558","16aac18f400e4dcc936db780247a398b","66bf974d12d048e5b328c41a784c5ace","8531029814ef47cb863eba11458033b3"]},"executionInfo":{"status":"ok","timestamp":1621164558185,"user_tz":-60,"elapsed":3450330,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"5a16308f-abbb-4214-baf1-4936f271124e"},"source":["args.model = \"bert-base-uncased\"\n","args.learning_rate = 1e-5\n","args.batch_size = 16\n","args.nepochs = 2\n","prior_prec = [1e7, 1e5, 1e3, 1e1, 1e-1, 1e-3, 1e-5]\n","betas = (0.9,0.995)\n","train_mc_samples = 5\n","eval_mc_samples = 20\n","\n","training_accuracy = {}\n","validation_accuracy = {}\n","test_accuracy = {}\n","hard_test_accuracy = {}\n","\n","model, optimizer = load_model(args)\n","train_data = load_process_data(args, data_dir, \"util\", train_name)\n","train_set, validation_set = torch.utils.data.random_split(train_data, [int(0.8*len(train_data)), \\\n","                                      len(train_data) - int(0.8*len(train_data))], generator=torch.Generator().manual_seed(42))\n","\n","train_dataloader = DataLoader(train_set, batch_size=args.batch_size // 2, shuffle=True)\n","validation_dataloader = DataLoader(validation_set, batch_size=args.batch_size // 2, shuffle=False)\n","\n","\n","for precision in prior_prec:\n","\n","  model, optimizer = load_model(args)\n","\n","  no_decay = ['bias', 'LayerNorm.weight']\n","  optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters()\n","                if not any(nd in n for nd in no_decay)],\n","      'weight_decay': args.weight_decay},\n","    {'params': [p for n, p in model.named_parameters()\n","                if any(nd in n for nd in no_decay)],\n","      'weight_decay': 0.0}\n","  ]\n","\n","  optimizer_vadam = Vadam(optimizer_grouped_parameters,\n","                lr = args.learning_rate,\n","                betas = betas,\n","                prior_prec = precision,\n","                prec_init = precision,\n","                train_set_size = len(train_set))\n","  \n","  for epoch in range(1, args.nepochs + 1):\n","    print()\n","    train_variational(model, optimizer_vadam, train_dataloader, epoch, verbose=True)\n","  training_accuracy[precision] = evaluate(model, train_dataloader)\n","  print(training_accuracy[precision])\n","  validation_accuracy[precision] = evaluate(model, validation_dataloader)\n","  print(validation_accuracy[precision])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d657b88c9823466bb8fb324d26eae32b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a56b5b0fba64430b4dc7d4d2816d86d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5fa514e8865e4a58b8d309fd3f6e5f18","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44f2599de2c0490398553134d0f423ae","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17eda0384bdc4864bf5b2605f2a4b0ac","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","train fraction of examples within context window (64 tokens): 1.000\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:79: UserWarning: This overload of addcdiv_ is deprecated:\n","\taddcdiv_(Number value, Tensor tensor1, Tensor tensor2)\n","Consider using one of the following signatures instead:\n","\taddcdiv_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n","\n","Train Epoch: 1 [10/1374 (1%)]\tLoss: 0.710716\n","Train Epoch: 1 [20/1374 (1%)]\tLoss: 0.774642\n","Train Epoch: 1 [30/1374 (2%)]\tLoss: 0.696204\n","Train Epoch: 1 [40/1374 (3%)]\tLoss: 0.657831\n","Train Epoch: 1 [50/1374 (4%)]\tLoss: 0.731901\n","Train Epoch: 1 [60/1374 (4%)]\tLoss: 0.706430\n","Train Epoch: 1 [70/1374 (5%)]\tLoss: 0.672105\n","Train Epoch: 1 [80/1374 (6%)]\tLoss: 0.687831\n","Train Epoch: 1 [90/1374 (7%)]\tLoss: 0.731698\n","Train Epoch: 1 [100/1374 (7%)]\tLoss: 0.687935\n","Train Epoch: 1 [110/1374 (8%)]\tLoss: 0.725055\n","Train Epoch: 1 [120/1374 (9%)]\tLoss: 0.696276\n","Train Epoch: 1 [130/1374 (9%)]\tLoss: 0.711436\n","Train Epoch: 1 [140/1374 (10%)]\tLoss: 0.766686\n","Train Epoch: 1 [150/1374 (11%)]\tLoss: 0.741060\n","Train Epoch: 1 [160/1374 (12%)]\tLoss: 0.720799\n","Train Epoch: 1 [170/1374 (12%)]\tLoss: 0.680889\n","Train Epoch: 1 [180/1374 (13%)]\tLoss: 0.693800\n","Train Epoch: 1 [190/1374 (14%)]\tLoss: 0.666459\n","Train Epoch: 1 [200/1374 (15%)]\tLoss: 0.660882\n","Train Epoch: 1 [210/1374 (15%)]\tLoss: 0.679250\n","Train Epoch: 1 [220/1374 (16%)]\tLoss: 0.653171\n","Train Epoch: 1 [230/1374 (17%)]\tLoss: 0.701716\n","Train Epoch: 1 [240/1374 (17%)]\tLoss: 0.600471\n","Train Epoch: 1 [250/1374 (18%)]\tLoss: 0.645183\n","Train Epoch: 1 [260/1374 (19%)]\tLoss: 0.748340\n","Train Epoch: 1 [270/1374 (20%)]\tLoss: 0.673477\n","Train Epoch: 1 [280/1374 (20%)]\tLoss: 0.704189\n","Train Epoch: 1 [290/1374 (21%)]\tLoss: 0.692113\n","Train Epoch: 1 [300/1374 (22%)]\tLoss: 0.653514\n","Train Epoch: 1 [310/1374 (23%)]\tLoss: 0.741403\n","Train Epoch: 1 [320/1374 (23%)]\tLoss: 0.696681\n","Train Epoch: 1 [330/1374 (24%)]\tLoss: 0.770346\n","Train Epoch: 1 [340/1374 (25%)]\tLoss: 0.733754\n","Train Epoch: 1 [350/1374 (25%)]\tLoss: 0.737312\n","Train Epoch: 1 [360/1374 (26%)]\tLoss: 0.678138\n","Train Epoch: 1 [370/1374 (27%)]\tLoss: 0.675841\n","Train Epoch: 1 [380/1374 (28%)]\tLoss: 0.603863\n","Train Epoch: 1 [390/1374 (28%)]\tLoss: 0.662888\n","Train Epoch: 1 [400/1374 (29%)]\tLoss: 0.706200\n","Train Epoch: 1 [410/1374 (30%)]\tLoss: 0.707503\n","Train Epoch: 1 [420/1374 (31%)]\tLoss: 0.700412\n","Train Epoch: 1 [430/1374 (31%)]\tLoss: 0.719678\n","Train Epoch: 1 [440/1374 (32%)]\tLoss: 0.683345\n","Train Epoch: 1 [450/1374 (33%)]\tLoss: 0.699917\n","Train Epoch: 1 [460/1374 (33%)]\tLoss: 0.713537\n","Train Epoch: 1 [470/1374 (34%)]\tLoss: 0.672076\n","Train Epoch: 1 [480/1374 (35%)]\tLoss: 0.683433\n","Train Epoch: 1 [490/1374 (36%)]\tLoss: 0.707740\n","Train Epoch: 1 [500/1374 (36%)]\tLoss: 0.692548\n","Train Epoch: 1 [510/1374 (37%)]\tLoss: 0.704762\n","Train Epoch: 1 [520/1374 (38%)]\tLoss: 0.735975\n","Train Epoch: 1 [530/1374 (39%)]\tLoss: 0.715095\n","Train Epoch: 1 [540/1374 (39%)]\tLoss: 0.718316\n","Train Epoch: 1 [550/1374 (40%)]\tLoss: 0.715336\n","Train Epoch: 1 [560/1374 (41%)]\tLoss: 0.698152\n","Train Epoch: 1 [570/1374 (41%)]\tLoss: 0.782666\n","Train Epoch: 1 [580/1374 (42%)]\tLoss: 0.726356\n","Train Epoch: 1 [590/1374 (43%)]\tLoss: 0.708490\n","Train Epoch: 1 [600/1374 (44%)]\tLoss: 0.695034\n","Train Epoch: 1 [610/1374 (44%)]\tLoss: 0.755740\n","Train Epoch: 1 [620/1374 (45%)]\tLoss: 0.694924\n","Train Epoch: 1 [630/1374 (46%)]\tLoss: 0.673047\n","Train Epoch: 1 [640/1374 (47%)]\tLoss: 0.697928\n","Train Epoch: 1 [650/1374 (47%)]\tLoss: 0.710586\n","Train Epoch: 1 [660/1374 (48%)]\tLoss: 0.659289\n","Train Epoch: 1 [670/1374 (49%)]\tLoss: 0.668449\n","Train Epoch: 1 [680/1374 (49%)]\tLoss: 0.683893\n","Train Epoch: 1 [690/1374 (50%)]\tLoss: 0.696839\n","Train Epoch: 1 [700/1374 (51%)]\tLoss: 0.716817\n","Train Epoch: 1 [710/1374 (52%)]\tLoss: 0.664104\n","Train Epoch: 1 [720/1374 (52%)]\tLoss: 0.694689\n","Train Epoch: 1 [730/1374 (53%)]\tLoss: 0.711759\n","Train Epoch: 1 [740/1374 (54%)]\tLoss: 0.704132\n","Train Epoch: 1 [750/1374 (55%)]\tLoss: 0.674889\n","Train Epoch: 1 [760/1374 (55%)]\tLoss: 0.685480\n","Train Epoch: 1 [770/1374 (56%)]\tLoss: 0.660671\n","Train Epoch: 1 [780/1374 (57%)]\tLoss: 0.700942\n","Train Epoch: 1 [790/1374 (57%)]\tLoss: 0.679641\n","Train Epoch: 1 [800/1374 (58%)]\tLoss: 0.701615\n","Train Epoch: 1 [810/1374 (59%)]\tLoss: 0.701672\n","Train Epoch: 1 [820/1374 (60%)]\tLoss: 0.721459\n","Train Epoch: 1 [830/1374 (60%)]\tLoss: 0.738891\n","Train Epoch: 1 [840/1374 (61%)]\tLoss: 0.701030\n","Train Epoch: 1 [850/1374 (62%)]\tLoss: 0.703626\n","Train Epoch: 1 [860/1374 (63%)]\tLoss: 0.715404\n","Train Epoch: 1 [870/1374 (63%)]\tLoss: 0.756514\n","Train Epoch: 1 [880/1374 (64%)]\tLoss: 0.715967\n","Train Epoch: 1 [890/1374 (65%)]\tLoss: 0.688513\n","Train Epoch: 1 [900/1374 (66%)]\tLoss: 0.696400\n","Train Epoch: 1 [910/1374 (66%)]\tLoss: 0.729127\n","Train Epoch: 1 [920/1374 (67%)]\tLoss: 0.682657\n","Train Epoch: 1 [930/1374 (68%)]\tLoss: 0.661706\n","Train Epoch: 1 [940/1374 (68%)]\tLoss: 0.713947\n","Train Epoch: 1 [950/1374 (69%)]\tLoss: 0.752602\n","Train Epoch: 1 [960/1374 (70%)]\tLoss: 0.669810\n","Train Epoch: 1 [970/1374 (71%)]\tLoss: 0.676335\n","Train Epoch: 1 [980/1374 (71%)]\tLoss: 0.698908\n","Train Epoch: 1 [990/1374 (72%)]\tLoss: 0.682710\n","Train Epoch: 1 [1000/1374 (73%)]\tLoss: 0.682128\n","Train Epoch: 1 [1010/1374 (74%)]\tLoss: 0.687222\n","Train Epoch: 1 [1020/1374 (74%)]\tLoss: 0.671298\n","Train Epoch: 1 [1030/1374 (75%)]\tLoss: 0.698422\n","Train Epoch: 1 [1040/1374 (76%)]\tLoss: 0.712841\n","Train Epoch: 1 [1050/1374 (76%)]\tLoss: 0.674957\n","Train Epoch: 1 [1060/1374 (77%)]\tLoss: 0.637418\n","Train Epoch: 1 [1070/1374 (78%)]\tLoss: 0.715694\n","Train Epoch: 1 [1080/1374 (79%)]\tLoss: 0.774042\n","Train Epoch: 1 [1090/1374 (79%)]\tLoss: 0.696038\n","Train Epoch: 1 [1100/1374 (80%)]\tLoss: 0.765574\n","Train Epoch: 1 [1110/1374 (81%)]\tLoss: 0.693782\n","Train Epoch: 1 [1120/1374 (82%)]\tLoss: 0.710211\n","Train Epoch: 1 [1130/1374 (82%)]\tLoss: 0.716963\n","Train Epoch: 1 [1140/1374 (83%)]\tLoss: 0.689855\n","Train Epoch: 1 [1150/1374 (84%)]\tLoss: 0.731547\n","Train Epoch: 1 [1160/1374 (84%)]\tLoss: 0.726507\n","Train Epoch: 1 [1170/1374 (85%)]\tLoss: 0.689609\n","Train Epoch: 1 [1180/1374 (86%)]\tLoss: 0.675136\n","Train Epoch: 1 [1190/1374 (87%)]\tLoss: 0.688222\n","Train Epoch: 1 [1200/1374 (87%)]\tLoss: 0.633610\n","Train Epoch: 1 [1210/1374 (88%)]\tLoss: 0.719262\n","Train Epoch: 1 [1220/1374 (89%)]\tLoss: 0.705478\n","Train Epoch: 1 [1230/1374 (90%)]\tLoss: 0.728842\n","Train Epoch: 1 [1240/1374 (90%)]\tLoss: 0.668232\n","Train Epoch: 1 [1250/1374 (91%)]\tLoss: 0.695166\n","Train Epoch: 1 [1260/1374 (92%)]\tLoss: 0.752734\n","Train Epoch: 1 [1270/1374 (92%)]\tLoss: 0.718247\n","Train Epoch: 1 [1280/1374 (93%)]\tLoss: 0.756106\n","Train Epoch: 1 [1290/1374 (94%)]\tLoss: 0.648012\n","Train Epoch: 1 [1300/1374 (95%)]\tLoss: 0.743460\n","Train Epoch: 1 [1310/1374 (95%)]\tLoss: 0.730470\n","Train Epoch: 1 [1320/1374 (96%)]\tLoss: 0.720399\n","Train Epoch: 1 [1330/1374 (97%)]\tLoss: 0.730803\n","Train Epoch: 1 [1340/1374 (98%)]\tLoss: 0.700512\n","Train Epoch: 1 [1350/1374 (98%)]\tLoss: 0.699863\n","Train Epoch: 1 [1360/1374 (99%)]\tLoss: 0.688779\n","Train Epoch: 1 [1370/1374 (100%)]\tLoss: 0.722162\n","\n","Train Epoch: 2 [10/1374 (1%)]\tLoss: 0.629383\n","Train Epoch: 2 [20/1374 (1%)]\tLoss: 0.663553\n","Train Epoch: 2 [30/1374 (2%)]\tLoss: 0.762075\n","Train Epoch: 2 [40/1374 (3%)]\tLoss: 0.668002\n","Train Epoch: 2 [50/1374 (4%)]\tLoss: 0.670789\n","Train Epoch: 2 [60/1374 (4%)]\tLoss: 0.703010\n","Train Epoch: 2 [70/1374 (5%)]\tLoss: 0.686369\n","Train Epoch: 2 [80/1374 (6%)]\tLoss: 0.680093\n","Train Epoch: 2 [90/1374 (7%)]\tLoss: 0.748426\n","Train Epoch: 2 [100/1374 (7%)]\tLoss: 0.680256\n","Train Epoch: 2 [110/1374 (8%)]\tLoss: 0.707362\n","Train Epoch: 2 [120/1374 (9%)]\tLoss: 0.720395\n","Train Epoch: 2 [130/1374 (9%)]\tLoss: 0.695916\n","Train Epoch: 2 [140/1374 (10%)]\tLoss: 0.648465\n","Train Epoch: 2 [150/1374 (11%)]\tLoss: 0.739127\n","Train Epoch: 2 [160/1374 (12%)]\tLoss: 0.718193\n","Train Epoch: 2 [170/1374 (12%)]\tLoss: 0.730301\n","Train Epoch: 2 [180/1374 (13%)]\tLoss: 0.724709\n","Train Epoch: 2 [190/1374 (14%)]\tLoss: 0.691231\n","Train Epoch: 2 [200/1374 (15%)]\tLoss: 0.733067\n","Train Epoch: 2 [210/1374 (15%)]\tLoss: 0.681036\n","Train Epoch: 2 [220/1374 (16%)]\tLoss: 0.718767\n","Train Epoch: 2 [230/1374 (17%)]\tLoss: 0.720030\n","Train Epoch: 2 [240/1374 (17%)]\tLoss: 0.688086\n","Train Epoch: 2 [250/1374 (18%)]\tLoss: 0.778524\n","Train Epoch: 2 [260/1374 (19%)]\tLoss: 0.683276\n","Train Epoch: 2 [270/1374 (20%)]\tLoss: 0.666836\n","Train Epoch: 2 [280/1374 (20%)]\tLoss: 0.742571\n","Train Epoch: 2 [290/1374 (21%)]\tLoss: 0.692941\n","Train Epoch: 2 [300/1374 (22%)]\tLoss: 0.685323\n","Train Epoch: 2 [310/1374 (23%)]\tLoss: 0.646563\n","Train Epoch: 2 [320/1374 (23%)]\tLoss: 0.702159\n","Train Epoch: 2 [330/1374 (24%)]\tLoss: 0.685529\n","Train Epoch: 2 [340/1374 (25%)]\tLoss: 0.700160\n","Train Epoch: 2 [350/1374 (25%)]\tLoss: 0.743855\n","Train Epoch: 2 [360/1374 (26%)]\tLoss: 0.667108\n","Train Epoch: 2 [370/1374 (27%)]\tLoss: 0.751897\n","Train Epoch: 2 [380/1374 (28%)]\tLoss: 0.724885\n","Train Epoch: 2 [390/1374 (28%)]\tLoss: 0.725490\n","Train Epoch: 2 [400/1374 (29%)]\tLoss: 0.685902\n","Train Epoch: 2 [410/1374 (30%)]\tLoss: 0.672282\n","Train Epoch: 2 [420/1374 (31%)]\tLoss: 0.697798\n","Train Epoch: 2 [430/1374 (31%)]\tLoss: 0.685635\n","Train Epoch: 2 [440/1374 (32%)]\tLoss: 0.651371\n","Train Epoch: 2 [450/1374 (33%)]\tLoss: 0.767022\n","Train Epoch: 2 [460/1374 (33%)]\tLoss: 0.650118\n","Train Epoch: 2 [470/1374 (34%)]\tLoss: 0.683804\n","Train Epoch: 2 [480/1374 (35%)]\tLoss: 0.699684\n","Train Epoch: 2 [490/1374 (36%)]\tLoss: 0.691935\n","Train Epoch: 2 [500/1374 (36%)]\tLoss: 0.695455\n","Train Epoch: 2 [510/1374 (37%)]\tLoss: 0.748646\n","Train Epoch: 2 [520/1374 (38%)]\tLoss: 0.695739\n","Train Epoch: 2 [530/1374 (39%)]\tLoss: 0.701606\n","Train Epoch: 2 [540/1374 (39%)]\tLoss: 0.718051\n","Train Epoch: 2 [550/1374 (40%)]\tLoss: 0.713946\n","Train Epoch: 2 [560/1374 (41%)]\tLoss: 0.639121\n","Train Epoch: 2 [570/1374 (41%)]\tLoss: 0.699538\n","Train Epoch: 2 [580/1374 (42%)]\tLoss: 0.684640\n","Train Epoch: 2 [590/1374 (43%)]\tLoss: 0.735820\n","Train Epoch: 2 [600/1374 (44%)]\tLoss: 0.744999\n","Train Epoch: 2 [610/1374 (44%)]\tLoss: 0.707311\n","Train Epoch: 2 [620/1374 (45%)]\tLoss: 0.681562\n","Train Epoch: 2 [630/1374 (46%)]\tLoss: 0.717930\n","Train Epoch: 2 [640/1374 (47%)]\tLoss: 0.617327\n","Train Epoch: 2 [650/1374 (47%)]\tLoss: 0.649350\n","Train Epoch: 2 [660/1374 (48%)]\tLoss: 0.684160\n","Train Epoch: 2 [670/1374 (49%)]\tLoss: 0.659930\n","Train Epoch: 2 [680/1374 (49%)]\tLoss: 0.707041\n","Train Epoch: 2 [690/1374 (50%)]\tLoss: 0.704215\n","Train Epoch: 2 [700/1374 (51%)]\tLoss: 0.682760\n","Train Epoch: 2 [710/1374 (52%)]\tLoss: 0.647789\n","Train Epoch: 2 [720/1374 (52%)]\tLoss: 0.728925\n","Train Epoch: 2 [730/1374 (53%)]\tLoss: 0.737391\n","Train Epoch: 2 [740/1374 (54%)]\tLoss: 0.756429\n","Train Epoch: 2 [750/1374 (55%)]\tLoss: 0.734249\n","Train Epoch: 2 [760/1374 (55%)]\tLoss: 0.713303\n","Train Epoch: 2 [770/1374 (56%)]\tLoss: 0.720111\n","Train Epoch: 2 [780/1374 (57%)]\tLoss: 0.700591\n","Train Epoch: 2 [790/1374 (57%)]\tLoss: 0.708336\n","Train Epoch: 2 [800/1374 (58%)]\tLoss: 0.714849\n","Train Epoch: 2 [810/1374 (59%)]\tLoss: 0.715740\n","Train Epoch: 2 [820/1374 (60%)]\tLoss: 0.684828\n","Train Epoch: 2 [830/1374 (60%)]\tLoss: 0.725195\n","Train Epoch: 2 [840/1374 (61%)]\tLoss: 0.682952\n","Train Epoch: 2 [850/1374 (62%)]\tLoss: 0.637627\n","Train Epoch: 2 [860/1374 (63%)]\tLoss: 0.689379\n","Train Epoch: 2 [870/1374 (63%)]\tLoss: 0.670194\n","Train Epoch: 2 [880/1374 (64%)]\tLoss: 0.712437\n","Train Epoch: 2 [890/1374 (65%)]\tLoss: 0.663017\n","Train Epoch: 2 [900/1374 (66%)]\tLoss: 0.699031\n","Train Epoch: 2 [910/1374 (66%)]\tLoss: 0.726078\n","Train Epoch: 2 [920/1374 (67%)]\tLoss: 0.726850\n","Train Epoch: 2 [930/1374 (68%)]\tLoss: 0.729676\n","Train Epoch: 2 [940/1374 (68%)]\tLoss: 0.721732\n","Train Epoch: 2 [950/1374 (69%)]\tLoss: 0.748243\n","Train Epoch: 2 [960/1374 (70%)]\tLoss: 0.743336\n","Train Epoch: 2 [970/1374 (71%)]\tLoss: 0.692834\n","Train Epoch: 2 [980/1374 (71%)]\tLoss: 0.721845\n","Train Epoch: 2 [990/1374 (72%)]\tLoss: 0.695460\n","Train Epoch: 2 [1000/1374 (73%)]\tLoss: 0.671693\n","Train Epoch: 2 [1010/1374 (74%)]\tLoss: 0.706501\n","Train Epoch: 2 [1020/1374 (74%)]\tLoss: 0.729307\n","Train Epoch: 2 [1030/1374 (75%)]\tLoss: 0.741928\n","Train Epoch: 2 [1040/1374 (76%)]\tLoss: 0.698105\n","Train Epoch: 2 [1050/1374 (76%)]\tLoss: 0.652403\n","Train Epoch: 2 [1060/1374 (77%)]\tLoss: 0.764608\n","Train Epoch: 2 [1070/1374 (78%)]\tLoss: 0.683569\n","Train Epoch: 2 [1080/1374 (79%)]\tLoss: 0.655909\n","Train Epoch: 2 [1090/1374 (79%)]\tLoss: 0.723495\n","Train Epoch: 2 [1100/1374 (80%)]\tLoss: 0.717587\n","Train Epoch: 2 [1110/1374 (81%)]\tLoss: 0.697773\n","Train Epoch: 2 [1120/1374 (82%)]\tLoss: 0.725212\n","Train Epoch: 2 [1130/1374 (82%)]\tLoss: 0.687287\n","Train Epoch: 2 [1140/1374 (83%)]\tLoss: 0.670528\n","Train Epoch: 2 [1150/1374 (84%)]\tLoss: 0.727657\n","Train Epoch: 2 [1160/1374 (84%)]\tLoss: 0.671066\n","Train Epoch: 2 [1170/1374 (85%)]\tLoss: 0.681066\n","Train Epoch: 2 [1180/1374 (86%)]\tLoss: 0.717414\n","Train Epoch: 2 [1190/1374 (87%)]\tLoss: 0.710699\n","Train Epoch: 2 [1200/1374 (87%)]\tLoss: 0.716896\n","Train Epoch: 2 [1210/1374 (88%)]\tLoss: 0.709332\n","Train Epoch: 2 [1220/1374 (89%)]\tLoss: 0.693390\n","Train Epoch: 2 [1230/1374 (90%)]\tLoss: 0.674268\n","Train Epoch: 2 [1240/1374 (90%)]\tLoss: 0.671531\n","Train Epoch: 2 [1250/1374 (91%)]\tLoss: 0.677230\n","Train Epoch: 2 [1260/1374 (92%)]\tLoss: 0.714958\n","Train Epoch: 2 [1270/1374 (92%)]\tLoss: 0.703547\n","Train Epoch: 2 [1280/1374 (93%)]\tLoss: 0.703455\n","Train Epoch: 2 [1290/1374 (94%)]\tLoss: 0.703648\n","Train Epoch: 2 [1300/1374 (95%)]\tLoss: 0.782741\n","Train Epoch: 2 [1310/1374 (95%)]\tLoss: 0.684694\n","Train Epoch: 2 [1320/1374 (96%)]\tLoss: 0.736960\n","Train Epoch: 2 [1330/1374 (97%)]\tLoss: 0.707822\n","Train Epoch: 2 [1340/1374 (98%)]\tLoss: 0.686607\n","Train Epoch: 2 [1350/1374 (98%)]\tLoss: 0.679540\n","Train Epoch: 2 [1360/1374 (99%)]\tLoss: 0.669336\n","Train Epoch: 2 [1370/1374 (100%)]\tLoss: 0.682791\n","Acc 0.504\n","0.5042766151046406\n","Acc 0.502\n","0.5018195050946143\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n","\n","Train Epoch: 1 [10/1374 (1%)]\tLoss: 0.696862\n","Train Epoch: 1 [20/1374 (1%)]\tLoss: 0.678134\n","Train Epoch: 1 [30/1374 (2%)]\tLoss: 0.673557\n","Train Epoch: 1 [40/1374 (3%)]\tLoss: 0.711939\n","Train Epoch: 1 [50/1374 (4%)]\tLoss: 0.750184\n","Train Epoch: 1 [60/1374 (4%)]\tLoss: 0.750676\n","Train Epoch: 1 [70/1374 (5%)]\tLoss: 0.717843\n","Train Epoch: 1 [80/1374 (6%)]\tLoss: 0.626564\n","Train Epoch: 1 [90/1374 (7%)]\tLoss: 0.726499\n","Train Epoch: 1 [100/1374 (7%)]\tLoss: 0.774144\n","Train Epoch: 1 [110/1374 (8%)]\tLoss: 0.719055\n","Train Epoch: 1 [120/1374 (9%)]\tLoss: 0.676648\n","Train Epoch: 1 [130/1374 (9%)]\tLoss: 0.669590\n","Train Epoch: 1 [140/1374 (10%)]\tLoss: 0.611122\n","Train Epoch: 1 [150/1374 (11%)]\tLoss: 0.683408\n","Train Epoch: 1 [160/1374 (12%)]\tLoss: 0.670714\n","Train Epoch: 1 [170/1374 (12%)]\tLoss: 0.664357\n","Train Epoch: 1 [180/1374 (13%)]\tLoss: 0.703466\n","Train Epoch: 1 [190/1374 (14%)]\tLoss: 0.696056\n","Train Epoch: 1 [200/1374 (15%)]\tLoss: 0.633874\n","Train Epoch: 1 [210/1374 (15%)]\tLoss: 0.782905\n","Train Epoch: 1 [220/1374 (16%)]\tLoss: 0.704761\n","Train Epoch: 1 [230/1374 (17%)]\tLoss: 0.645203\n","Train Epoch: 1 [240/1374 (17%)]\tLoss: 0.597807\n","Train Epoch: 1 [250/1374 (18%)]\tLoss: 0.685115\n","Train Epoch: 1 [260/1374 (19%)]\tLoss: 0.686278\n","Train Epoch: 1 [270/1374 (20%)]\tLoss: 0.691931\n","Train Epoch: 1 [280/1374 (20%)]\tLoss: 0.703538\n","Train Epoch: 1 [290/1374 (21%)]\tLoss: 0.673413\n","Train Epoch: 1 [300/1374 (22%)]\tLoss: 0.724496\n","Train Epoch: 1 [310/1374 (23%)]\tLoss: 0.748633\n","Train Epoch: 1 [320/1374 (23%)]\tLoss: 0.650661\n","Train Epoch: 1 [330/1374 (24%)]\tLoss: 0.732838\n","Train Epoch: 1 [340/1374 (25%)]\tLoss: 0.719153\n","Train Epoch: 1 [350/1374 (25%)]\tLoss: 0.710280\n","Train Epoch: 1 [360/1374 (26%)]\tLoss: 0.734098\n","Train Epoch: 1 [370/1374 (27%)]\tLoss: 0.777800\n","Train Epoch: 1 [380/1374 (28%)]\tLoss: 0.665859\n","Train Epoch: 1 [390/1374 (28%)]\tLoss: 0.695768\n","Train Epoch: 1 [400/1374 (29%)]\tLoss: 0.749328\n","Train Epoch: 1 [410/1374 (30%)]\tLoss: 0.710010\n","Train Epoch: 1 [420/1374 (31%)]\tLoss: 0.640040\n","Train Epoch: 1 [430/1374 (31%)]\tLoss: 0.705048\n","Train Epoch: 1 [440/1374 (32%)]\tLoss: 0.687579\n","Train Epoch: 1 [450/1374 (33%)]\tLoss: 0.710648\n","Train Epoch: 1 [460/1374 (33%)]\tLoss: 0.721700\n","Train Epoch: 1 [470/1374 (34%)]\tLoss: 0.749096\n","Train Epoch: 1 [480/1374 (35%)]\tLoss: 0.658938\n","Train Epoch: 1 [490/1374 (36%)]\tLoss: 0.669712\n","Train Epoch: 1 [500/1374 (36%)]\tLoss: 0.691003\n","Train Epoch: 1 [510/1374 (37%)]\tLoss: 0.706053\n","Train Epoch: 1 [520/1374 (38%)]\tLoss: 0.676711\n","Train Epoch: 1 [530/1374 (39%)]\tLoss: 0.651198\n","Train Epoch: 1 [540/1374 (39%)]\tLoss: 0.675497\n","Train Epoch: 1 [550/1374 (40%)]\tLoss: 0.613481\n","Train Epoch: 1 [560/1374 (41%)]\tLoss: 0.731665\n","Train Epoch: 1 [570/1374 (41%)]\tLoss: 0.732109\n","Train Epoch: 1 [580/1374 (42%)]\tLoss: 0.668752\n","Train Epoch: 1 [590/1374 (43%)]\tLoss: 0.707655\n","Train Epoch: 1 [600/1374 (44%)]\tLoss: 0.765907\n","Train Epoch: 1 [610/1374 (44%)]\tLoss: 0.679662\n","Train Epoch: 1 [620/1374 (45%)]\tLoss: 0.661039\n","Train Epoch: 1 [630/1374 (46%)]\tLoss: 0.661146\n","Train Epoch: 1 [640/1374 (47%)]\tLoss: 0.739905\n","Train Epoch: 1 [650/1374 (47%)]\tLoss: 0.696818\n","Train Epoch: 1 [660/1374 (48%)]\tLoss: 0.671195\n","Train Epoch: 1 [670/1374 (49%)]\tLoss: 0.630036\n","Train Epoch: 1 [680/1374 (49%)]\tLoss: 0.715616\n","Train Epoch: 1 [690/1374 (50%)]\tLoss: 0.727275\n","Train Epoch: 1 [700/1374 (51%)]\tLoss: 0.681756\n","Train Epoch: 1 [710/1374 (52%)]\tLoss: 0.655881\n","Train Epoch: 1 [720/1374 (52%)]\tLoss: 0.716746\n","Train Epoch: 1 [730/1374 (53%)]\tLoss: 0.700594\n","Train Epoch: 1 [740/1374 (54%)]\tLoss: 0.685024\n","Train Epoch: 1 [750/1374 (55%)]\tLoss: 0.654742\n","Train Epoch: 1 [760/1374 (55%)]\tLoss: 0.708469\n","Train Epoch: 1 [770/1374 (56%)]\tLoss: 0.736937\n","Train Epoch: 1 [780/1374 (57%)]\tLoss: 0.729058\n","Train Epoch: 1 [790/1374 (57%)]\tLoss: 0.623437\n","Train Epoch: 1 [800/1374 (58%)]\tLoss: 0.763951\n","Train Epoch: 1 [810/1374 (59%)]\tLoss: 0.752347\n","Train Epoch: 1 [820/1374 (60%)]\tLoss: 0.706676\n","Train Epoch: 1 [830/1374 (60%)]\tLoss: 0.722010\n","Train Epoch: 1 [840/1374 (61%)]\tLoss: 0.723297\n","Train Epoch: 1 [850/1374 (62%)]\tLoss: 0.664794\n","Train Epoch: 1 [860/1374 (63%)]\tLoss: 0.680733\n","Train Epoch: 1 [870/1374 (63%)]\tLoss: 0.649744\n","Train Epoch: 1 [880/1374 (64%)]\tLoss: 0.708480\n","Train Epoch: 1 [890/1374 (65%)]\tLoss: 0.709674\n","Train Epoch: 1 [900/1374 (66%)]\tLoss: 0.697672\n","Train Epoch: 1 [910/1374 (66%)]\tLoss: 0.651687\n","Train Epoch: 1 [920/1374 (67%)]\tLoss: 0.670850\n","Train Epoch: 1 [930/1374 (68%)]\tLoss: 0.713203\n","Train Epoch: 1 [940/1374 (68%)]\tLoss: 0.751085\n","Train Epoch: 1 [950/1374 (69%)]\tLoss: 0.662526\n","Train Epoch: 1 [960/1374 (70%)]\tLoss: 0.662706\n","Train Epoch: 1 [970/1374 (71%)]\tLoss: 0.721793\n","Train Epoch: 1 [980/1374 (71%)]\tLoss: 0.682986\n","Train Epoch: 1 [990/1374 (72%)]\tLoss: 0.696794\n","Train Epoch: 1 [1000/1374 (73%)]\tLoss: 0.663017\n","Train Epoch: 1 [1010/1374 (74%)]\tLoss: 0.686895\n","Train Epoch: 1 [1020/1374 (74%)]\tLoss: 0.713212\n","Train Epoch: 1 [1030/1374 (75%)]\tLoss: 0.724254\n","Train Epoch: 1 [1040/1374 (76%)]\tLoss: 0.675383\n","Train Epoch: 1 [1050/1374 (76%)]\tLoss: 0.696505\n","Train Epoch: 1 [1060/1374 (77%)]\tLoss: 0.689198\n","Train Epoch: 1 [1070/1374 (78%)]\tLoss: 0.676057\n","Train Epoch: 1 [1080/1374 (79%)]\tLoss: 0.669999\n","Train Epoch: 1 [1090/1374 (79%)]\tLoss: 0.661732\n","Train Epoch: 1 [1100/1374 (80%)]\tLoss: 0.656720\n","Train Epoch: 1 [1110/1374 (81%)]\tLoss: 0.642170\n","Train Epoch: 1 [1120/1374 (82%)]\tLoss: 0.690983\n","Train Epoch: 1 [1130/1374 (82%)]\tLoss: 0.676638\n","Train Epoch: 1 [1140/1374 (83%)]\tLoss: 0.664252\n","Train Epoch: 1 [1150/1374 (84%)]\tLoss: 0.706047\n","Train Epoch: 1 [1160/1374 (84%)]\tLoss: 0.681709\n","Train Epoch: 1 [1170/1374 (85%)]\tLoss: 0.732222\n","Train Epoch: 1 [1180/1374 (86%)]\tLoss: 0.644689\n","Train Epoch: 1 [1190/1374 (87%)]\tLoss: 0.674003\n","Train Epoch: 1 [1200/1374 (87%)]\tLoss: 0.710082\n","Train Epoch: 1 [1210/1374 (88%)]\tLoss: 0.762768\n","Train Epoch: 1 [1220/1374 (89%)]\tLoss: 0.677827\n","Train Epoch: 1 [1230/1374 (90%)]\tLoss: 0.660788\n","Train Epoch: 1 [1240/1374 (90%)]\tLoss: 0.703582\n","Train Epoch: 1 [1250/1374 (91%)]\tLoss: 0.666847\n","Train Epoch: 1 [1260/1374 (92%)]\tLoss: 0.686163\n","Train Epoch: 1 [1270/1374 (92%)]\tLoss: 0.676577\n","Train Epoch: 1 [1280/1374 (93%)]\tLoss: 0.677703\n","Train Epoch: 1 [1290/1374 (94%)]\tLoss: 0.769880\n","Train Epoch: 1 [1300/1374 (95%)]\tLoss: 0.700388\n","Train Epoch: 1 [1310/1374 (95%)]\tLoss: 0.694003\n","Train Epoch: 1 [1320/1374 (96%)]\tLoss: 0.677359\n","Train Epoch: 1 [1330/1374 (97%)]\tLoss: 0.690810\n","Train Epoch: 1 [1340/1374 (98%)]\tLoss: 0.682028\n","Train Epoch: 1 [1350/1374 (98%)]\tLoss: 0.779293\n","Train Epoch: 1 [1360/1374 (99%)]\tLoss: 0.720301\n","Train Epoch: 1 [1370/1374 (100%)]\tLoss: 0.694215\n","\n","Train Epoch: 2 [10/1374 (1%)]\tLoss: 0.662684\n","Train Epoch: 2 [20/1374 (1%)]\tLoss: 0.722610\n","Train Epoch: 2 [30/1374 (2%)]\tLoss: 0.726640\n","Train Epoch: 2 [40/1374 (3%)]\tLoss: 0.747008\n","Train Epoch: 2 [50/1374 (4%)]\tLoss: 0.758264\n","Train Epoch: 2 [60/1374 (4%)]\tLoss: 0.701553\n","Train Epoch: 2 [70/1374 (5%)]\tLoss: 0.717208\n","Train Epoch: 2 [80/1374 (6%)]\tLoss: 0.736701\n","Train Epoch: 2 [90/1374 (7%)]\tLoss: 0.711121\n","Train Epoch: 2 [100/1374 (7%)]\tLoss: 0.686886\n","Train Epoch: 2 [110/1374 (8%)]\tLoss: 0.691303\n","Train Epoch: 2 [120/1374 (9%)]\tLoss: 0.737065\n","Train Epoch: 2 [130/1374 (9%)]\tLoss: 0.698704\n","Train Epoch: 2 [140/1374 (10%)]\tLoss: 0.695484\n","Train Epoch: 2 [150/1374 (11%)]\tLoss: 0.702717\n","Train Epoch: 2 [160/1374 (12%)]\tLoss: 0.675353\n","Train Epoch: 2 [170/1374 (12%)]\tLoss: 0.756765\n","Train Epoch: 2 [180/1374 (13%)]\tLoss: 0.635381\n","Train Epoch: 2 [190/1374 (14%)]\tLoss: 0.638338\n","Train Epoch: 2 [200/1374 (15%)]\tLoss: 0.619082\n","Train Epoch: 2 [210/1374 (15%)]\tLoss: 0.701628\n","Train Epoch: 2 [220/1374 (16%)]\tLoss: 0.711937\n","Train Epoch: 2 [230/1374 (17%)]\tLoss: 0.711401\n","Train Epoch: 2 [240/1374 (17%)]\tLoss: 0.685044\n","Train Epoch: 2 [250/1374 (18%)]\tLoss: 0.655955\n","Train Epoch: 2 [260/1374 (19%)]\tLoss: 0.703472\n","Train Epoch: 2 [270/1374 (20%)]\tLoss: 0.675259\n","Train Epoch: 2 [280/1374 (20%)]\tLoss: 0.746092\n","Train Epoch: 2 [290/1374 (21%)]\tLoss: 0.742734\n","Train Epoch: 2 [300/1374 (22%)]\tLoss: 0.665406\n","Train Epoch: 2 [310/1374 (23%)]\tLoss: 0.628494\n","Train Epoch: 2 [320/1374 (23%)]\tLoss: 0.700057\n","Train Epoch: 2 [330/1374 (24%)]\tLoss: 0.657790\n","Train Epoch: 2 [340/1374 (25%)]\tLoss: 0.658880\n","Train Epoch: 2 [350/1374 (25%)]\tLoss: 0.720059\n","Train Epoch: 2 [360/1374 (26%)]\tLoss: 0.680711\n","Train Epoch: 2 [370/1374 (27%)]\tLoss: 0.693040\n","Train Epoch: 2 [380/1374 (28%)]\tLoss: 0.662121\n","Train Epoch: 2 [390/1374 (28%)]\tLoss: 0.658939\n","Train Epoch: 2 [400/1374 (29%)]\tLoss: 0.673522\n","Train Epoch: 2 [410/1374 (30%)]\tLoss: 0.648131\n","Train Epoch: 2 [420/1374 (31%)]\tLoss: 0.677891\n","Train Epoch: 2 [430/1374 (31%)]\tLoss: 0.670909\n","Train Epoch: 2 [440/1374 (32%)]\tLoss: 0.716909\n","Train Epoch: 2 [450/1374 (33%)]\tLoss: 0.734978\n","Train Epoch: 2 [460/1374 (33%)]\tLoss: 0.725530\n","Train Epoch: 2 [470/1374 (34%)]\tLoss: 0.683106\n","Train Epoch: 2 [480/1374 (35%)]\tLoss: 0.638113\n","Train Epoch: 2 [490/1374 (36%)]\tLoss: 0.734292\n","Train Epoch: 2 [500/1374 (36%)]\tLoss: 0.678460\n","Train Epoch: 2 [510/1374 (37%)]\tLoss: 0.743913\n","Train Epoch: 2 [520/1374 (38%)]\tLoss: 0.689276\n","Train Epoch: 2 [530/1374 (39%)]\tLoss: 0.686506\n","Train Epoch: 2 [540/1374 (39%)]\tLoss: 0.674424\n","Train Epoch: 2 [550/1374 (40%)]\tLoss: 0.718227\n","Train Epoch: 2 [560/1374 (41%)]\tLoss: 0.709275\n","Train Epoch: 2 [570/1374 (41%)]\tLoss: 0.687926\n","Train Epoch: 2 [580/1374 (42%)]\tLoss: 0.719701\n","Train Epoch: 2 [590/1374 (43%)]\tLoss: 0.736367\n","Train Epoch: 2 [600/1374 (44%)]\tLoss: 0.749649\n","Train Epoch: 2 [610/1374 (44%)]\tLoss: 0.671855\n","Train Epoch: 2 [620/1374 (45%)]\tLoss: 0.664121\n","Train Epoch: 2 [630/1374 (46%)]\tLoss: 0.713614\n","Train Epoch: 2 [640/1374 (47%)]\tLoss: 0.680106\n","Train Epoch: 2 [650/1374 (47%)]\tLoss: 0.696528\n","Train Epoch: 2 [660/1374 (48%)]\tLoss: 0.645793\n","Train Epoch: 2 [670/1374 (49%)]\tLoss: 0.674270\n","Train Epoch: 2 [680/1374 (49%)]\tLoss: 0.654794\n","Train Epoch: 2 [690/1374 (50%)]\tLoss: 0.738283\n","Train Epoch: 2 [700/1374 (51%)]\tLoss: 0.662648\n","Train Epoch: 2 [710/1374 (52%)]\tLoss: 0.717436\n","Train Epoch: 2 [720/1374 (52%)]\tLoss: 0.624360\n","Train Epoch: 2 [730/1374 (53%)]\tLoss: 0.694018\n","Train Epoch: 2 [740/1374 (54%)]\tLoss: 0.739250\n","Train Epoch: 2 [750/1374 (55%)]\tLoss: 0.630170\n","Train Epoch: 2 [760/1374 (55%)]\tLoss: 0.728900\n","Train Epoch: 2 [770/1374 (56%)]\tLoss: 0.641857\n","Train Epoch: 2 [780/1374 (57%)]\tLoss: 0.713690\n","Train Epoch: 2 [790/1374 (57%)]\tLoss: 0.657712\n","Train Epoch: 2 [800/1374 (58%)]\tLoss: 0.695505\n","Train Epoch: 2 [810/1374 (59%)]\tLoss: 0.709892\n","Train Epoch: 2 [820/1374 (60%)]\tLoss: 0.663253\n","Train Epoch: 2 [830/1374 (60%)]\tLoss: 0.717398\n","Train Epoch: 2 [840/1374 (61%)]\tLoss: 0.706481\n","Train Epoch: 2 [850/1374 (62%)]\tLoss: 0.701949\n","Train Epoch: 2 [860/1374 (63%)]\tLoss: 0.680512\n","Train Epoch: 2 [870/1374 (63%)]\tLoss: 0.768439\n","Train Epoch: 2 [880/1374 (64%)]\tLoss: 0.667021\n","Train Epoch: 2 [890/1374 (65%)]\tLoss: 0.721318\n","Train Epoch: 2 [900/1374 (66%)]\tLoss: 0.649690\n","Train Epoch: 2 [910/1374 (66%)]\tLoss: 0.697758\n","Train Epoch: 2 [920/1374 (67%)]\tLoss: 0.666063\n","Train Epoch: 2 [930/1374 (68%)]\tLoss: 0.658710\n","Train Epoch: 2 [940/1374 (68%)]\tLoss: 0.740299\n","Train Epoch: 2 [950/1374 (69%)]\tLoss: 0.662030\n","Train Epoch: 2 [960/1374 (70%)]\tLoss: 0.659478\n","Train Epoch: 2 [970/1374 (71%)]\tLoss: 0.735107\n","Train Epoch: 2 [980/1374 (71%)]\tLoss: 0.709453\n","Train Epoch: 2 [990/1374 (72%)]\tLoss: 0.681831\n","Train Epoch: 2 [1000/1374 (73%)]\tLoss: 0.690765\n","Train Epoch: 2 [1010/1374 (74%)]\tLoss: 0.685727\n","Train Epoch: 2 [1020/1374 (74%)]\tLoss: 0.717371\n","Train Epoch: 2 [1030/1374 (75%)]\tLoss: 0.705274\n","Train Epoch: 2 [1040/1374 (76%)]\tLoss: 0.603690\n","Train Epoch: 2 [1050/1374 (76%)]\tLoss: 0.739964\n","Train Epoch: 2 [1060/1374 (77%)]\tLoss: 0.662563\n","Train Epoch: 2 [1070/1374 (78%)]\tLoss: 0.685521\n","Train Epoch: 2 [1080/1374 (79%)]\tLoss: 0.802737\n","Train Epoch: 2 [1090/1374 (79%)]\tLoss: 0.726735\n","Train Epoch: 2 [1100/1374 (80%)]\tLoss: 0.682587\n","Train Epoch: 2 [1110/1374 (81%)]\tLoss: 0.696522\n","Train Epoch: 2 [1120/1374 (82%)]\tLoss: 0.651453\n","Train Epoch: 2 [1130/1374 (82%)]\tLoss: 0.771189\n","Train Epoch: 2 [1140/1374 (83%)]\tLoss: 0.676486\n","Train Epoch: 2 [1150/1374 (84%)]\tLoss: 0.738691\n","Train Epoch: 2 [1160/1374 (84%)]\tLoss: 0.670024\n","Train Epoch: 2 [1170/1374 (85%)]\tLoss: 0.737490\n","Train Epoch: 2 [1180/1374 (86%)]\tLoss: 0.674226\n","Train Epoch: 2 [1190/1374 (87%)]\tLoss: 0.695272\n","Train Epoch: 2 [1200/1374 (87%)]\tLoss: 0.691816\n","Train Epoch: 2 [1210/1374 (88%)]\tLoss: 0.662213\n","Train Epoch: 2 [1220/1374 (89%)]\tLoss: 0.673107\n","Train Epoch: 2 [1230/1374 (90%)]\tLoss: 0.727663\n","Train Epoch: 2 [1240/1374 (90%)]\tLoss: 0.640435\n","Train Epoch: 2 [1250/1374 (91%)]\tLoss: 0.724766\n","Train Epoch: 2 [1260/1374 (92%)]\tLoss: 0.627015\n","Train Epoch: 2 [1270/1374 (92%)]\tLoss: 0.741588\n","Train Epoch: 2 [1280/1374 (93%)]\tLoss: 0.662769\n","Train Epoch: 2 [1290/1374 (94%)]\tLoss: 0.672727\n","Train Epoch: 2 [1300/1374 (95%)]\tLoss: 0.664744\n","Train Epoch: 2 [1310/1374 (95%)]\tLoss: 0.644854\n","Train Epoch: 2 [1320/1374 (96%)]\tLoss: 0.677670\n","Train Epoch: 2 [1330/1374 (97%)]\tLoss: 0.689040\n","Train Epoch: 2 [1340/1374 (98%)]\tLoss: 0.743770\n","Train Epoch: 2 [1350/1374 (98%)]\tLoss: 0.714361\n","Train Epoch: 2 [1360/1374 (99%)]\tLoss: 0.670940\n","Train Epoch: 2 [1370/1374 (100%)]\tLoss: 0.680383\n","Acc 0.493\n","0.4931756141947225\n","Acc 0.485\n","0.485080058224163\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n","\n","Train Epoch: 1 [10/1374 (1%)]\tLoss: 0.797486\n","Train Epoch: 1 [20/1374 (1%)]\tLoss: 0.950808\n","Train Epoch: 1 [30/1374 (2%)]\tLoss: 0.599425\n","Train Epoch: 1 [40/1374 (3%)]\tLoss: 0.700656\n","Train Epoch: 1 [50/1374 (4%)]\tLoss: 0.952370\n","Train Epoch: 1 [60/1374 (4%)]\tLoss: 0.851390\n","Train Epoch: 1 [70/1374 (5%)]\tLoss: 0.636125\n","Train Epoch: 1 [80/1374 (6%)]\tLoss: 0.740939\n","Train Epoch: 1 [90/1374 (7%)]\tLoss: 0.791464\n","Train Epoch: 1 [100/1374 (7%)]\tLoss: 0.807494\n","Train Epoch: 1 [110/1374 (8%)]\tLoss: 0.618836\n","Train Epoch: 1 [120/1374 (9%)]\tLoss: 0.891132\n","Train Epoch: 1 [130/1374 (9%)]\tLoss: 0.913949\n","Train Epoch: 1 [140/1374 (10%)]\tLoss: 0.720883\n","Train Epoch: 1 [150/1374 (11%)]\tLoss: 0.806880\n","Train Epoch: 1 [160/1374 (12%)]\tLoss: 0.644321\n","Train Epoch: 1 [170/1374 (12%)]\tLoss: 0.937343\n","Train Epoch: 1 [180/1374 (13%)]\tLoss: 0.772362\n","Train Epoch: 1 [190/1374 (14%)]\tLoss: 0.732813\n","Train Epoch: 1 [200/1374 (15%)]\tLoss: 0.732260\n","Train Epoch: 1 [210/1374 (15%)]\tLoss: 0.563747\n","Train Epoch: 1 [220/1374 (16%)]\tLoss: 0.651833\n","Train Epoch: 1 [230/1374 (17%)]\tLoss: 0.642317\n","Train Epoch: 1 [240/1374 (17%)]\tLoss: 0.930267\n","Train Epoch: 1 [250/1374 (18%)]\tLoss: 0.644126\n","Train Epoch: 1 [260/1374 (19%)]\tLoss: 0.645193\n","Train Epoch: 1 [270/1374 (20%)]\tLoss: 0.908808\n","Train Epoch: 1 [280/1374 (20%)]\tLoss: 0.796308\n","Train Epoch: 1 [290/1374 (21%)]\tLoss: 0.858368\n","Train Epoch: 1 [300/1374 (22%)]\tLoss: 0.631345\n","Train Epoch: 1 [310/1374 (23%)]\tLoss: 0.796104\n","Train Epoch: 1 [320/1374 (23%)]\tLoss: 0.783137\n","Train Epoch: 1 [330/1374 (24%)]\tLoss: 0.608068\n","Train Epoch: 1 [340/1374 (25%)]\tLoss: 0.979266\n","Train Epoch: 1 [350/1374 (25%)]\tLoss: 0.550435\n","Train Epoch: 1 [360/1374 (26%)]\tLoss: 0.784212\n","Train Epoch: 1 [370/1374 (27%)]\tLoss: 0.650563\n","Train Epoch: 1 [380/1374 (28%)]\tLoss: 0.811462\n","Train Epoch: 1 [390/1374 (28%)]\tLoss: 0.740300\n","Train Epoch: 1 [400/1374 (29%)]\tLoss: 0.920656\n","Train Epoch: 1 [410/1374 (30%)]\tLoss: 0.921624\n","Train Epoch: 1 [420/1374 (31%)]\tLoss: 0.654930\n","Train Epoch: 1 [430/1374 (31%)]\tLoss: 0.749624\n","Train Epoch: 1 [440/1374 (32%)]\tLoss: 0.801493\n","Train Epoch: 1 [450/1374 (33%)]\tLoss: 0.770489\n","Train Epoch: 1 [460/1374 (33%)]\tLoss: 0.546109\n","Train Epoch: 1 [470/1374 (34%)]\tLoss: 0.957848\n","Train Epoch: 1 [480/1374 (35%)]\tLoss: 0.571507\n","Train Epoch: 1 [490/1374 (36%)]\tLoss: 0.473751\n","Train Epoch: 1 [500/1374 (36%)]\tLoss: 0.882385\n","Train Epoch: 1 [510/1374 (37%)]\tLoss: 0.651767\n","Train Epoch: 1 [520/1374 (38%)]\tLoss: 0.812817\n","Train Epoch: 1 [530/1374 (39%)]\tLoss: 0.789430\n","Train Epoch: 1 [540/1374 (39%)]\tLoss: 0.661597\n","Train Epoch: 1 [550/1374 (40%)]\tLoss: 0.792481\n","Train Epoch: 1 [560/1374 (41%)]\tLoss: 0.688398\n","Train Epoch: 1 [570/1374 (41%)]\tLoss: 0.638202\n","Train Epoch: 1 [580/1374 (42%)]\tLoss: 0.739526\n","Train Epoch: 1 [590/1374 (43%)]\tLoss: 0.815459\n","Train Epoch: 1 [600/1374 (44%)]\tLoss: 0.653994\n","Train Epoch: 1 [610/1374 (44%)]\tLoss: 0.561149\n","Train Epoch: 1 [620/1374 (45%)]\tLoss: 0.787848\n","Train Epoch: 1 [630/1374 (46%)]\tLoss: 0.756061\n","Train Epoch: 1 [640/1374 (47%)]\tLoss: 0.747978\n","Train Epoch: 1 [650/1374 (47%)]\tLoss: 0.671306\n","Train Epoch: 1 [660/1374 (48%)]\tLoss: 0.896113\n","Train Epoch: 1 [670/1374 (49%)]\tLoss: 0.922561\n","Train Epoch: 1 [680/1374 (49%)]\tLoss: 0.768106\n","Train Epoch: 1 [690/1374 (50%)]\tLoss: 0.668524\n","Train Epoch: 1 [700/1374 (51%)]\tLoss: 0.547332\n","Train Epoch: 1 [710/1374 (52%)]\tLoss: 0.819217\n","Train Epoch: 1 [720/1374 (52%)]\tLoss: 0.671566\n","Train Epoch: 1 [730/1374 (53%)]\tLoss: 0.648277\n","Train Epoch: 1 [740/1374 (54%)]\tLoss: 0.735001\n","Train Epoch: 1 [750/1374 (55%)]\tLoss: 0.630560\n","Train Epoch: 1 [760/1374 (55%)]\tLoss: 0.761557\n","Train Epoch: 1 [770/1374 (56%)]\tLoss: 0.685083\n","Train Epoch: 1 [780/1374 (57%)]\tLoss: 0.712743\n","Train Epoch: 1 [790/1374 (57%)]\tLoss: 0.632624\n","Train Epoch: 1 [800/1374 (58%)]\tLoss: 0.727915\n","Train Epoch: 1 [810/1374 (59%)]\tLoss: 0.718808\n","Train Epoch: 1 [820/1374 (60%)]\tLoss: 0.780733\n","Train Epoch: 1 [830/1374 (60%)]\tLoss: 0.664556\n","Train Epoch: 1 [840/1374 (61%)]\tLoss: 0.728340\n","Train Epoch: 1 [850/1374 (62%)]\tLoss: 0.657874\n","Train Epoch: 1 [860/1374 (63%)]\tLoss: 0.653891\n","Train Epoch: 1 [870/1374 (63%)]\tLoss: 0.928873\n","Train Epoch: 1 [880/1374 (64%)]\tLoss: 0.855453\n","Train Epoch: 1 [890/1374 (65%)]\tLoss: 0.814749\n","Train Epoch: 1 [900/1374 (66%)]\tLoss: 0.647098\n","Train Epoch: 1 [910/1374 (66%)]\tLoss: 0.757676\n","Train Epoch: 1 [920/1374 (67%)]\tLoss: 0.709124\n","Train Epoch: 1 [930/1374 (68%)]\tLoss: 0.622215\n","Train Epoch: 1 [940/1374 (68%)]\tLoss: 0.870488\n","Train Epoch: 1 [950/1374 (69%)]\tLoss: 0.866213\n","Train Epoch: 1 [960/1374 (70%)]\tLoss: 0.821336\n","Train Epoch: 1 [970/1374 (71%)]\tLoss: 0.700016\n","Train Epoch: 1 [980/1374 (71%)]\tLoss: 0.673337\n","Train Epoch: 1 [990/1374 (72%)]\tLoss: 0.706489\n","Train Epoch: 1 [1000/1374 (73%)]\tLoss: 0.771320\n","Train Epoch: 1 [1010/1374 (74%)]\tLoss: 0.733185\n","Train Epoch: 1 [1020/1374 (74%)]\tLoss: 0.686397\n","Train Epoch: 1 [1030/1374 (75%)]\tLoss: 0.743694\n","Train Epoch: 1 [1040/1374 (76%)]\tLoss: 0.951005\n","Train Epoch: 1 [1050/1374 (76%)]\tLoss: 0.616952\n","Train Epoch: 1 [1060/1374 (77%)]\tLoss: 0.739289\n","Train Epoch: 1 [1070/1374 (78%)]\tLoss: 0.901938\n","Train Epoch: 1 [1080/1374 (79%)]\tLoss: 0.619368\n","Train Epoch: 1 [1090/1374 (79%)]\tLoss: 0.678704\n","Train Epoch: 1 [1100/1374 (80%)]\tLoss: 0.879764\n","Train Epoch: 1 [1110/1374 (81%)]\tLoss: 0.584955\n","Train Epoch: 1 [1120/1374 (82%)]\tLoss: 0.546200\n","Train Epoch: 1 [1130/1374 (82%)]\tLoss: 0.702327\n","Train Epoch: 1 [1140/1374 (83%)]\tLoss: 0.669113\n","Train Epoch: 1 [1150/1374 (84%)]\tLoss: 0.718616\n","Train Epoch: 1 [1160/1374 (84%)]\tLoss: 0.690647\n","Train Epoch: 1 [1170/1374 (85%)]\tLoss: 0.639678\n","Train Epoch: 1 [1180/1374 (86%)]\tLoss: 0.605144\n","Train Epoch: 1 [1190/1374 (87%)]\tLoss: 0.638606\n","Train Epoch: 1 [1200/1374 (87%)]\tLoss: 0.661394\n","Train Epoch: 1 [1210/1374 (88%)]\tLoss: 0.632838\n","Train Epoch: 1 [1220/1374 (89%)]\tLoss: 0.558386\n","Train Epoch: 1 [1230/1374 (90%)]\tLoss: 0.842320\n","Train Epoch: 1 [1240/1374 (90%)]\tLoss: 0.738662\n","Train Epoch: 1 [1250/1374 (91%)]\tLoss: 0.532474\n","Train Epoch: 1 [1260/1374 (92%)]\tLoss: 0.656015\n","Train Epoch: 1 [1270/1374 (92%)]\tLoss: 0.859862\n","Train Epoch: 1 [1280/1374 (93%)]\tLoss: 0.684187\n","Train Epoch: 1 [1290/1374 (94%)]\tLoss: 0.690744\n","Train Epoch: 1 [1300/1374 (95%)]\tLoss: 0.732952\n","Train Epoch: 1 [1310/1374 (95%)]\tLoss: 0.616275\n","Train Epoch: 1 [1320/1374 (96%)]\tLoss: 0.503125\n","Train Epoch: 1 [1330/1374 (97%)]\tLoss: 0.696409\n","Train Epoch: 1 [1340/1374 (98%)]\tLoss: 0.642488\n","Train Epoch: 1 [1350/1374 (98%)]\tLoss: 0.623177\n","Train Epoch: 1 [1360/1374 (99%)]\tLoss: 0.662695\n","Train Epoch: 1 [1370/1374 (100%)]\tLoss: 0.652618\n","\n","Train Epoch: 2 [10/1374 (1%)]\tLoss: 0.641954\n","Train Epoch: 2 [20/1374 (1%)]\tLoss: 0.838190\n","Train Epoch: 2 [30/1374 (2%)]\tLoss: 0.737428\n","Train Epoch: 2 [40/1374 (3%)]\tLoss: 0.691105\n","Train Epoch: 2 [50/1374 (4%)]\tLoss: 0.734515\n","Train Epoch: 2 [60/1374 (4%)]\tLoss: 0.830422\n","Train Epoch: 2 [70/1374 (5%)]\tLoss: 0.675673\n","Train Epoch: 2 [80/1374 (6%)]\tLoss: 0.587412\n","Train Epoch: 2 [90/1374 (7%)]\tLoss: 0.817070\n","Train Epoch: 2 [100/1374 (7%)]\tLoss: 0.745964\n","Train Epoch: 2 [110/1374 (8%)]\tLoss: 0.994546\n","Train Epoch: 2 [120/1374 (9%)]\tLoss: 0.660772\n","Train Epoch: 2 [130/1374 (9%)]\tLoss: 0.531184\n","Train Epoch: 2 [140/1374 (10%)]\tLoss: 0.710486\n","Train Epoch: 2 [150/1374 (11%)]\tLoss: 0.711974\n","Train Epoch: 2 [160/1374 (12%)]\tLoss: 0.708016\n","Train Epoch: 2 [170/1374 (12%)]\tLoss: 0.587453\n","Train Epoch: 2 [180/1374 (13%)]\tLoss: 0.692904\n","Train Epoch: 2 [190/1374 (14%)]\tLoss: 0.573370\n","Train Epoch: 2 [200/1374 (15%)]\tLoss: 0.599817\n","Train Epoch: 2 [210/1374 (15%)]\tLoss: 0.945075\n","Train Epoch: 2 [220/1374 (16%)]\tLoss: 0.761468\n","Train Epoch: 2 [230/1374 (17%)]\tLoss: 0.694931\n","Train Epoch: 2 [240/1374 (17%)]\tLoss: 0.610252\n","Train Epoch: 2 [250/1374 (18%)]\tLoss: 0.671172\n","Train Epoch: 2 [260/1374 (19%)]\tLoss: 0.712082\n","Train Epoch: 2 [270/1374 (20%)]\tLoss: 0.909329\n","Train Epoch: 2 [280/1374 (20%)]\tLoss: 0.746272\n","Train Epoch: 2 [290/1374 (21%)]\tLoss: 1.194369\n","Train Epoch: 2 [300/1374 (22%)]\tLoss: 0.904777\n","Train Epoch: 2 [310/1374 (23%)]\tLoss: 0.805048\n","Train Epoch: 2 [320/1374 (23%)]\tLoss: 0.680144\n","Train Epoch: 2 [330/1374 (24%)]\tLoss: 0.721629\n","Train Epoch: 2 [340/1374 (25%)]\tLoss: 0.691478\n","Train Epoch: 2 [350/1374 (25%)]\tLoss: 0.750147\n","Train Epoch: 2 [360/1374 (26%)]\tLoss: 0.780390\n","Train Epoch: 2 [370/1374 (27%)]\tLoss: 0.695362\n","Train Epoch: 2 [380/1374 (28%)]\tLoss: 0.696055\n","Train Epoch: 2 [390/1374 (28%)]\tLoss: 0.736533\n","Train Epoch: 2 [400/1374 (29%)]\tLoss: 0.585199\n","Train Epoch: 2 [410/1374 (30%)]\tLoss: 0.771158\n","Train Epoch: 2 [420/1374 (31%)]\tLoss: 0.863483\n","Train Epoch: 2 [430/1374 (31%)]\tLoss: 0.601696\n","Train Epoch: 2 [440/1374 (32%)]\tLoss: 0.872793\n","Train Epoch: 2 [450/1374 (33%)]\tLoss: 0.605574\n","Train Epoch: 2 [460/1374 (33%)]\tLoss: 0.653072\n","Train Epoch: 2 [470/1374 (34%)]\tLoss: 0.731873\n","Train Epoch: 2 [480/1374 (35%)]\tLoss: 0.644002\n","Train Epoch: 2 [490/1374 (36%)]\tLoss: 0.894212\n","Train Epoch: 2 [500/1374 (36%)]\tLoss: 0.797883\n","Train Epoch: 2 [510/1374 (37%)]\tLoss: 0.806668\n","Train Epoch: 2 [520/1374 (38%)]\tLoss: 0.691241\n","Train Epoch: 2 [530/1374 (39%)]\tLoss: 0.683836\n","Train Epoch: 2 [540/1374 (39%)]\tLoss: 0.783049\n","Train Epoch: 2 [550/1374 (40%)]\tLoss: 0.777363\n","Train Epoch: 2 [560/1374 (41%)]\tLoss: 0.883346\n","Train Epoch: 2 [570/1374 (41%)]\tLoss: 0.648979\n","Train Epoch: 2 [580/1374 (42%)]\tLoss: 0.707338\n","Train Epoch: 2 [590/1374 (43%)]\tLoss: 0.833936\n","Train Epoch: 2 [600/1374 (44%)]\tLoss: 0.548266\n","Train Epoch: 2 [610/1374 (44%)]\tLoss: 0.780076\n","Train Epoch: 2 [620/1374 (45%)]\tLoss: 0.820004\n","Train Epoch: 2 [630/1374 (46%)]\tLoss: 0.666197\n","Train Epoch: 2 [640/1374 (47%)]\tLoss: 0.840346\n","Train Epoch: 2 [650/1374 (47%)]\tLoss: 0.741609\n","Train Epoch: 2 [660/1374 (48%)]\tLoss: 0.701431\n","Train Epoch: 2 [670/1374 (49%)]\tLoss: 0.682676\n","Train Epoch: 2 [680/1374 (49%)]\tLoss: 0.679246\n","Train Epoch: 2 [690/1374 (50%)]\tLoss: 0.648484\n","Train Epoch: 2 [700/1374 (51%)]\tLoss: 0.860397\n","Train Epoch: 2 [710/1374 (52%)]\tLoss: 0.762427\n","Train Epoch: 2 [720/1374 (52%)]\tLoss: 0.606853\n","Train Epoch: 2 [730/1374 (53%)]\tLoss: 0.806392\n","Train Epoch: 2 [740/1374 (54%)]\tLoss: 0.781101\n","Train Epoch: 2 [750/1374 (55%)]\tLoss: 0.767507\n","Train Epoch: 2 [760/1374 (55%)]\tLoss: 0.802797\n","Train Epoch: 2 [770/1374 (56%)]\tLoss: 0.771473\n","Train Epoch: 2 [780/1374 (57%)]\tLoss: 0.679408\n","Train Epoch: 2 [790/1374 (57%)]\tLoss: 0.824461\n","Train Epoch: 2 [800/1374 (58%)]\tLoss: 0.705315\n","Train Epoch: 2 [810/1374 (59%)]\tLoss: 0.834379\n","Train Epoch: 2 [820/1374 (60%)]\tLoss: 0.628141\n","Train Epoch: 2 [830/1374 (60%)]\tLoss: 0.745779\n","Train Epoch: 2 [840/1374 (61%)]\tLoss: 0.717649\n","Train Epoch: 2 [850/1374 (62%)]\tLoss: 0.802159\n","Train Epoch: 2 [860/1374 (63%)]\tLoss: 0.676375\n","Train Epoch: 2 [870/1374 (63%)]\tLoss: 0.707395\n","Train Epoch: 2 [880/1374 (64%)]\tLoss: 1.004037\n","Train Epoch: 2 [890/1374 (65%)]\tLoss: 0.639279\n","Train Epoch: 2 [900/1374 (66%)]\tLoss: 0.848698\n","Train Epoch: 2 [910/1374 (66%)]\tLoss: 0.647423\n","Train Epoch: 2 [920/1374 (67%)]\tLoss: 0.761344\n","Train Epoch: 2 [930/1374 (68%)]\tLoss: 0.918028\n","Train Epoch: 2 [940/1374 (68%)]\tLoss: 0.755769\n","Train Epoch: 2 [950/1374 (69%)]\tLoss: 0.531739\n","Train Epoch: 2 [960/1374 (70%)]\tLoss: 0.779742\n","Train Epoch: 2 [970/1374 (71%)]\tLoss: 0.872564\n","Train Epoch: 2 [980/1374 (71%)]\tLoss: 0.633871\n","Train Epoch: 2 [990/1374 (72%)]\tLoss: 0.752351\n","Train Epoch: 2 [1000/1374 (73%)]\tLoss: 0.786502\n","Train Epoch: 2 [1010/1374 (74%)]\tLoss: 0.719423\n","Train Epoch: 2 [1020/1374 (74%)]\tLoss: 0.626842\n","Train Epoch: 2 [1030/1374 (75%)]\tLoss: 0.695758\n","Train Epoch: 2 [1040/1374 (76%)]\tLoss: 0.873231\n","Train Epoch: 2 [1050/1374 (76%)]\tLoss: 0.599896\n","Train Epoch: 2 [1060/1374 (77%)]\tLoss: 0.614316\n","Train Epoch: 2 [1070/1374 (78%)]\tLoss: 0.780169\n","Train Epoch: 2 [1080/1374 (79%)]\tLoss: 0.762092\n","Train Epoch: 2 [1090/1374 (79%)]\tLoss: 0.875203\n","Train Epoch: 2 [1100/1374 (80%)]\tLoss: 0.634886\n","Train Epoch: 2 [1110/1374 (81%)]\tLoss: 0.854946\n","Train Epoch: 2 [1120/1374 (82%)]\tLoss: 0.614076\n","Train Epoch: 2 [1130/1374 (82%)]\tLoss: 0.736895\n","Train Epoch: 2 [1140/1374 (83%)]\tLoss: 0.638671\n","Train Epoch: 2 [1150/1374 (84%)]\tLoss: 0.735951\n","Train Epoch: 2 [1160/1374 (84%)]\tLoss: 0.879486\n","Train Epoch: 2 [1170/1374 (85%)]\tLoss: 1.102200\n","Train Epoch: 2 [1180/1374 (86%)]\tLoss: 0.814547\n","Train Epoch: 2 [1190/1374 (87%)]\tLoss: 0.682497\n","Train Epoch: 2 [1200/1374 (87%)]\tLoss: 0.834992\n","Train Epoch: 2 [1210/1374 (88%)]\tLoss: 0.709806\n","Train Epoch: 2 [1220/1374 (89%)]\tLoss: 0.814180\n","Train Epoch: 2 [1230/1374 (90%)]\tLoss: 0.832736\n","Train Epoch: 2 [1240/1374 (90%)]\tLoss: 0.656026\n","Train Epoch: 2 [1250/1374 (91%)]\tLoss: 0.753620\n","Train Epoch: 2 [1260/1374 (92%)]\tLoss: 0.739936\n","Train Epoch: 2 [1270/1374 (92%)]\tLoss: 0.700823\n","Train Epoch: 2 [1280/1374 (93%)]\tLoss: 0.704894\n","Train Epoch: 2 [1290/1374 (94%)]\tLoss: 0.747185\n","Train Epoch: 2 [1300/1374 (95%)]\tLoss: 0.587440\n","Train Epoch: 2 [1310/1374 (95%)]\tLoss: 0.745661\n","Train Epoch: 2 [1320/1374 (96%)]\tLoss: 0.747664\n","Train Epoch: 2 [1330/1374 (97%)]\tLoss: 0.734634\n","Train Epoch: 2 [1340/1374 (98%)]\tLoss: 0.683850\n","Train Epoch: 2 [1350/1374 (98%)]\tLoss: 0.541546\n","Train Epoch: 2 [1360/1374 (99%)]\tLoss: 0.852612\n","Train Epoch: 2 [1370/1374 (100%)]\tLoss: 0.898176\n","Acc 0.469\n","0.4691537761601456\n","Acc 0.466\n","0.4657933042212518\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n","\n","Train Epoch: 1 [10/1374 (1%)]\tLoss: 2.547065\n","Train Epoch: 1 [20/1374 (1%)]\tLoss: 2.014702\n","Train Epoch: 1 [30/1374 (2%)]\tLoss: 1.805563\n","Train Epoch: 1 [40/1374 (3%)]\tLoss: 0.637688\n","Train Epoch: 1 [50/1374 (4%)]\tLoss: 1.282903\n","Train Epoch: 1 [60/1374 (4%)]\tLoss: 1.252607\n","Train Epoch: 1 [70/1374 (5%)]\tLoss: 1.191140\n","Train Epoch: 1 [80/1374 (6%)]\tLoss: 2.023918\n","Train Epoch: 1 [90/1374 (7%)]\tLoss: 1.170390\n","Train Epoch: 1 [100/1374 (7%)]\tLoss: 1.203955\n","Train Epoch: 1 [110/1374 (8%)]\tLoss: 1.026917\n","Train Epoch: 1 [120/1374 (9%)]\tLoss: 1.186266\n","Train Epoch: 1 [130/1374 (9%)]\tLoss: 0.673558\n","Train Epoch: 1 [140/1374 (10%)]\tLoss: 0.844965\n","Train Epoch: 1 [150/1374 (11%)]\tLoss: 1.034851\n","Train Epoch: 1 [160/1374 (12%)]\tLoss: 0.840257\n","Train Epoch: 1 [170/1374 (12%)]\tLoss: 0.835955\n","Train Epoch: 1 [180/1374 (13%)]\tLoss: 1.099810\n","Train Epoch: 1 [190/1374 (14%)]\tLoss: 0.801794\n","Train Epoch: 1 [200/1374 (15%)]\tLoss: 0.634672\n","Train Epoch: 1 [210/1374 (15%)]\tLoss: 1.115752\n","Train Epoch: 1 [220/1374 (16%)]\tLoss: 0.904132\n","Train Epoch: 1 [230/1374 (17%)]\tLoss: 0.767881\n","Train Epoch: 1 [240/1374 (17%)]\tLoss: 1.470306\n","Train Epoch: 1 [250/1374 (18%)]\tLoss: 1.567931\n","Train Epoch: 1 [260/1374 (19%)]\tLoss: 1.491788\n","Train Epoch: 1 [270/1374 (20%)]\tLoss: 0.770401\n","Train Epoch: 1 [280/1374 (20%)]\tLoss: 1.048709\n","Train Epoch: 1 [290/1374 (21%)]\tLoss: 0.901152\n","Train Epoch: 1 [300/1374 (22%)]\tLoss: 0.703729\n","Train Epoch: 1 [310/1374 (23%)]\tLoss: 1.343382\n","Train Epoch: 1 [320/1374 (23%)]\tLoss: 1.333421\n","Train Epoch: 1 [330/1374 (24%)]\tLoss: 0.667641\n","Train Epoch: 1 [340/1374 (25%)]\tLoss: 0.836710\n","Train Epoch: 1 [350/1374 (25%)]\tLoss: 1.316092\n","Train Epoch: 1 [360/1374 (26%)]\tLoss: 1.125886\n","Train Epoch: 1 [370/1374 (27%)]\tLoss: 0.524139\n","Train Epoch: 1 [380/1374 (28%)]\tLoss: 1.163558\n","Train Epoch: 1 [390/1374 (28%)]\tLoss: 1.028280\n","Train Epoch: 1 [400/1374 (29%)]\tLoss: 0.565101\n","Train Epoch: 1 [410/1374 (30%)]\tLoss: 0.737234\n","Train Epoch: 1 [420/1374 (31%)]\tLoss: 0.800395\n","Train Epoch: 1 [430/1374 (31%)]\tLoss: 0.779493\n","Train Epoch: 1 [440/1374 (32%)]\tLoss: 1.080556\n","Train Epoch: 1 [450/1374 (33%)]\tLoss: 1.133277\n","Train Epoch: 1 [460/1374 (33%)]\tLoss: 0.720744\n","Train Epoch: 1 [470/1374 (34%)]\tLoss: 0.964849\n","Train Epoch: 1 [480/1374 (35%)]\tLoss: 0.441536\n","Train Epoch: 1 [490/1374 (36%)]\tLoss: 0.546880\n","Train Epoch: 1 [500/1374 (36%)]\tLoss: 0.580996\n","Train Epoch: 1 [510/1374 (37%)]\tLoss: 1.102728\n","Train Epoch: 1 [520/1374 (38%)]\tLoss: 1.062036\n","Train Epoch: 1 [530/1374 (39%)]\tLoss: 1.169636\n","Train Epoch: 1 [540/1374 (39%)]\tLoss: 0.765575\n","Train Epoch: 1 [550/1374 (40%)]\tLoss: 0.360634\n","Train Epoch: 1 [560/1374 (41%)]\tLoss: 0.531695\n","Train Epoch: 1 [570/1374 (41%)]\tLoss: 0.983308\n","Train Epoch: 1 [580/1374 (42%)]\tLoss: 0.499971\n","Train Epoch: 1 [590/1374 (43%)]\tLoss: 0.820689\n","Train Epoch: 1 [600/1374 (44%)]\tLoss: 0.973427\n","Train Epoch: 1 [610/1374 (44%)]\tLoss: 1.058365\n","Train Epoch: 1 [620/1374 (45%)]\tLoss: 1.292139\n","Train Epoch: 1 [630/1374 (46%)]\tLoss: 1.735733\n","Train Epoch: 1 [640/1374 (47%)]\tLoss: 0.598514\n","Train Epoch: 1 [650/1374 (47%)]\tLoss: 0.940545\n","Train Epoch: 1 [660/1374 (48%)]\tLoss: 0.812593\n","Train Epoch: 1 [670/1374 (49%)]\tLoss: 0.694364\n","Train Epoch: 1 [680/1374 (49%)]\tLoss: 1.367067\n","Train Epoch: 1 [690/1374 (50%)]\tLoss: 0.608391\n","Train Epoch: 1 [700/1374 (51%)]\tLoss: 1.075799\n","Train Epoch: 1 [710/1374 (52%)]\tLoss: 0.918979\n","Train Epoch: 1 [720/1374 (52%)]\tLoss: 0.904719\n","Train Epoch: 1 [730/1374 (53%)]\tLoss: 1.491934\n","Train Epoch: 1 [740/1374 (54%)]\tLoss: 1.205439\n","Train Epoch: 1 [750/1374 (55%)]\tLoss: 1.142642\n","Train Epoch: 1 [760/1374 (55%)]\tLoss: 0.949031\n","Train Epoch: 1 [770/1374 (56%)]\tLoss: 0.642584\n","Train Epoch: 1 [780/1374 (57%)]\tLoss: 1.147379\n","Train Epoch: 1 [790/1374 (57%)]\tLoss: 1.020893\n","Train Epoch: 1 [800/1374 (58%)]\tLoss: 1.294150\n","Train Epoch: 1 [810/1374 (59%)]\tLoss: 1.313002\n","Train Epoch: 1 [820/1374 (60%)]\tLoss: 1.247441\n","Train Epoch: 1 [830/1374 (60%)]\tLoss: 0.963362\n","Train Epoch: 1 [840/1374 (61%)]\tLoss: 0.858112\n","Train Epoch: 1 [850/1374 (62%)]\tLoss: 1.073359\n","Train Epoch: 1 [860/1374 (63%)]\tLoss: 0.984734\n","Train Epoch: 1 [870/1374 (63%)]\tLoss: 0.818031\n","Train Epoch: 1 [880/1374 (64%)]\tLoss: 0.564457\n","Train Epoch: 1 [890/1374 (65%)]\tLoss: 0.753012\n","Train Epoch: 1 [900/1374 (66%)]\tLoss: 0.955806\n","Train Epoch: 1 [910/1374 (66%)]\tLoss: 1.138345\n","Train Epoch: 1 [920/1374 (67%)]\tLoss: 1.276029\n","Train Epoch: 1 [930/1374 (68%)]\tLoss: 0.935397\n","Train Epoch: 1 [940/1374 (68%)]\tLoss: 0.872705\n","Train Epoch: 1 [950/1374 (69%)]\tLoss: 0.651133\n","Train Epoch: 1 [960/1374 (70%)]\tLoss: 0.442313\n","Train Epoch: 1 [970/1374 (71%)]\tLoss: 1.051392\n","Train Epoch: 1 [980/1374 (71%)]\tLoss: 0.856306\n","Train Epoch: 1 [990/1374 (72%)]\tLoss: 1.285691\n","Train Epoch: 1 [1000/1374 (73%)]\tLoss: 0.640207\n","Train Epoch: 1 [1010/1374 (74%)]\tLoss: 0.610247\n","Train Epoch: 1 [1020/1374 (74%)]\tLoss: 1.364082\n","Train Epoch: 1 [1030/1374 (75%)]\tLoss: 1.263944\n","Train Epoch: 1 [1040/1374 (76%)]\tLoss: 1.072042\n","Train Epoch: 1 [1050/1374 (76%)]\tLoss: 0.990033\n","Train Epoch: 1 [1060/1374 (77%)]\tLoss: 1.164017\n","Train Epoch: 1 [1070/1374 (78%)]\tLoss: 0.527949\n","Train Epoch: 1 [1080/1374 (79%)]\tLoss: 1.088635\n","Train Epoch: 1 [1090/1374 (79%)]\tLoss: 0.896328\n","Train Epoch: 1 [1100/1374 (80%)]\tLoss: 1.106783\n","Train Epoch: 1 [1110/1374 (81%)]\tLoss: 1.367483\n","Train Epoch: 1 [1120/1374 (82%)]\tLoss: 0.946775\n","Train Epoch: 1 [1130/1374 (82%)]\tLoss: 0.994922\n","Train Epoch: 1 [1140/1374 (83%)]\tLoss: 0.483315\n","Train Epoch: 1 [1150/1374 (84%)]\tLoss: 0.764751\n","Train Epoch: 1 [1160/1374 (84%)]\tLoss: 0.908687\n","Train Epoch: 1 [1170/1374 (85%)]\tLoss: 0.834249\n","Train Epoch: 1 [1180/1374 (86%)]\tLoss: 0.675191\n","Train Epoch: 1 [1190/1374 (87%)]\tLoss: 0.842771\n","Train Epoch: 1 [1200/1374 (87%)]\tLoss: 0.588269\n","Train Epoch: 1 [1210/1374 (88%)]\tLoss: 1.285826\n","Train Epoch: 1 [1220/1374 (89%)]\tLoss: 1.419192\n","Train Epoch: 1 [1230/1374 (90%)]\tLoss: 1.435882\n","Train Epoch: 1 [1240/1374 (90%)]\tLoss: 0.692596\n","Train Epoch: 1 [1250/1374 (91%)]\tLoss: 1.237212\n","Train Epoch: 1 [1260/1374 (92%)]\tLoss: 0.833864\n","Train Epoch: 1 [1270/1374 (92%)]\tLoss: 1.028014\n","Train Epoch: 1 [1280/1374 (93%)]\tLoss: 1.092970\n","Train Epoch: 1 [1290/1374 (94%)]\tLoss: 1.110006\n","Train Epoch: 1 [1300/1374 (95%)]\tLoss: 1.249504\n","Train Epoch: 1 [1310/1374 (95%)]\tLoss: 0.862670\n","Train Epoch: 1 [1320/1374 (96%)]\tLoss: 1.594800\n","Train Epoch: 1 [1330/1374 (97%)]\tLoss: 1.270492\n","Train Epoch: 1 [1340/1374 (98%)]\tLoss: 0.837695\n","Train Epoch: 1 [1350/1374 (98%)]\tLoss: 0.798438\n","Train Epoch: 1 [1360/1374 (99%)]\tLoss: 0.640323\n","Train Epoch: 1 [1370/1374 (100%)]\tLoss: 0.797757\n","\n","Train Epoch: 2 [10/1374 (1%)]\tLoss: 0.650557\n","Train Epoch: 2 [20/1374 (1%)]\tLoss: 0.723162\n","Train Epoch: 2 [30/1374 (2%)]\tLoss: 0.827222\n","Train Epoch: 2 [40/1374 (3%)]\tLoss: 0.754702\n","Train Epoch: 2 [50/1374 (4%)]\tLoss: 0.743304\n","Train Epoch: 2 [60/1374 (4%)]\tLoss: 1.014621\n","Train Epoch: 2 [70/1374 (5%)]\tLoss: 0.793759\n","Train Epoch: 2 [80/1374 (6%)]\tLoss: 0.857858\n","Train Epoch: 2 [90/1374 (7%)]\tLoss: 0.536440\n","Train Epoch: 2 [100/1374 (7%)]\tLoss: 0.882190\n","Train Epoch: 2 [110/1374 (8%)]\tLoss: 1.165359\n","Train Epoch: 2 [120/1374 (9%)]\tLoss: 0.580296\n","Train Epoch: 2 [130/1374 (9%)]\tLoss: 0.599362\n","Train Epoch: 2 [140/1374 (10%)]\tLoss: 0.587640\n","Train Epoch: 2 [150/1374 (11%)]\tLoss: 0.507326\n","Train Epoch: 2 [160/1374 (12%)]\tLoss: 1.083814\n","Train Epoch: 2 [170/1374 (12%)]\tLoss: 0.642720\n","Train Epoch: 2 [180/1374 (13%)]\tLoss: 1.026578\n","Train Epoch: 2 [190/1374 (14%)]\tLoss: 0.811808\n","Train Epoch: 2 [200/1374 (15%)]\tLoss: 0.661506\n","Train Epoch: 2 [210/1374 (15%)]\tLoss: 0.688340\n","Train Epoch: 2 [220/1374 (16%)]\tLoss: 0.622201\n","Train Epoch: 2 [230/1374 (17%)]\tLoss: 1.237341\n","Train Epoch: 2 [240/1374 (17%)]\tLoss: 1.074206\n","Train Epoch: 2 [250/1374 (18%)]\tLoss: 0.306737\n","Train Epoch: 2 [260/1374 (19%)]\tLoss: 1.230161\n","Train Epoch: 2 [270/1374 (20%)]\tLoss: 1.226580\n","Train Epoch: 2 [280/1374 (20%)]\tLoss: 1.413886\n","Train Epoch: 2 [290/1374 (21%)]\tLoss: 0.603513\n","Train Epoch: 2 [300/1374 (22%)]\tLoss: 1.034332\n","Train Epoch: 2 [310/1374 (23%)]\tLoss: 0.588063\n","Train Epoch: 2 [320/1374 (23%)]\tLoss: 0.330945\n","Train Epoch: 2 [330/1374 (24%)]\tLoss: 0.817407\n","Train Epoch: 2 [340/1374 (25%)]\tLoss: 0.943665\n","Train Epoch: 2 [350/1374 (25%)]\tLoss: 1.364552\n","Train Epoch: 2 [360/1374 (26%)]\tLoss: 1.347574\n","Train Epoch: 2 [370/1374 (27%)]\tLoss: 1.069063\n","Train Epoch: 2 [380/1374 (28%)]\tLoss: 0.742302\n","Train Epoch: 2 [390/1374 (28%)]\tLoss: 1.266971\n","Train Epoch: 2 [400/1374 (29%)]\tLoss: 1.596046\n","Train Epoch: 2 [410/1374 (30%)]\tLoss: 0.955893\n","Train Epoch: 2 [420/1374 (31%)]\tLoss: 0.991341\n","Train Epoch: 2 [430/1374 (31%)]\tLoss: 0.554890\n","Train Epoch: 2 [440/1374 (32%)]\tLoss: 0.870104\n","Train Epoch: 2 [450/1374 (33%)]\tLoss: 1.004539\n","Train Epoch: 2 [460/1374 (33%)]\tLoss: 0.981617\n","Train Epoch: 2 [470/1374 (34%)]\tLoss: 0.903890\n","Train Epoch: 2 [480/1374 (35%)]\tLoss: 0.906890\n","Train Epoch: 2 [490/1374 (36%)]\tLoss: 0.787090\n","Train Epoch: 2 [500/1374 (36%)]\tLoss: 0.722140\n","Train Epoch: 2 [510/1374 (37%)]\tLoss: 1.183575\n","Train Epoch: 2 [520/1374 (38%)]\tLoss: 0.721043\n","Train Epoch: 2 [530/1374 (39%)]\tLoss: 0.671983\n","Train Epoch: 2 [540/1374 (39%)]\tLoss: 1.007885\n","Train Epoch: 2 [550/1374 (40%)]\tLoss: 0.546580\n","Train Epoch: 2 [560/1374 (41%)]\tLoss: 0.916755\n","Train Epoch: 2 [570/1374 (41%)]\tLoss: 0.861553\n","Train Epoch: 2 [580/1374 (42%)]\tLoss: 0.983193\n","Train Epoch: 2 [590/1374 (43%)]\tLoss: 1.027145\n","Train Epoch: 2 [600/1374 (44%)]\tLoss: 0.858208\n","Train Epoch: 2 [610/1374 (44%)]\tLoss: 0.993019\n","Train Epoch: 2 [620/1374 (45%)]\tLoss: 1.271999\n","Train Epoch: 2 [630/1374 (46%)]\tLoss: 0.897805\n","Train Epoch: 2 [640/1374 (47%)]\tLoss: 1.017589\n","Train Epoch: 2 [650/1374 (47%)]\tLoss: 0.868559\n","Train Epoch: 2 [660/1374 (48%)]\tLoss: 0.952665\n","Train Epoch: 2 [670/1374 (49%)]\tLoss: 0.924900\n","Train Epoch: 2 [680/1374 (49%)]\tLoss: 1.058827\n","Train Epoch: 2 [690/1374 (50%)]\tLoss: 1.038552\n","Train Epoch: 2 [700/1374 (51%)]\tLoss: 0.915649\n","Train Epoch: 2 [710/1374 (52%)]\tLoss: 0.522054\n","Train Epoch: 2 [720/1374 (52%)]\tLoss: 0.477007\n","Train Epoch: 2 [730/1374 (53%)]\tLoss: 0.994743\n","Train Epoch: 2 [740/1374 (54%)]\tLoss: 0.880837\n","Train Epoch: 2 [750/1374 (55%)]\tLoss: 0.789737\n","Train Epoch: 2 [760/1374 (55%)]\tLoss: 0.988230\n","Train Epoch: 2 [770/1374 (56%)]\tLoss: 0.837668\n","Train Epoch: 2 [780/1374 (57%)]\tLoss: 1.155992\n","Train Epoch: 2 [790/1374 (57%)]\tLoss: 0.830493\n","Train Epoch: 2 [800/1374 (58%)]\tLoss: 0.582913\n","Train Epoch: 2 [810/1374 (59%)]\tLoss: 1.614939\n","Train Epoch: 2 [820/1374 (60%)]\tLoss: 1.285882\n","Train Epoch: 2 [830/1374 (60%)]\tLoss: 0.925424\n","Train Epoch: 2 [840/1374 (61%)]\tLoss: 0.807286\n","Train Epoch: 2 [850/1374 (62%)]\tLoss: 0.776380\n","Train Epoch: 2 [860/1374 (63%)]\tLoss: 0.808484\n","Train Epoch: 2 [870/1374 (63%)]\tLoss: 0.378043\n","Train Epoch: 2 [880/1374 (64%)]\tLoss: 1.453564\n","Train Epoch: 2 [890/1374 (65%)]\tLoss: 1.061406\n","Train Epoch: 2 [900/1374 (66%)]\tLoss: 0.551401\n","Train Epoch: 2 [910/1374 (66%)]\tLoss: 1.159099\n","Train Epoch: 2 [920/1374 (67%)]\tLoss: 0.690790\n","Train Epoch: 2 [930/1374 (68%)]\tLoss: 1.410430\n","Train Epoch: 2 [940/1374 (68%)]\tLoss: 0.687487\n","Train Epoch: 2 [950/1374 (69%)]\tLoss: 0.372266\n","Train Epoch: 2 [960/1374 (70%)]\tLoss: 0.960189\n","Train Epoch: 2 [970/1374 (71%)]\tLoss: 1.019310\n","Train Epoch: 2 [980/1374 (71%)]\tLoss: 1.169104\n","Train Epoch: 2 [990/1374 (72%)]\tLoss: 0.630834\n","Train Epoch: 2 [1000/1374 (73%)]\tLoss: 0.724579\n","Train Epoch: 2 [1010/1374 (74%)]\tLoss: 0.809957\n","Train Epoch: 2 [1020/1374 (74%)]\tLoss: 0.813454\n","Train Epoch: 2 [1030/1374 (75%)]\tLoss: 1.288435\n","Train Epoch: 2 [1040/1374 (76%)]\tLoss: 1.007949\n","Train Epoch: 2 [1050/1374 (76%)]\tLoss: 1.076186\n","Train Epoch: 2 [1060/1374 (77%)]\tLoss: 0.770401\n","Train Epoch: 2 [1070/1374 (78%)]\tLoss: 0.539736\n","Train Epoch: 2 [1080/1374 (79%)]\tLoss: 0.768057\n","Train Epoch: 2 [1090/1374 (79%)]\tLoss: 1.668159\n","Train Epoch: 2 [1100/1374 (80%)]\tLoss: 0.716244\n","Train Epoch: 2 [1110/1374 (81%)]\tLoss: 0.747952\n","Train Epoch: 2 [1120/1374 (82%)]\tLoss: 1.212144\n","Train Epoch: 2 [1130/1374 (82%)]\tLoss: 1.062938\n","Train Epoch: 2 [1140/1374 (83%)]\tLoss: 0.828806\n","Train Epoch: 2 [1150/1374 (84%)]\tLoss: 1.110184\n","Train Epoch: 2 [1160/1374 (84%)]\tLoss: 0.951676\n","Train Epoch: 2 [1170/1374 (85%)]\tLoss: 0.971805\n","Train Epoch: 2 [1180/1374 (86%)]\tLoss: 1.330171\n","Train Epoch: 2 [1190/1374 (87%)]\tLoss: 1.000197\n","Train Epoch: 2 [1200/1374 (87%)]\tLoss: 0.975038\n","Train Epoch: 2 [1210/1374 (88%)]\tLoss: 0.977937\n","Train Epoch: 2 [1220/1374 (89%)]\tLoss: 1.140833\n","Train Epoch: 2 [1230/1374 (90%)]\tLoss: 0.732133\n","Train Epoch: 2 [1240/1374 (90%)]\tLoss: 0.634394\n","Train Epoch: 2 [1250/1374 (91%)]\tLoss: 1.303789\n","Train Epoch: 2 [1260/1374 (92%)]\tLoss: 1.010498\n","Train Epoch: 2 [1270/1374 (92%)]\tLoss: 0.715953\n","Train Epoch: 2 [1280/1374 (93%)]\tLoss: 1.030484\n","Train Epoch: 2 [1290/1374 (94%)]\tLoss: 0.858398\n","Train Epoch: 2 [1300/1374 (95%)]\tLoss: 0.923669\n","Train Epoch: 2 [1310/1374 (95%)]\tLoss: 1.127492\n","Train Epoch: 2 [1320/1374 (96%)]\tLoss: 0.778587\n","Train Epoch: 2 [1330/1374 (97%)]\tLoss: 0.920188\n","Train Epoch: 2 [1340/1374 (98%)]\tLoss: 1.030167\n","Train Epoch: 2 [1350/1374 (98%)]\tLoss: 1.091331\n","Train Epoch: 2 [1360/1374 (99%)]\tLoss: 0.632498\n","Train Epoch: 2 [1370/1374 (100%)]\tLoss: 0.903564\n","Acc 0.487\n","0.48653321201091904\n","Acc 0.505\n","0.504730713245997\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n","\n","Train Epoch: 1 [10/1374 (1%)]\tLoss: 3.229981\n","Train Epoch: 1 [20/1374 (1%)]\tLoss: 0.884662\n","Train Epoch: 1 [30/1374 (2%)]\tLoss: 1.627972\n","Train Epoch: 1 [40/1374 (3%)]\tLoss: 1.062229\n","Train Epoch: 1 [50/1374 (4%)]\tLoss: 1.222311\n","Train Epoch: 1 [60/1374 (4%)]\tLoss: 0.936464\n","Train Epoch: 1 [70/1374 (5%)]\tLoss: 1.171444\n","Train Epoch: 1 [80/1374 (6%)]\tLoss: 1.023292\n","Train Epoch: 1 [90/1374 (7%)]\tLoss: 1.031242\n","Train Epoch: 1 [100/1374 (7%)]\tLoss: 0.704411\n","Train Epoch: 1 [110/1374 (8%)]\tLoss: 1.071424\n","Train Epoch: 1 [120/1374 (9%)]\tLoss: 0.608321\n","Train Epoch: 1 [130/1374 (9%)]\tLoss: 0.938381\n","Train Epoch: 1 [140/1374 (10%)]\tLoss: 1.392628\n","Train Epoch: 1 [150/1374 (11%)]\tLoss: 0.986003\n","Train Epoch: 1 [160/1374 (12%)]\tLoss: 1.196683\n","Train Epoch: 1 [170/1374 (12%)]\tLoss: 0.301595\n","Train Epoch: 1 [180/1374 (13%)]\tLoss: 0.474613\n","Train Epoch: 1 [190/1374 (14%)]\tLoss: 0.527872\n","Train Epoch: 1 [200/1374 (15%)]\tLoss: 0.322585\n","Train Epoch: 1 [210/1374 (15%)]\tLoss: 0.727916\n","Train Epoch: 1 [220/1374 (16%)]\tLoss: 0.394541\n","Train Epoch: 1 [230/1374 (17%)]\tLoss: 1.297818\n","Train Epoch: 1 [240/1374 (17%)]\tLoss: 1.271297\n","Train Epoch: 1 [250/1374 (18%)]\tLoss: 0.640813\n","Train Epoch: 1 [260/1374 (19%)]\tLoss: 1.427669\n","Train Epoch: 1 [270/1374 (20%)]\tLoss: 1.294605\n","Train Epoch: 1 [280/1374 (20%)]\tLoss: 1.017890\n","Train Epoch: 1 [290/1374 (21%)]\tLoss: 0.888383\n","Train Epoch: 1 [300/1374 (22%)]\tLoss: 0.854628\n","Train Epoch: 1 [310/1374 (23%)]\tLoss: 0.336168\n","Train Epoch: 1 [320/1374 (23%)]\tLoss: 0.771733\n","Train Epoch: 1 [330/1374 (24%)]\tLoss: 0.819742\n","Train Epoch: 1 [340/1374 (25%)]\tLoss: 0.730473\n","Train Epoch: 1 [350/1374 (25%)]\tLoss: 0.593760\n","Train Epoch: 1 [360/1374 (26%)]\tLoss: 0.592355\n","Train Epoch: 1 [370/1374 (27%)]\tLoss: 0.344562\n","Train Epoch: 1 [380/1374 (28%)]\tLoss: 1.092049\n","Train Epoch: 1 [390/1374 (28%)]\tLoss: 1.341145\n","Train Epoch: 1 [400/1374 (29%)]\tLoss: 1.036703\n","Train Epoch: 1 [410/1374 (30%)]\tLoss: 0.808233\n","Train Epoch: 1 [420/1374 (31%)]\tLoss: 0.547995\n","Train Epoch: 1 [430/1374 (31%)]\tLoss: 0.969990\n","Train Epoch: 1 [440/1374 (32%)]\tLoss: 0.801381\n","Train Epoch: 1 [450/1374 (33%)]\tLoss: 0.740611\n","Train Epoch: 1 [460/1374 (33%)]\tLoss: 0.898867\n","Train Epoch: 1 [470/1374 (34%)]\tLoss: 0.910815\n","Train Epoch: 1 [480/1374 (35%)]\tLoss: 0.834727\n","Train Epoch: 1 [490/1374 (36%)]\tLoss: 1.122307\n","Train Epoch: 1 [500/1374 (36%)]\tLoss: 1.174482\n","Train Epoch: 1 [510/1374 (37%)]\tLoss: 0.962035\n","Train Epoch: 1 [520/1374 (38%)]\tLoss: 1.408598\n","Train Epoch: 1 [530/1374 (39%)]\tLoss: 1.031302\n","Train Epoch: 1 [540/1374 (39%)]\tLoss: 0.950334\n","Train Epoch: 1 [550/1374 (40%)]\tLoss: 1.063776\n","Train Epoch: 1 [560/1374 (41%)]\tLoss: 1.082889\n","Train Epoch: 1 [570/1374 (41%)]\tLoss: 1.107789\n","Train Epoch: 1 [580/1374 (42%)]\tLoss: 0.713557\n","Train Epoch: 1 [590/1374 (43%)]\tLoss: 1.528838\n","Train Epoch: 1 [600/1374 (44%)]\tLoss: 1.311429\n","Train Epoch: 1 [610/1374 (44%)]\tLoss: 0.720202\n","Train Epoch: 1 [620/1374 (45%)]\tLoss: 0.698903\n","Train Epoch: 1 [630/1374 (46%)]\tLoss: 0.858705\n","Train Epoch: 1 [640/1374 (47%)]\tLoss: 0.817616\n","Train Epoch: 1 [650/1374 (47%)]\tLoss: 0.742165\n","Train Epoch: 1 [660/1374 (48%)]\tLoss: 0.808831\n","Train Epoch: 1 [670/1374 (49%)]\tLoss: 1.173961\n","Train Epoch: 1 [680/1374 (49%)]\tLoss: 0.952414\n","Train Epoch: 1 [690/1374 (50%)]\tLoss: 0.639831\n","Train Epoch: 1 [700/1374 (51%)]\tLoss: 0.739459\n","Train Epoch: 1 [710/1374 (52%)]\tLoss: 0.408617\n","Train Epoch: 1 [720/1374 (52%)]\tLoss: 0.998799\n","Train Epoch: 1 [730/1374 (53%)]\tLoss: 0.717871\n","Train Epoch: 1 [740/1374 (54%)]\tLoss: 0.624685\n","Train Epoch: 1 [750/1374 (55%)]\tLoss: 0.924487\n","Train Epoch: 1 [760/1374 (55%)]\tLoss: 0.721218\n","Train Epoch: 1 [770/1374 (56%)]\tLoss: 1.066702\n","Train Epoch: 1 [780/1374 (57%)]\tLoss: 1.365280\n","Train Epoch: 1 [790/1374 (57%)]\tLoss: 0.993711\n","Train Epoch: 1 [800/1374 (58%)]\tLoss: 0.884458\n","Train Epoch: 1 [810/1374 (59%)]\tLoss: 1.510975\n","Train Epoch: 1 [820/1374 (60%)]\tLoss: 1.019373\n","Train Epoch: 1 [830/1374 (60%)]\tLoss: 1.378984\n","Train Epoch: 1 [840/1374 (61%)]\tLoss: 1.628962\n","Train Epoch: 1 [850/1374 (62%)]\tLoss: 0.555615\n","Train Epoch: 1 [860/1374 (63%)]\tLoss: 0.902702\n","Train Epoch: 1 [870/1374 (63%)]\tLoss: 0.791488\n","Train Epoch: 1 [880/1374 (64%)]\tLoss: 0.738474\n","Train Epoch: 1 [890/1374 (65%)]\tLoss: 1.039376\n","Train Epoch: 1 [900/1374 (66%)]\tLoss: 0.874053\n","Train Epoch: 1 [910/1374 (66%)]\tLoss: 0.976226\n","Train Epoch: 1 [920/1374 (67%)]\tLoss: 0.904642\n","Train Epoch: 1 [930/1374 (68%)]\tLoss: 1.507956\n","Train Epoch: 1 [940/1374 (68%)]\tLoss: 0.595197\n","Train Epoch: 1 [950/1374 (69%)]\tLoss: 0.795192\n","Train Epoch: 1 [960/1374 (70%)]\tLoss: 0.610798\n","Train Epoch: 1 [970/1374 (71%)]\tLoss: 0.934486\n","Train Epoch: 1 [980/1374 (71%)]\tLoss: 1.010695\n","Train Epoch: 1 [990/1374 (72%)]\tLoss: 1.574077\n","Train Epoch: 1 [1000/1374 (73%)]\tLoss: 1.066813\n","Train Epoch: 1 [1010/1374 (74%)]\tLoss: 0.627115\n","Train Epoch: 1 [1020/1374 (74%)]\tLoss: 1.065832\n","Train Epoch: 1 [1030/1374 (75%)]\tLoss: 0.839028\n","Train Epoch: 1 [1040/1374 (76%)]\tLoss: 0.797892\n","Train Epoch: 1 [1050/1374 (76%)]\tLoss: 0.970539\n","Train Epoch: 1 [1060/1374 (77%)]\tLoss: 0.651936\n","Train Epoch: 1 [1070/1374 (78%)]\tLoss: 1.213141\n","Train Epoch: 1 [1080/1374 (79%)]\tLoss: 0.869219\n","Train Epoch: 1 [1090/1374 (79%)]\tLoss: 0.993823\n","Train Epoch: 1 [1100/1374 (80%)]\tLoss: 0.845534\n","Train Epoch: 1 [1110/1374 (81%)]\tLoss: 0.840342\n","Train Epoch: 1 [1120/1374 (82%)]\tLoss: 1.032938\n","Train Epoch: 1 [1130/1374 (82%)]\tLoss: 1.021923\n","Train Epoch: 1 [1140/1374 (83%)]\tLoss: 0.560403\n","Train Epoch: 1 [1150/1374 (84%)]\tLoss: 1.061929\n","Train Epoch: 1 [1160/1374 (84%)]\tLoss: 0.726688\n","Train Epoch: 1 [1170/1374 (85%)]\tLoss: 1.046437\n","Train Epoch: 1 [1180/1374 (86%)]\tLoss: 0.376689\n","Train Epoch: 1 [1190/1374 (87%)]\tLoss: 0.714840\n","Train Epoch: 1 [1200/1374 (87%)]\tLoss: 1.171234\n","Train Epoch: 1 [1210/1374 (88%)]\tLoss: 1.186473\n","Train Epoch: 1 [1220/1374 (89%)]\tLoss: 0.562247\n","Train Epoch: 1 [1230/1374 (90%)]\tLoss: 1.099882\n","Train Epoch: 1 [1240/1374 (90%)]\tLoss: 1.454196\n","Train Epoch: 1 [1250/1374 (91%)]\tLoss: 1.164194\n","Train Epoch: 1 [1260/1374 (92%)]\tLoss: 0.426040\n","Train Epoch: 1 [1270/1374 (92%)]\tLoss: 0.594374\n","Train Epoch: 1 [1280/1374 (93%)]\tLoss: 0.770801\n","Train Epoch: 1 [1290/1374 (94%)]\tLoss: 0.791573\n","Train Epoch: 1 [1300/1374 (95%)]\tLoss: 1.056705\n","Train Epoch: 1 [1310/1374 (95%)]\tLoss: 0.406253\n","Train Epoch: 1 [1320/1374 (96%)]\tLoss: 1.438013\n","Train Epoch: 1 [1330/1374 (97%)]\tLoss: 0.898255\n","Train Epoch: 1 [1340/1374 (98%)]\tLoss: 0.679532\n","Train Epoch: 1 [1350/1374 (98%)]\tLoss: 0.958593\n","Train Epoch: 1 [1360/1374 (99%)]\tLoss: 1.213598\n","Train Epoch: 1 [1370/1374 (100%)]\tLoss: 0.874651\n","\n","Train Epoch: 2 [10/1374 (1%)]\tLoss: 0.825829\n","Train Epoch: 2 [20/1374 (1%)]\tLoss: 1.398515\n","Train Epoch: 2 [30/1374 (2%)]\tLoss: 0.773330\n","Train Epoch: 2 [40/1374 (3%)]\tLoss: 0.916862\n","Train Epoch: 2 [50/1374 (4%)]\tLoss: 1.035019\n","Train Epoch: 2 [60/1374 (4%)]\tLoss: 1.034342\n","Train Epoch: 2 [70/1374 (5%)]\tLoss: 0.990502\n","Train Epoch: 2 [80/1374 (6%)]\tLoss: 0.706893\n","Train Epoch: 2 [90/1374 (7%)]\tLoss: 0.714187\n","Train Epoch: 2 [100/1374 (7%)]\tLoss: 0.827037\n","Train Epoch: 2 [110/1374 (8%)]\tLoss: 0.874646\n","Train Epoch: 2 [120/1374 (9%)]\tLoss: 0.845210\n","Train Epoch: 2 [130/1374 (9%)]\tLoss: 0.943723\n","Train Epoch: 2 [140/1374 (10%)]\tLoss: 0.832100\n","Train Epoch: 2 [150/1374 (11%)]\tLoss: 0.522870\n","Train Epoch: 2 [160/1374 (12%)]\tLoss: 1.168362\n","Train Epoch: 2 [170/1374 (12%)]\tLoss: 0.784005\n","Train Epoch: 2 [180/1374 (13%)]\tLoss: 1.076308\n","Train Epoch: 2 [190/1374 (14%)]\tLoss: 0.636548\n","Train Epoch: 2 [200/1374 (15%)]\tLoss: 1.015455\n","Train Epoch: 2 [210/1374 (15%)]\tLoss: 0.886570\n","Train Epoch: 2 [220/1374 (16%)]\tLoss: 0.902314\n","Train Epoch: 2 [230/1374 (17%)]\tLoss: 1.026894\n","Train Epoch: 2 [240/1374 (17%)]\tLoss: 1.018773\n","Train Epoch: 2 [250/1374 (18%)]\tLoss: 1.022206\n","Train Epoch: 2 [260/1374 (19%)]\tLoss: 0.927890\n","Train Epoch: 2 [270/1374 (20%)]\tLoss: 0.893450\n","Train Epoch: 2 [280/1374 (20%)]\tLoss: 1.150863\n","Train Epoch: 2 [290/1374 (21%)]\tLoss: 1.216524\n","Train Epoch: 2 [300/1374 (22%)]\tLoss: 1.456944\n","Train Epoch: 2 [310/1374 (23%)]\tLoss: 1.103960\n","Train Epoch: 2 [320/1374 (23%)]\tLoss: 0.951553\n","Train Epoch: 2 [330/1374 (24%)]\tLoss: 1.098487\n","Train Epoch: 2 [340/1374 (25%)]\tLoss: 1.135894\n","Train Epoch: 2 [350/1374 (25%)]\tLoss: 0.890600\n","Train Epoch: 2 [360/1374 (26%)]\tLoss: 0.795746\n","Train Epoch: 2 [370/1374 (27%)]\tLoss: 0.906013\n","Train Epoch: 2 [380/1374 (28%)]\tLoss: 0.952411\n","Train Epoch: 2 [390/1374 (28%)]\tLoss: 1.623734\n","Train Epoch: 2 [400/1374 (29%)]\tLoss: 0.497271\n","Train Epoch: 2 [410/1374 (30%)]\tLoss: 1.288780\n","Train Epoch: 2 [420/1374 (31%)]\tLoss: 0.785725\n","Train Epoch: 2 [430/1374 (31%)]\tLoss: 0.852793\n","Train Epoch: 2 [440/1374 (32%)]\tLoss: 0.642735\n","Train Epoch: 2 [450/1374 (33%)]\tLoss: 1.132390\n","Train Epoch: 2 [460/1374 (33%)]\tLoss: 0.810919\n","Train Epoch: 2 [470/1374 (34%)]\tLoss: 1.140093\n","Train Epoch: 2 [480/1374 (35%)]\tLoss: 0.564402\n","Train Epoch: 2 [490/1374 (36%)]\tLoss: 1.016897\n","Train Epoch: 2 [500/1374 (36%)]\tLoss: 0.350983\n","Train Epoch: 2 [510/1374 (37%)]\tLoss: 1.477691\n","Train Epoch: 2 [520/1374 (38%)]\tLoss: 1.359319\n","Train Epoch: 2 [530/1374 (39%)]\tLoss: 1.079205\n","Train Epoch: 2 [540/1374 (39%)]\tLoss: 1.131148\n","Train Epoch: 2 [550/1374 (40%)]\tLoss: 1.412862\n","Train Epoch: 2 [560/1374 (41%)]\tLoss: 1.185262\n","Train Epoch: 2 [570/1374 (41%)]\tLoss: 1.087901\n","Train Epoch: 2 [580/1374 (42%)]\tLoss: 1.094797\n","Train Epoch: 2 [590/1374 (43%)]\tLoss: 1.047432\n","Train Epoch: 2 [600/1374 (44%)]\tLoss: 0.930075\n","Train Epoch: 2 [610/1374 (44%)]\tLoss: 0.887849\n","Train Epoch: 2 [620/1374 (45%)]\tLoss: 0.404812\n","Train Epoch: 2 [630/1374 (46%)]\tLoss: 1.038103\n","Train Epoch: 2 [640/1374 (47%)]\tLoss: 0.813500\n","Train Epoch: 2 [650/1374 (47%)]\tLoss: 1.048643\n","Train Epoch: 2 [660/1374 (48%)]\tLoss: 0.860670\n","Train Epoch: 2 [670/1374 (49%)]\tLoss: 0.749717\n","Train Epoch: 2 [680/1374 (49%)]\tLoss: 1.309416\n","Train Epoch: 2 [690/1374 (50%)]\tLoss: 0.627361\n","Train Epoch: 2 [700/1374 (51%)]\tLoss: 0.666177\n","Train Epoch: 2 [710/1374 (52%)]\tLoss: 0.796764\n","Train Epoch: 2 [720/1374 (52%)]\tLoss: 0.828216\n","Train Epoch: 2 [730/1374 (53%)]\tLoss: 0.755205\n","Train Epoch: 2 [740/1374 (54%)]\tLoss: 0.853510\n","Train Epoch: 2 [750/1374 (55%)]\tLoss: 0.694720\n","Train Epoch: 2 [760/1374 (55%)]\tLoss: 1.110593\n","Train Epoch: 2 [770/1374 (56%)]\tLoss: 0.522562\n","Train Epoch: 2 [780/1374 (57%)]\tLoss: 0.999280\n","Train Epoch: 2 [790/1374 (57%)]\tLoss: 1.028934\n","Train Epoch: 2 [800/1374 (58%)]\tLoss: 1.147368\n","Train Epoch: 2 [810/1374 (59%)]\tLoss: 1.154619\n","Train Epoch: 2 [820/1374 (60%)]\tLoss: 0.868355\n","Train Epoch: 2 [830/1374 (60%)]\tLoss: 0.797010\n","Train Epoch: 2 [840/1374 (61%)]\tLoss: 0.809169\n","Train Epoch: 2 [850/1374 (62%)]\tLoss: 0.570636\n","Train Epoch: 2 [860/1374 (63%)]\tLoss: 0.768097\n","Train Epoch: 2 [870/1374 (63%)]\tLoss: 0.593076\n","Train Epoch: 2 [880/1374 (64%)]\tLoss: 1.104858\n","Train Epoch: 2 [890/1374 (65%)]\tLoss: 0.736035\n","Train Epoch: 2 [900/1374 (66%)]\tLoss: 0.864016\n","Train Epoch: 2 [910/1374 (66%)]\tLoss: 0.865891\n","Train Epoch: 2 [920/1374 (67%)]\tLoss: 1.005244\n","Train Epoch: 2 [930/1374 (68%)]\tLoss: 0.698918\n","Train Epoch: 2 [940/1374 (68%)]\tLoss: 0.989566\n","Train Epoch: 2 [950/1374 (69%)]\tLoss: 0.950372\n","Train Epoch: 2 [960/1374 (70%)]\tLoss: 0.786053\n","Train Epoch: 2 [970/1374 (71%)]\tLoss: 1.050746\n","Train Epoch: 2 [980/1374 (71%)]\tLoss: 1.487892\n","Train Epoch: 2 [990/1374 (72%)]\tLoss: 0.982984\n","Train Epoch: 2 [1000/1374 (73%)]\tLoss: 0.546283\n","Train Epoch: 2 [1010/1374 (74%)]\tLoss: 1.071782\n","Train Epoch: 2 [1020/1374 (74%)]\tLoss: 0.932091\n","Train Epoch: 2 [1030/1374 (75%)]\tLoss: 1.436683\n","Train Epoch: 2 [1040/1374 (76%)]\tLoss: 0.537977\n","Train Epoch: 2 [1050/1374 (76%)]\tLoss: 1.077602\n","Train Epoch: 2 [1060/1374 (77%)]\tLoss: 1.293351\n","Train Epoch: 2 [1070/1374 (78%)]\tLoss: 1.081171\n","Train Epoch: 2 [1080/1374 (79%)]\tLoss: 0.839787\n","Train Epoch: 2 [1090/1374 (79%)]\tLoss: 0.980357\n","Train Epoch: 2 [1100/1374 (80%)]\tLoss: 0.855909\n","Train Epoch: 2 [1110/1374 (81%)]\tLoss: 1.439931\n","Train Epoch: 2 [1120/1374 (82%)]\tLoss: 0.840374\n","Train Epoch: 2 [1130/1374 (82%)]\tLoss: 1.279367\n","Train Epoch: 2 [1140/1374 (83%)]\tLoss: 0.689689\n","Train Epoch: 2 [1150/1374 (84%)]\tLoss: 1.102856\n","Train Epoch: 2 [1160/1374 (84%)]\tLoss: 0.819551\n","Train Epoch: 2 [1170/1374 (85%)]\tLoss: 0.985342\n","Train Epoch: 2 [1180/1374 (86%)]\tLoss: 0.863724\n","Train Epoch: 2 [1190/1374 (87%)]\tLoss: 0.846813\n","Train Epoch: 2 [1200/1374 (87%)]\tLoss: 0.750159\n","Train Epoch: 2 [1210/1374 (88%)]\tLoss: 0.679107\n","Train Epoch: 2 [1220/1374 (89%)]\tLoss: 0.733381\n","Train Epoch: 2 [1230/1374 (90%)]\tLoss: 0.932724\n","Train Epoch: 2 [1240/1374 (90%)]\tLoss: 0.905488\n","Train Epoch: 2 [1250/1374 (91%)]\tLoss: 0.848436\n","Train Epoch: 2 [1260/1374 (92%)]\tLoss: 0.662095\n","Train Epoch: 2 [1270/1374 (92%)]\tLoss: 0.725095\n","Train Epoch: 2 [1280/1374 (93%)]\tLoss: 0.410132\n","Train Epoch: 2 [1290/1374 (94%)]\tLoss: 0.548928\n","Train Epoch: 2 [1300/1374 (95%)]\tLoss: 1.362548\n","Train Epoch: 2 [1310/1374 (95%)]\tLoss: 1.042007\n","Train Epoch: 2 [1320/1374 (96%)]\tLoss: 1.337505\n","Train Epoch: 2 [1330/1374 (97%)]\tLoss: 0.973697\n","Train Epoch: 2 [1340/1374 (98%)]\tLoss: 0.799890\n","Train Epoch: 2 [1350/1374 (98%)]\tLoss: 0.375082\n","Train Epoch: 2 [1360/1374 (99%)]\tLoss: 0.786773\n","Train Epoch: 2 [1370/1374 (100%)]\tLoss: 0.886400\n","Acc 0.485\n","0.48525932666060057\n","Acc 0.496\n","0.49563318777292575\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n","\n","Train Epoch: 1 [10/1374 (1%)]\tLoss: 5.750261\n","Train Epoch: 1 [20/1374 (1%)]\tLoss: 2.479404\n","Train Epoch: 1 [30/1374 (2%)]\tLoss: 1.241204\n","Train Epoch: 1 [40/1374 (3%)]\tLoss: 1.761586\n","Train Epoch: 1 [50/1374 (4%)]\tLoss: 0.785084\n","Train Epoch: 1 [60/1374 (4%)]\tLoss: 1.436671\n","Train Epoch: 1 [70/1374 (5%)]\tLoss: 1.265064\n","Train Epoch: 1 [80/1374 (6%)]\tLoss: 1.091483\n","Train Epoch: 1 [90/1374 (7%)]\tLoss: 1.154819\n","Train Epoch: 1 [100/1374 (7%)]\tLoss: 1.355450\n","Train Epoch: 1 [110/1374 (8%)]\tLoss: 1.116030\n","Train Epoch: 1 [120/1374 (9%)]\tLoss: 0.692133\n","Train Epoch: 1 [130/1374 (9%)]\tLoss: 1.111783\n","Train Epoch: 1 [140/1374 (10%)]\tLoss: 0.919524\n","Train Epoch: 1 [150/1374 (11%)]\tLoss: 1.535683\n","Train Epoch: 1 [160/1374 (12%)]\tLoss: 0.976476\n","Train Epoch: 1 [170/1374 (12%)]\tLoss: 1.137289\n","Train Epoch: 1 [180/1374 (13%)]\tLoss: 1.307261\n","Train Epoch: 1 [190/1374 (14%)]\tLoss: 1.163611\n","Train Epoch: 1 [200/1374 (15%)]\tLoss: 1.414545\n","Train Epoch: 1 [210/1374 (15%)]\tLoss: 0.798857\n","Train Epoch: 1 [220/1374 (16%)]\tLoss: 0.737913\n","Train Epoch: 1 [230/1374 (17%)]\tLoss: 1.254975\n","Train Epoch: 1 [240/1374 (17%)]\tLoss: 0.622308\n","Train Epoch: 1 [250/1374 (18%)]\tLoss: 0.582166\n","Train Epoch: 1 [260/1374 (19%)]\tLoss: 0.843810\n","Train Epoch: 1 [270/1374 (20%)]\tLoss: 1.475968\n","Train Epoch: 1 [280/1374 (20%)]\tLoss: 0.827558\n","Train Epoch: 1 [290/1374 (21%)]\tLoss: 0.871335\n","Train Epoch: 1 [300/1374 (22%)]\tLoss: 1.159913\n","Train Epoch: 1 [310/1374 (23%)]\tLoss: 0.600896\n","Train Epoch: 1 [320/1374 (23%)]\tLoss: 0.914946\n","Train Epoch: 1 [330/1374 (24%)]\tLoss: 0.625082\n","Train Epoch: 1 [340/1374 (25%)]\tLoss: 1.346656\n","Train Epoch: 1 [350/1374 (25%)]\tLoss: 0.657177\n","Train Epoch: 1 [360/1374 (26%)]\tLoss: 0.945211\n","Train Epoch: 1 [370/1374 (27%)]\tLoss: 0.542856\n","Train Epoch: 1 [380/1374 (28%)]\tLoss: 0.626816\n","Train Epoch: 1 [390/1374 (28%)]\tLoss: 0.733254\n","Train Epoch: 1 [400/1374 (29%)]\tLoss: 1.800087\n","Train Epoch: 1 [410/1374 (30%)]\tLoss: 1.366997\n","Train Epoch: 1 [420/1374 (31%)]\tLoss: 0.981383\n","Train Epoch: 1 [430/1374 (31%)]\tLoss: 0.921883\n","Train Epoch: 1 [440/1374 (32%)]\tLoss: 1.030972\n","Train Epoch: 1 [450/1374 (33%)]\tLoss: 1.092834\n","Train Epoch: 1 [460/1374 (33%)]\tLoss: 0.994422\n","Train Epoch: 1 [470/1374 (34%)]\tLoss: 0.831365\n","Train Epoch: 1 [480/1374 (35%)]\tLoss: 0.556263\n","Train Epoch: 1 [490/1374 (36%)]\tLoss: 0.999337\n","Train Epoch: 1 [500/1374 (36%)]\tLoss: 0.891337\n","Train Epoch: 1 [510/1374 (37%)]\tLoss: 0.679377\n","Train Epoch: 1 [520/1374 (38%)]\tLoss: 1.240903\n","Train Epoch: 1 [530/1374 (39%)]\tLoss: 0.887513\n","Train Epoch: 1 [540/1374 (39%)]\tLoss: 0.656691\n","Train Epoch: 1 [550/1374 (40%)]\tLoss: 1.395316\n","Train Epoch: 1 [560/1374 (41%)]\tLoss: 0.843773\n","Train Epoch: 1 [570/1374 (41%)]\tLoss: 1.257300\n","Train Epoch: 1 [580/1374 (42%)]\tLoss: 1.140136\n","Train Epoch: 1 [590/1374 (43%)]\tLoss: 0.858607\n","Train Epoch: 1 [600/1374 (44%)]\tLoss: 0.864510\n","Train Epoch: 1 [610/1374 (44%)]\tLoss: 0.654679\n","Train Epoch: 1 [620/1374 (45%)]\tLoss: 1.031035\n","Train Epoch: 1 [630/1374 (46%)]\tLoss: 1.099902\n","Train Epoch: 1 [640/1374 (47%)]\tLoss: 1.149506\n","Train Epoch: 1 [650/1374 (47%)]\tLoss: 0.910704\n","Train Epoch: 1 [660/1374 (48%)]\tLoss: 0.810974\n","Train Epoch: 1 [670/1374 (49%)]\tLoss: 0.663895\n","Train Epoch: 1 [680/1374 (49%)]\tLoss: 0.790354\n","Train Epoch: 1 [690/1374 (50%)]\tLoss: 0.605361\n","Train Epoch: 1 [700/1374 (51%)]\tLoss: 0.832627\n","Train Epoch: 1 [710/1374 (52%)]\tLoss: 0.824943\n","Train Epoch: 1 [720/1374 (52%)]\tLoss: 1.410169\n","Train Epoch: 1 [730/1374 (53%)]\tLoss: 0.724024\n","Train Epoch: 1 [740/1374 (54%)]\tLoss: 0.749713\n","Train Epoch: 1 [750/1374 (55%)]\tLoss: 0.523613\n","Train Epoch: 1 [760/1374 (55%)]\tLoss: 0.933807\n","Train Epoch: 1 [770/1374 (56%)]\tLoss: 1.384844\n","Train Epoch: 1 [780/1374 (57%)]\tLoss: 0.874004\n","Train Epoch: 1 [790/1374 (57%)]\tLoss: 0.507805\n","Train Epoch: 1 [800/1374 (58%)]\tLoss: 1.510205\n","Train Epoch: 1 [810/1374 (59%)]\tLoss: 1.071738\n","Train Epoch: 1 [820/1374 (60%)]\tLoss: 1.200849\n","Train Epoch: 1 [830/1374 (60%)]\tLoss: 1.205012\n","Train Epoch: 1 [840/1374 (61%)]\tLoss: 1.073513\n","Train Epoch: 1 [850/1374 (62%)]\tLoss: 0.443222\n","Train Epoch: 1 [860/1374 (63%)]\tLoss: 1.400868\n","Train Epoch: 1 [870/1374 (63%)]\tLoss: 1.589101\n","Train Epoch: 1 [880/1374 (64%)]\tLoss: 0.460360\n","Train Epoch: 1 [890/1374 (65%)]\tLoss: 0.902763\n","Train Epoch: 1 [900/1374 (66%)]\tLoss: 0.937429\n","Train Epoch: 1 [910/1374 (66%)]\tLoss: 0.701037\n","Train Epoch: 1 [920/1374 (67%)]\tLoss: 1.309482\n","Train Epoch: 1 [930/1374 (68%)]\tLoss: 0.511017\n","Train Epoch: 1 [940/1374 (68%)]\tLoss: 0.646815\n","Train Epoch: 1 [950/1374 (69%)]\tLoss: 1.246462\n","Train Epoch: 1 [960/1374 (70%)]\tLoss: 0.916514\n","Train Epoch: 1 [970/1374 (71%)]\tLoss: 0.634867\n","Train Epoch: 1 [980/1374 (71%)]\tLoss: 1.537550\n","Train Epoch: 1 [990/1374 (72%)]\tLoss: 0.723589\n","Train Epoch: 1 [1000/1374 (73%)]\tLoss: 0.688387\n","Train Epoch: 1 [1010/1374 (74%)]\tLoss: 0.951455\n","Train Epoch: 1 [1020/1374 (74%)]\tLoss: 0.532036\n","Train Epoch: 1 [1030/1374 (75%)]\tLoss: 1.197509\n","Train Epoch: 1 [1040/1374 (76%)]\tLoss: 1.093480\n","Train Epoch: 1 [1050/1374 (76%)]\tLoss: 1.348525\n","Train Epoch: 1 [1060/1374 (77%)]\tLoss: 1.009212\n","Train Epoch: 1 [1070/1374 (78%)]\tLoss: 0.981835\n","Train Epoch: 1 [1080/1374 (79%)]\tLoss: 0.823774\n","Train Epoch: 1 [1090/1374 (79%)]\tLoss: 0.491528\n","Train Epoch: 1 [1100/1374 (80%)]\tLoss: 1.111149\n","Train Epoch: 1 [1110/1374 (81%)]\tLoss: 0.672267\n","Train Epoch: 1 [1120/1374 (82%)]\tLoss: 0.654176\n","Train Epoch: 1 [1130/1374 (82%)]\tLoss: 0.918262\n","Train Epoch: 1 [1140/1374 (83%)]\tLoss: 1.108530\n","Train Epoch: 1 [1150/1374 (84%)]\tLoss: 0.689611\n","Train Epoch: 1 [1160/1374 (84%)]\tLoss: 1.178312\n","Train Epoch: 1 [1170/1374 (85%)]\tLoss: 0.982247\n","Train Epoch: 1 [1180/1374 (86%)]\tLoss: 0.953340\n","Train Epoch: 1 [1190/1374 (87%)]\tLoss: 1.357818\n","Train Epoch: 1 [1200/1374 (87%)]\tLoss: 0.523595\n","Train Epoch: 1 [1210/1374 (88%)]\tLoss: 0.667149\n","Train Epoch: 1 [1220/1374 (89%)]\tLoss: 0.845210\n","Train Epoch: 1 [1230/1374 (90%)]\tLoss: 0.291646\n","Train Epoch: 1 [1240/1374 (90%)]\tLoss: 0.714099\n","Train Epoch: 1 [1250/1374 (91%)]\tLoss: 0.902275\n","Train Epoch: 1 [1260/1374 (92%)]\tLoss: 1.014830\n","Train Epoch: 1 [1270/1374 (92%)]\tLoss: 1.344242\n","Train Epoch: 1 [1280/1374 (93%)]\tLoss: 1.179187\n","Train Epoch: 1 [1290/1374 (94%)]\tLoss: 0.639124\n","Train Epoch: 1 [1300/1374 (95%)]\tLoss: 0.897846\n","Train Epoch: 1 [1310/1374 (95%)]\tLoss: 0.925359\n","Train Epoch: 1 [1320/1374 (96%)]\tLoss: 0.814007\n","Train Epoch: 1 [1330/1374 (97%)]\tLoss: 1.320175\n","Train Epoch: 1 [1340/1374 (98%)]\tLoss: 0.471379\n","Train Epoch: 1 [1350/1374 (98%)]\tLoss: 1.184849\n","Train Epoch: 1 [1360/1374 (99%)]\tLoss: 0.916168\n","Train Epoch: 1 [1370/1374 (100%)]\tLoss: 0.608763\n","\n","Train Epoch: 2 [10/1374 (1%)]\tLoss: 0.779993\n","Train Epoch: 2 [20/1374 (1%)]\tLoss: 0.902759\n","Train Epoch: 2 [30/1374 (2%)]\tLoss: 0.734338\n","Train Epoch: 2 [40/1374 (3%)]\tLoss: 1.019162\n","Train Epoch: 2 [50/1374 (4%)]\tLoss: 1.222997\n","Train Epoch: 2 [60/1374 (4%)]\tLoss: 0.612389\n","Train Epoch: 2 [70/1374 (5%)]\tLoss: 1.095153\n","Train Epoch: 2 [80/1374 (6%)]\tLoss: 1.293239\n","Train Epoch: 2 [90/1374 (7%)]\tLoss: 1.157137\n","Train Epoch: 2 [100/1374 (7%)]\tLoss: 0.913092\n","Train Epoch: 2 [110/1374 (8%)]\tLoss: 1.016877\n","Train Epoch: 2 [120/1374 (9%)]\tLoss: 0.971558\n","Train Epoch: 2 [130/1374 (9%)]\tLoss: 0.547484\n","Train Epoch: 2 [140/1374 (10%)]\tLoss: 1.096677\n","Train Epoch: 2 [150/1374 (11%)]\tLoss: 0.617050\n","Train Epoch: 2 [160/1374 (12%)]\tLoss: 0.794944\n","Train Epoch: 2 [170/1374 (12%)]\tLoss: 1.162901\n","Train Epoch: 2 [180/1374 (13%)]\tLoss: 0.537553\n","Train Epoch: 2 [190/1374 (14%)]\tLoss: 0.582296\n","Train Epoch: 2 [200/1374 (15%)]\tLoss: 1.023230\n","Train Epoch: 2 [210/1374 (15%)]\tLoss: 0.805837\n","Train Epoch: 2 [220/1374 (16%)]\tLoss: 1.179848\n","Train Epoch: 2 [230/1374 (17%)]\tLoss: 1.248828\n","Train Epoch: 2 [240/1374 (17%)]\tLoss: 0.880274\n","Train Epoch: 2 [250/1374 (18%)]\tLoss: 0.961909\n","Train Epoch: 2 [260/1374 (19%)]\tLoss: 0.947848\n","Train Epoch: 2 [270/1374 (20%)]\tLoss: 0.738957\n","Train Epoch: 2 [280/1374 (20%)]\tLoss: 0.776696\n","Train Epoch: 2 [290/1374 (21%)]\tLoss: 1.287396\n","Train Epoch: 2 [300/1374 (22%)]\tLoss: 1.233404\n","Train Epoch: 2 [310/1374 (23%)]\tLoss: 0.899989\n","Train Epoch: 2 [320/1374 (23%)]\tLoss: 1.197407\n","Train Epoch: 2 [330/1374 (24%)]\tLoss: 0.574044\n","Train Epoch: 2 [340/1374 (25%)]\tLoss: 1.413855\n","Train Epoch: 2 [350/1374 (25%)]\tLoss: 1.284575\n","Train Epoch: 2 [360/1374 (26%)]\tLoss: 1.303468\n","Train Epoch: 2 [370/1374 (27%)]\tLoss: 1.166019\n","Train Epoch: 2 [380/1374 (28%)]\tLoss: 0.641883\n","Train Epoch: 2 [390/1374 (28%)]\tLoss: 1.085331\n","Train Epoch: 2 [400/1374 (29%)]\tLoss: 0.650826\n","Train Epoch: 2 [410/1374 (30%)]\tLoss: 1.422595\n","Train Epoch: 2 [420/1374 (31%)]\tLoss: 0.868967\n","Train Epoch: 2 [430/1374 (31%)]\tLoss: 1.259423\n","Train Epoch: 2 [440/1374 (32%)]\tLoss: 0.839702\n","Train Epoch: 2 [450/1374 (33%)]\tLoss: 1.416244\n","Train Epoch: 2 [460/1374 (33%)]\tLoss: 0.758705\n","Train Epoch: 2 [470/1374 (34%)]\tLoss: 1.079739\n","Train Epoch: 2 [480/1374 (35%)]\tLoss: 1.629832\n","Train Epoch: 2 [490/1374 (36%)]\tLoss: 0.766111\n","Train Epoch: 2 [500/1374 (36%)]\tLoss: 0.874726\n","Train Epoch: 2 [510/1374 (37%)]\tLoss: 1.274038\n","Train Epoch: 2 [520/1374 (38%)]\tLoss: 1.413646\n","Train Epoch: 2 [530/1374 (39%)]\tLoss: 0.441288\n","Train Epoch: 2 [540/1374 (39%)]\tLoss: 1.381701\n","Train Epoch: 2 [550/1374 (40%)]\tLoss: 0.848674\n","Train Epoch: 2 [560/1374 (41%)]\tLoss: 1.060623\n","Train Epoch: 2 [570/1374 (41%)]\tLoss: 1.094517\n","Train Epoch: 2 [580/1374 (42%)]\tLoss: 0.841812\n","Train Epoch: 2 [590/1374 (43%)]\tLoss: 1.050656\n","Train Epoch: 2 [600/1374 (44%)]\tLoss: 0.841590\n","Train Epoch: 2 [610/1374 (44%)]\tLoss: 0.726089\n","Train Epoch: 2 [620/1374 (45%)]\tLoss: 1.147348\n","Train Epoch: 2 [630/1374 (46%)]\tLoss: 1.125507\n","Train Epoch: 2 [640/1374 (47%)]\tLoss: 0.994182\n","Train Epoch: 2 [650/1374 (47%)]\tLoss: 1.196058\n","Train Epoch: 2 [660/1374 (48%)]\tLoss: 1.403654\n","Train Epoch: 2 [670/1374 (49%)]\tLoss: 0.668232\n","Train Epoch: 2 [680/1374 (49%)]\tLoss: 1.347262\n","Train Epoch: 2 [690/1374 (50%)]\tLoss: 1.379306\n","Train Epoch: 2 [700/1374 (51%)]\tLoss: 0.820802\n","Train Epoch: 2 [710/1374 (52%)]\tLoss: 0.793245\n","Train Epoch: 2 [720/1374 (52%)]\tLoss: 0.617642\n","Train Epoch: 2 [730/1374 (53%)]\tLoss: 0.631970\n","Train Epoch: 2 [740/1374 (54%)]\tLoss: 0.805142\n","Train Epoch: 2 [750/1374 (55%)]\tLoss: 1.067631\n","Train Epoch: 2 [760/1374 (55%)]\tLoss: 0.722827\n","Train Epoch: 2 [770/1374 (56%)]\tLoss: 1.193072\n","Train Epoch: 2 [780/1374 (57%)]\tLoss: 0.877616\n","Train Epoch: 2 [790/1374 (57%)]\tLoss: 0.950519\n","Train Epoch: 2 [800/1374 (58%)]\tLoss: 0.889161\n","Train Epoch: 2 [810/1374 (59%)]\tLoss: 0.934740\n","Train Epoch: 2 [820/1374 (60%)]\tLoss: 0.852790\n","Train Epoch: 2 [830/1374 (60%)]\tLoss: 0.477474\n","Train Epoch: 2 [840/1374 (61%)]\tLoss: 1.616929\n","Train Epoch: 2 [850/1374 (62%)]\tLoss: 1.401641\n","Train Epoch: 2 [860/1374 (63%)]\tLoss: 0.528476\n","Train Epoch: 2 [870/1374 (63%)]\tLoss: 0.702677\n","Train Epoch: 2 [880/1374 (64%)]\tLoss: 0.319443\n","Train Epoch: 2 [890/1374 (65%)]\tLoss: 0.784720\n","Train Epoch: 2 [900/1374 (66%)]\tLoss: 1.374451\n","Train Epoch: 2 [910/1374 (66%)]\tLoss: 1.091236\n","Train Epoch: 2 [920/1374 (67%)]\tLoss: 0.991600\n","Train Epoch: 2 [930/1374 (68%)]\tLoss: 1.706222\n","Train Epoch: 2 [940/1374 (68%)]\tLoss: 1.035501\n","Train Epoch: 2 [950/1374 (69%)]\tLoss: 1.112160\n","Train Epoch: 2 [960/1374 (70%)]\tLoss: 0.783863\n","Train Epoch: 2 [970/1374 (71%)]\tLoss: 0.698894\n","Train Epoch: 2 [980/1374 (71%)]\tLoss: 0.922558\n","Train Epoch: 2 [990/1374 (72%)]\tLoss: 0.896847\n","Train Epoch: 2 [1000/1374 (73%)]\tLoss: 0.647303\n","Train Epoch: 2 [1010/1374 (74%)]\tLoss: 0.854877\n","Train Epoch: 2 [1020/1374 (74%)]\tLoss: 0.738653\n","Train Epoch: 2 [1030/1374 (75%)]\tLoss: 1.075082\n","Train Epoch: 2 [1040/1374 (76%)]\tLoss: 0.518029\n","Train Epoch: 2 [1050/1374 (76%)]\tLoss: 1.005236\n","Train Epoch: 2 [1060/1374 (77%)]\tLoss: 0.562413\n","Train Epoch: 2 [1070/1374 (78%)]\tLoss: 1.089853\n","Train Epoch: 2 [1080/1374 (79%)]\tLoss: 0.965533\n","Train Epoch: 2 [1090/1374 (79%)]\tLoss: 1.137143\n","Train Epoch: 2 [1100/1374 (80%)]\tLoss: 0.574957\n","Train Epoch: 2 [1110/1374 (81%)]\tLoss: 1.111966\n","Train Epoch: 2 [1120/1374 (82%)]\tLoss: 1.220600\n","Train Epoch: 2 [1130/1374 (82%)]\tLoss: 0.920264\n","Train Epoch: 2 [1140/1374 (83%)]\tLoss: 1.259098\n","Train Epoch: 2 [1150/1374 (84%)]\tLoss: 0.791008\n","Train Epoch: 2 [1160/1374 (84%)]\tLoss: 0.956500\n","Train Epoch: 2 [1170/1374 (85%)]\tLoss: 0.581532\n","Train Epoch: 2 [1180/1374 (86%)]\tLoss: 0.746401\n","Train Epoch: 2 [1190/1374 (87%)]\tLoss: 0.965375\n","Train Epoch: 2 [1200/1374 (87%)]\tLoss: 1.272462\n","Train Epoch: 2 [1210/1374 (88%)]\tLoss: 0.763991\n","Train Epoch: 2 [1220/1374 (89%)]\tLoss: 0.719586\n","Train Epoch: 2 [1230/1374 (90%)]\tLoss: 1.087594\n","Train Epoch: 2 [1240/1374 (90%)]\tLoss: 0.956823\n","Train Epoch: 2 [1250/1374 (91%)]\tLoss: 1.035938\n","Train Epoch: 2 [1260/1374 (92%)]\tLoss: 0.264437\n","Train Epoch: 2 [1270/1374 (92%)]\tLoss: 1.461565\n","Train Epoch: 2 [1280/1374 (93%)]\tLoss: 0.999087\n","Train Epoch: 2 [1290/1374 (94%)]\tLoss: 1.275845\n","Train Epoch: 2 [1300/1374 (95%)]\tLoss: 0.345554\n","Train Epoch: 2 [1310/1374 (95%)]\tLoss: 1.207517\n","Train Epoch: 2 [1320/1374 (96%)]\tLoss: 0.692278\n","Train Epoch: 2 [1330/1374 (97%)]\tLoss: 1.318962\n","Train Epoch: 2 [1340/1374 (98%)]\tLoss: 0.794405\n","Train Epoch: 2 [1350/1374 (98%)]\tLoss: 0.467604\n","Train Epoch: 2 [1360/1374 (99%)]\tLoss: 0.919222\n","Train Epoch: 2 [1370/1374 (100%)]\tLoss: 0.625328\n","Acc 0.530\n","0.5302092811646951\n","Acc 0.518\n","0.5178311499272198\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n","\n","Train Epoch: 1 [10/1374 (1%)]\tLoss: 3.091805\n","Train Epoch: 1 [20/1374 (1%)]\tLoss: 1.108741\n","Train Epoch: 1 [30/1374 (2%)]\tLoss: 1.495963\n","Train Epoch: 1 [40/1374 (3%)]\tLoss: 1.282913\n","Train Epoch: 1 [50/1374 (4%)]\tLoss: 0.740506\n","Train Epoch: 1 [60/1374 (4%)]\tLoss: 1.289604\n","Train Epoch: 1 [70/1374 (5%)]\tLoss: 2.003893\n","Train Epoch: 1 [80/1374 (6%)]\tLoss: 1.060304\n","Train Epoch: 1 [90/1374 (7%)]\tLoss: 1.232226\n","Train Epoch: 1 [100/1374 (7%)]\tLoss: 1.150194\n","Train Epoch: 1 [110/1374 (8%)]\tLoss: 1.202738\n","Train Epoch: 1 [120/1374 (9%)]\tLoss: 1.232707\n","Train Epoch: 1 [130/1374 (9%)]\tLoss: 0.671492\n","Train Epoch: 1 [140/1374 (10%)]\tLoss: 1.070745\n","Train Epoch: 1 [150/1374 (11%)]\tLoss: 0.889070\n","Train Epoch: 1 [160/1374 (12%)]\tLoss: 0.707898\n","Train Epoch: 1 [170/1374 (12%)]\tLoss: 0.822665\n","Train Epoch: 1 [180/1374 (13%)]\tLoss: 1.228941\n","Train Epoch: 1 [190/1374 (14%)]\tLoss: 0.816209\n","Train Epoch: 1 [200/1374 (15%)]\tLoss: 1.068838\n","Train Epoch: 1 [210/1374 (15%)]\tLoss: 0.548297\n","Train Epoch: 1 [220/1374 (16%)]\tLoss: 1.323670\n","Train Epoch: 1 [230/1374 (17%)]\tLoss: 1.013452\n","Train Epoch: 1 [240/1374 (17%)]\tLoss: 1.655071\n","Train Epoch: 1 [250/1374 (18%)]\tLoss: 0.738755\n","Train Epoch: 1 [260/1374 (19%)]\tLoss: 1.574114\n","Train Epoch: 1 [270/1374 (20%)]\tLoss: 1.640635\n","Train Epoch: 1 [280/1374 (20%)]\tLoss: 0.977173\n","Train Epoch: 1 [290/1374 (21%)]\tLoss: 0.925252\n","Train Epoch: 1 [300/1374 (22%)]\tLoss: 0.986767\n","Train Epoch: 1 [310/1374 (23%)]\tLoss: 1.813492\n","Train Epoch: 1 [320/1374 (23%)]\tLoss: 1.101415\n","Train Epoch: 1 [330/1374 (24%)]\tLoss: 1.146326\n","Train Epoch: 1 [340/1374 (25%)]\tLoss: 1.550326\n","Train Epoch: 1 [350/1374 (25%)]\tLoss: 1.164000\n","Train Epoch: 1 [360/1374 (26%)]\tLoss: 1.042514\n","Train Epoch: 1 [370/1374 (27%)]\tLoss: 0.830503\n","Train Epoch: 1 [380/1374 (28%)]\tLoss: 1.699457\n","Train Epoch: 1 [390/1374 (28%)]\tLoss: 0.872060\n","Train Epoch: 1 [400/1374 (29%)]\tLoss: 0.719718\n","Train Epoch: 1 [410/1374 (30%)]\tLoss: 0.932357\n","Train Epoch: 1 [420/1374 (31%)]\tLoss: 0.805318\n","Train Epoch: 1 [430/1374 (31%)]\tLoss: 0.295470\n","Train Epoch: 1 [440/1374 (32%)]\tLoss: 0.890049\n","Train Epoch: 1 [450/1374 (33%)]\tLoss: 1.443651\n","Train Epoch: 1 [460/1374 (33%)]\tLoss: 1.044395\n","Train Epoch: 1 [470/1374 (34%)]\tLoss: 1.102031\n","Train Epoch: 1 [480/1374 (35%)]\tLoss: 1.024712\n","Train Epoch: 1 [490/1374 (36%)]\tLoss: 0.967817\n","Train Epoch: 1 [500/1374 (36%)]\tLoss: 1.398524\n","Train Epoch: 1 [510/1374 (37%)]\tLoss: 1.005385\n","Train Epoch: 1 [520/1374 (38%)]\tLoss: 0.978875\n","Train Epoch: 1 [530/1374 (39%)]\tLoss: 0.754405\n","Train Epoch: 1 [540/1374 (39%)]\tLoss: 0.829757\n","Train Epoch: 1 [550/1374 (40%)]\tLoss: 0.622967\n","Train Epoch: 1 [560/1374 (41%)]\tLoss: 1.427167\n","Train Epoch: 1 [570/1374 (41%)]\tLoss: 0.756054\n","Train Epoch: 1 [580/1374 (42%)]\tLoss: 0.597545\n","Train Epoch: 1 [590/1374 (43%)]\tLoss: 0.973726\n","Train Epoch: 1 [600/1374 (44%)]\tLoss: 0.929641\n","Train Epoch: 1 [610/1374 (44%)]\tLoss: 0.854528\n","Train Epoch: 1 [620/1374 (45%)]\tLoss: 0.566965\n","Train Epoch: 1 [630/1374 (46%)]\tLoss: 0.770623\n","Train Epoch: 1 [640/1374 (47%)]\tLoss: 1.388286\n","Train Epoch: 1 [650/1374 (47%)]\tLoss: 0.677156\n","Train Epoch: 1 [660/1374 (48%)]\tLoss: 0.626196\n","Train Epoch: 1 [670/1374 (49%)]\tLoss: 1.107493\n","Train Epoch: 1 [680/1374 (49%)]\tLoss: 0.632690\n","Train Epoch: 1 [690/1374 (50%)]\tLoss: 0.874266\n","Train Epoch: 1 [700/1374 (51%)]\tLoss: 1.599249\n","Train Epoch: 1 [710/1374 (52%)]\tLoss: 0.605474\n","Train Epoch: 1 [720/1374 (52%)]\tLoss: 0.960961\n","Train Epoch: 1 [730/1374 (53%)]\tLoss: 0.833018\n","Train Epoch: 1 [740/1374 (54%)]\tLoss: 0.668505\n","Train Epoch: 1 [750/1374 (55%)]\tLoss: 0.689210\n","Train Epoch: 1 [760/1374 (55%)]\tLoss: 0.880205\n","Train Epoch: 1 [770/1374 (56%)]\tLoss: 0.938084\n","Train Epoch: 1 [780/1374 (57%)]\tLoss: 0.617317\n","Train Epoch: 1 [790/1374 (57%)]\tLoss: 1.117549\n","Train Epoch: 1 [800/1374 (58%)]\tLoss: 0.682722\n","Train Epoch: 1 [810/1374 (59%)]\tLoss: 0.924530\n","Train Epoch: 1 [820/1374 (60%)]\tLoss: 1.209034\n","Train Epoch: 1 [830/1374 (60%)]\tLoss: 0.952491\n","Train Epoch: 1 [840/1374 (61%)]\tLoss: 0.453282\n","Train Epoch: 1 [850/1374 (62%)]\tLoss: 0.983246\n","Train Epoch: 1 [860/1374 (63%)]\tLoss: 0.700955\n","Train Epoch: 1 [870/1374 (63%)]\tLoss: 0.878159\n","Train Epoch: 1 [880/1374 (64%)]\tLoss: 0.644546\n","Train Epoch: 1 [890/1374 (65%)]\tLoss: 1.435821\n","Train Epoch: 1 [900/1374 (66%)]\tLoss: 1.110424\n","Train Epoch: 1 [910/1374 (66%)]\tLoss: 0.770566\n","Train Epoch: 1 [920/1374 (67%)]\tLoss: 0.816719\n","Train Epoch: 1 [930/1374 (68%)]\tLoss: 1.019779\n","Train Epoch: 1 [940/1374 (68%)]\tLoss: 1.116743\n","Train Epoch: 1 [950/1374 (69%)]\tLoss: 0.846883\n","Train Epoch: 1 [960/1374 (70%)]\tLoss: 0.434862\n","Train Epoch: 1 [970/1374 (71%)]\tLoss: 1.268077\n","Train Epoch: 1 [980/1374 (71%)]\tLoss: 0.775343\n","Train Epoch: 1 [990/1374 (72%)]\tLoss: 0.956475\n","Train Epoch: 1 [1000/1374 (73%)]\tLoss: 0.814018\n","Train Epoch: 1 [1010/1374 (74%)]\tLoss: 1.125053\n","Train Epoch: 1 [1020/1374 (74%)]\tLoss: 1.215192\n","Train Epoch: 1 [1030/1374 (75%)]\tLoss: 0.642747\n","Train Epoch: 1 [1040/1374 (76%)]\tLoss: 1.089527\n","Train Epoch: 1 [1050/1374 (76%)]\tLoss: 1.298365\n","Train Epoch: 1 [1060/1374 (77%)]\tLoss: 1.192436\n","Train Epoch: 1 [1070/1374 (78%)]\tLoss: 1.645664\n","Train Epoch: 1 [1080/1374 (79%)]\tLoss: 0.812900\n","Train Epoch: 1 [1090/1374 (79%)]\tLoss: 0.620875\n","Train Epoch: 1 [1100/1374 (80%)]\tLoss: 1.196412\n","Train Epoch: 1 [1110/1374 (81%)]\tLoss: 0.665485\n","Train Epoch: 1 [1120/1374 (82%)]\tLoss: 1.254158\n","Train Epoch: 1 [1130/1374 (82%)]\tLoss: 0.909125\n","Train Epoch: 1 [1140/1374 (83%)]\tLoss: 1.010192\n","Train Epoch: 1 [1150/1374 (84%)]\tLoss: 0.857254\n","Train Epoch: 1 [1160/1374 (84%)]\tLoss: 0.704911\n","Train Epoch: 1 [1170/1374 (85%)]\tLoss: 0.728735\n","Train Epoch: 1 [1180/1374 (86%)]\tLoss: 1.305912\n","Train Epoch: 1 [1190/1374 (87%)]\tLoss: 1.021199\n","Train Epoch: 1 [1200/1374 (87%)]\tLoss: 0.870275\n","Train Epoch: 1 [1210/1374 (88%)]\tLoss: 0.850475\n","Train Epoch: 1 [1220/1374 (89%)]\tLoss: 1.094483\n","Train Epoch: 1 [1230/1374 (90%)]\tLoss: 1.462588\n","Train Epoch: 1 [1240/1374 (90%)]\tLoss: 0.609978\n","Train Epoch: 1 [1250/1374 (91%)]\tLoss: 0.511517\n","Train Epoch: 1 [1260/1374 (92%)]\tLoss: 0.655219\n","Train Epoch: 1 [1270/1374 (92%)]\tLoss: 0.894454\n","Train Epoch: 1 [1280/1374 (93%)]\tLoss: 0.685755\n","Train Epoch: 1 [1290/1374 (94%)]\tLoss: 0.761582\n","Train Epoch: 1 [1300/1374 (95%)]\tLoss: 0.850743\n","Train Epoch: 1 [1310/1374 (95%)]\tLoss: 1.119618\n","Train Epoch: 1 [1320/1374 (96%)]\tLoss: 0.552072\n","Train Epoch: 1 [1330/1374 (97%)]\tLoss: 0.888251\n","Train Epoch: 1 [1340/1374 (98%)]\tLoss: 1.237281\n","Train Epoch: 1 [1350/1374 (98%)]\tLoss: 0.646281\n","Train Epoch: 1 [1360/1374 (99%)]\tLoss: 1.290070\n","Train Epoch: 1 [1370/1374 (100%)]\tLoss: 0.902500\n","\n","Train Epoch: 2 [10/1374 (1%)]\tLoss: 0.838032\n","Train Epoch: 2 [20/1374 (1%)]\tLoss: 1.222085\n","Train Epoch: 2 [30/1374 (2%)]\tLoss: 0.970277\n","Train Epoch: 2 [40/1374 (3%)]\tLoss: 0.616867\n","Train Epoch: 2 [50/1374 (4%)]\tLoss: 0.874744\n","Train Epoch: 2 [60/1374 (4%)]\tLoss: 0.535463\n","Train Epoch: 2 [70/1374 (5%)]\tLoss: 0.799590\n","Train Epoch: 2 [80/1374 (6%)]\tLoss: 1.110320\n","Train Epoch: 2 [90/1374 (7%)]\tLoss: 0.734351\n","Train Epoch: 2 [100/1374 (7%)]\tLoss: 0.892452\n","Train Epoch: 2 [110/1374 (8%)]\tLoss: 1.329529\n","Train Epoch: 2 [120/1374 (9%)]\tLoss: 1.079746\n","Train Epoch: 2 [130/1374 (9%)]\tLoss: 0.899765\n","Train Epoch: 2 [140/1374 (10%)]\tLoss: 1.752539\n","Train Epoch: 2 [150/1374 (11%)]\tLoss: 0.436974\n","Train Epoch: 2 [160/1374 (12%)]\tLoss: 1.304298\n","Train Epoch: 2 [170/1374 (12%)]\tLoss: 0.955631\n","Train Epoch: 2 [180/1374 (13%)]\tLoss: 1.215881\n","Train Epoch: 2 [190/1374 (14%)]\tLoss: 1.333779\n","Train Epoch: 2 [200/1374 (15%)]\tLoss: 0.916464\n","Train Epoch: 2 [210/1374 (15%)]\tLoss: 0.917967\n","Train Epoch: 2 [220/1374 (16%)]\tLoss: 1.171898\n","Train Epoch: 2 [230/1374 (17%)]\tLoss: 1.331310\n","Train Epoch: 2 [240/1374 (17%)]\tLoss: 1.510529\n","Train Epoch: 2 [250/1374 (18%)]\tLoss: 1.006877\n","Train Epoch: 2 [260/1374 (19%)]\tLoss: 0.760622\n","Train Epoch: 2 [270/1374 (20%)]\tLoss: 0.592276\n","Train Epoch: 2 [280/1374 (20%)]\tLoss: 1.143702\n","Train Epoch: 2 [290/1374 (21%)]\tLoss: 1.448712\n","Train Epoch: 2 [300/1374 (22%)]\tLoss: 0.776509\n","Train Epoch: 2 [310/1374 (23%)]\tLoss: 1.319025\n","Train Epoch: 2 [320/1374 (23%)]\tLoss: 0.918486\n","Train Epoch: 2 [330/1374 (24%)]\tLoss: 1.072078\n","Train Epoch: 2 [340/1374 (25%)]\tLoss: 1.156406\n","Train Epoch: 2 [350/1374 (25%)]\tLoss: 0.838965\n","Train Epoch: 2 [360/1374 (26%)]\tLoss: 1.170099\n","Train Epoch: 2 [370/1374 (27%)]\tLoss: 1.398880\n","Train Epoch: 2 [380/1374 (28%)]\tLoss: 1.035381\n","Train Epoch: 2 [390/1374 (28%)]\tLoss: 0.806533\n","Train Epoch: 2 [400/1374 (29%)]\tLoss: 0.953307\n","Train Epoch: 2 [410/1374 (30%)]\tLoss: 1.044548\n","Train Epoch: 2 [420/1374 (31%)]\tLoss: 0.966463\n","Train Epoch: 2 [430/1374 (31%)]\tLoss: 0.389857\n","Train Epoch: 2 [440/1374 (32%)]\tLoss: 0.799537\n","Train Epoch: 2 [450/1374 (33%)]\tLoss: 0.638840\n","Train Epoch: 2 [460/1374 (33%)]\tLoss: 0.994731\n","Train Epoch: 2 [470/1374 (34%)]\tLoss: 1.056039\n","Train Epoch: 2 [480/1374 (35%)]\tLoss: 0.752696\n","Train Epoch: 2 [490/1374 (36%)]\tLoss: 1.005862\n","Train Epoch: 2 [500/1374 (36%)]\tLoss: 1.003477\n","Train Epoch: 2 [510/1374 (37%)]\tLoss: 0.933630\n","Train Epoch: 2 [520/1374 (38%)]\tLoss: 0.729381\n","Train Epoch: 2 [530/1374 (39%)]\tLoss: 1.038248\n","Train Epoch: 2 [540/1374 (39%)]\tLoss: 1.066748\n","Train Epoch: 2 [550/1374 (40%)]\tLoss: 0.687374\n","Train Epoch: 2 [560/1374 (41%)]\tLoss: 0.498221\n","Train Epoch: 2 [570/1374 (41%)]\tLoss: 1.117992\n","Train Epoch: 2 [580/1374 (42%)]\tLoss: 0.990538\n","Train Epoch: 2 [590/1374 (43%)]\tLoss: 1.242496\n","Train Epoch: 2 [600/1374 (44%)]\tLoss: 0.959342\n","Train Epoch: 2 [610/1374 (44%)]\tLoss: 1.049652\n","Train Epoch: 2 [620/1374 (45%)]\tLoss: 0.803139\n","Train Epoch: 2 [630/1374 (46%)]\tLoss: 0.521239\n","Train Epoch: 2 [640/1374 (47%)]\tLoss: 0.801845\n","Train Epoch: 2 [650/1374 (47%)]\tLoss: 0.980032\n","Train Epoch: 2 [660/1374 (48%)]\tLoss: 1.111884\n","Train Epoch: 2 [670/1374 (49%)]\tLoss: 1.078522\n","Train Epoch: 2 [680/1374 (49%)]\tLoss: 0.980938\n","Train Epoch: 2 [690/1374 (50%)]\tLoss: 0.408185\n","Train Epoch: 2 [700/1374 (51%)]\tLoss: 0.791460\n","Train Epoch: 2 [710/1374 (52%)]\tLoss: 1.285331\n","Train Epoch: 2 [720/1374 (52%)]\tLoss: 1.289290\n","Train Epoch: 2 [730/1374 (53%)]\tLoss: 0.947155\n","Train Epoch: 2 [740/1374 (54%)]\tLoss: 0.749928\n","Train Epoch: 2 [750/1374 (55%)]\tLoss: 1.584816\n","Train Epoch: 2 [760/1374 (55%)]\tLoss: 1.185715\n","Train Epoch: 2 [770/1374 (56%)]\tLoss: 0.739227\n","Train Epoch: 2 [780/1374 (57%)]\tLoss: 0.644448\n","Train Epoch: 2 [790/1374 (57%)]\tLoss: 0.965163\n","Train Epoch: 2 [800/1374 (58%)]\tLoss: 1.249359\n","Train Epoch: 2 [810/1374 (59%)]\tLoss: 1.264579\n","Train Epoch: 2 [820/1374 (60%)]\tLoss: 0.907627\n","Train Epoch: 2 [830/1374 (60%)]\tLoss: 0.893372\n","Train Epoch: 2 [840/1374 (61%)]\tLoss: 0.791469\n","Train Epoch: 2 [850/1374 (62%)]\tLoss: 1.488341\n","Train Epoch: 2 [860/1374 (63%)]\tLoss: 1.183436\n","Train Epoch: 2 [870/1374 (63%)]\tLoss: 0.605810\n","Train Epoch: 2 [880/1374 (64%)]\tLoss: 1.005041\n","Train Epoch: 2 [890/1374 (65%)]\tLoss: 1.514216\n","Train Epoch: 2 [900/1374 (66%)]\tLoss: 0.976480\n","Train Epoch: 2 [910/1374 (66%)]\tLoss: 0.828301\n","Train Epoch: 2 [920/1374 (67%)]\tLoss: 0.875724\n","Train Epoch: 2 [930/1374 (68%)]\tLoss: 0.697368\n","Train Epoch: 2 [940/1374 (68%)]\tLoss: 1.112052\n","Train Epoch: 2 [950/1374 (69%)]\tLoss: 0.492393\n","Train Epoch: 2 [960/1374 (70%)]\tLoss: 0.905853\n","Train Epoch: 2 [970/1374 (71%)]\tLoss: 0.700730\n","Train Epoch: 2 [980/1374 (71%)]\tLoss: 0.993606\n","Train Epoch: 2 [990/1374 (72%)]\tLoss: 0.917553\n","Train Epoch: 2 [1000/1374 (73%)]\tLoss: 1.381197\n","Train Epoch: 2 [1010/1374 (74%)]\tLoss: 0.782086\n","Train Epoch: 2 [1020/1374 (74%)]\tLoss: 0.887062\n","Train Epoch: 2 [1030/1374 (75%)]\tLoss: 0.838420\n","Train Epoch: 2 [1040/1374 (76%)]\tLoss: 0.979441\n","Train Epoch: 2 [1050/1374 (76%)]\tLoss: 0.833149\n","Train Epoch: 2 [1060/1374 (77%)]\tLoss: 1.036355\n","Train Epoch: 2 [1070/1374 (78%)]\tLoss: 1.727573\n","Train Epoch: 2 [1080/1374 (79%)]\tLoss: 0.935123\n","Train Epoch: 2 [1090/1374 (79%)]\tLoss: 0.876318\n","Train Epoch: 2 [1100/1374 (80%)]\tLoss: 0.830385\n","Train Epoch: 2 [1110/1374 (81%)]\tLoss: 0.892065\n","Train Epoch: 2 [1120/1374 (82%)]\tLoss: 0.751911\n","Train Epoch: 2 [1130/1374 (82%)]\tLoss: 1.110817\n","Train Epoch: 2 [1140/1374 (83%)]\tLoss: 0.435347\n","Train Epoch: 2 [1150/1374 (84%)]\tLoss: 0.413496\n","Train Epoch: 2 [1160/1374 (84%)]\tLoss: 0.774541\n","Train Epoch: 2 [1170/1374 (85%)]\tLoss: 0.725195\n","Train Epoch: 2 [1180/1374 (86%)]\tLoss: 0.993355\n","Train Epoch: 2 [1190/1374 (87%)]\tLoss: 1.069525\n","Train Epoch: 2 [1200/1374 (87%)]\tLoss: 1.189248\n","Train Epoch: 2 [1210/1374 (88%)]\tLoss: 0.776739\n","Train Epoch: 2 [1220/1374 (89%)]\tLoss: 0.459842\n","Train Epoch: 2 [1230/1374 (90%)]\tLoss: 1.548826\n","Train Epoch: 2 [1240/1374 (90%)]\tLoss: 0.637892\n","Train Epoch: 2 [1250/1374 (91%)]\tLoss: 0.913508\n","Train Epoch: 2 [1260/1374 (92%)]\tLoss: 1.140079\n","Train Epoch: 2 [1270/1374 (92%)]\tLoss: 0.925227\n","Train Epoch: 2 [1280/1374 (93%)]\tLoss: 0.984110\n","Train Epoch: 2 [1290/1374 (94%)]\tLoss: 1.109524\n","Train Epoch: 2 [1300/1374 (95%)]\tLoss: 0.873550\n","Train Epoch: 2 [1310/1374 (95%)]\tLoss: 1.045039\n","Train Epoch: 2 [1320/1374 (96%)]\tLoss: 0.932806\n","Train Epoch: 2 [1330/1374 (97%)]\tLoss: 0.890081\n","Train Epoch: 2 [1340/1374 (98%)]\tLoss: 1.081076\n","Train Epoch: 2 [1350/1374 (98%)]\tLoss: 0.660524\n","Train Epoch: 2 [1360/1374 (99%)]\tLoss: 0.663644\n","Train Epoch: 2 [1370/1374 (100%)]\tLoss: 0.951524\n","Acc 0.484\n","0.4842584167424932\n","Acc 0.487\n","0.48653566229985445\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VTPMI6uSLbfZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621164700218,"user_tz":-60,"elapsed":630,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"42a933a1-fb3a-4af8-a63d-b5ab9338b729"},"source":["validation_accuracy"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{1e-05: 0.48653566229985445,\n"," 0.001: 0.5178311499272198,\n"," 0.1: 0.49563318777292575,\n"," 10.0: 0.504730713245997,\n"," 1000.0: 0.4657933042212518,\n"," 100000.0: 0.485080058224163,\n"," 10000000.0: 0.5018195050946143}"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"jmXvCTiJfLgk"},"source":["#import pickle\n","\n","#Save results\n","#f = open(\"hyperparameter_search_vadam_full_model_results_validation_final.pkl\",\"wb\")\n","#pickle.dump(validation_accuracy,f)\n","#f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YbYZNHaFez_L"},"source":["And now, for the pretrained non fine-tuned BERT the results are:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E_AA8hlDfHmP","executionInfo":{"status":"ok","timestamp":1621164711478,"user_tz":-60,"elapsed":2210,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"31009270-e046-4fa0-91cc-31afca1b33af"},"source":["model, optimizer = load_model(args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"moiECynkdHdM","executionInfo":{"status":"ok","timestamp":1621164731116,"user_tz":-60,"elapsed":12232,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"cd25f196-f2c5-454b-f14f-de83aaa0561b"},"source":["evaluate(model, validation_dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Acc 0.478\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.47780203784570596"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"Co3cykaEhBRK"},"source":["We clearly see that training the full model using variational Adam doesn't lead to good results. We conjecture that the reason for this is the additional stochasticity introduced in variational Adam via the weight perturbations, that makes it difficult for the model to learn. "]},{"cell_type":"markdown","metadata":{"id":"EGeVikph4emz"},"source":["# Vadam: Approximating the posterior of the final layer after converging to a local optima in the original dataset"]},{"cell_type":"markdown","metadata":{"id":"589bxKiX4lo_"},"source":["Given the impossibility of fine-tuning a full transformer using Vadam, we first do the fine-tuning using AdamW and, once we have converged to a local optimum, freeze all the layers except for the last one and start using Vadam, to approximate the posterior of the last layer parameters.We first apply this procedure to the already trained RoBERTa-large model provided by the authors in [Aligning AI with shared human values](https://arxiv.org/abs/2008.02275) (so we will only have to do the  Since the model has already been trained, we only perform the step of freezing all its layers except for the last one and using Vadam."]},{"cell_type":"code","metadata":{"id":"o9m0AHz7vEAP"},"source":["args = MyArgs(model='roberta-large', ngpus=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzC_3IJO5EAl","executionInfo":{"status":"ok","timestamp":1621127631732,"user_tz":-60,"elapsed":44044,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"78c67c33-5b38-432d-f9df-c8c63baf7b45"},"source":["!pip install gdown\n","import gdown\n","!gdown https://drive.google.com/uc?id=1MHvSFbHjvzebib90wW378VtDAtn1WVxc"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"roberta-large\" loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h4Tv5hmn5Fwr"},"source":["model, optimizer = load_model(args, load_path='util_roberta-large.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rT0b6TFx4yAi"},"source":["data_dir = '1_original_study_datasets'\n","train_name = 'util_train'\n","test_name = \"util_test\"\n","hard_test_name = \"util_test_hard\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223,"referenced_widgets":["9c70307208b84d698e5449b26148bb3e","2a01d857e6d2486281fddca2e8ad3332","e6e2924d3ced4085aba4baba689fb92f","8dd8c2e71c2345ceac1458610e24b733","2f4ac25249f3489bbfe187a381b362c2","1b5d3bd3f0b34b288f812f5542c0fc31","f538a352482f4b9ca1ec83ee7784d1cb","45978ca965b24d4eb4269dc79cafae60","7ff54f76d9304ff8be97fdc02d7b9085","48a18969428a4bf4ace98ac74c8212b6","8c6236bb7ffc4c10ab9816b7cd73c930","cb129899590748c886a1048c6c1f9dda","b75ffe06cd3e43e7adccbab4c2612747","a0af3c9a812f4217a4c8a390e939536c","1e9aad32a5cc43e3acaf8126dce0bdd2","d98cbf5b1d0143b2a0a7fbed51deba66","5c9346e864234645bb228ac76f0323ed","36e5f15541734779921dbe9d6cf6c43b","a509e5fe14a54e8186cf40c204c71c5d","aeb565b1693443ed8bb2f406ef4819dc","9955919c10e14351be8b0532ed03246f","346b25bf9f504db5a5d4988ef8e07935","970e90c2871d4b348ee1af1bcfb649d5","0fd247f2d8e44add8c234a75f11664d3"]},"id":"jsCTVGPH5ZUB","executionInfo":{"status":"ok","timestamp":1621124155460,"user_tz":-60,"elapsed":83277,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"940445ff-6df5-450d-d1d0-a8607caff653"},"source":["train_data = load_process_data(args, data_dir, \"util\", train_name)\n","test_hard_data = load_process_data(args, data_dir, \"util\", hard_test_name)\n","test_data = load_process_data(args, data_dir, \"util\", test_name)\n","\n","train_dataloader = DataLoader(train_data, batch_size=args.batch_size // 2, shuffle=True)\n","test_dataloader = DataLoader(test_data, batch_size=args.batch_size // 2, shuffle=False)\n","hard_test_dataloader = DataLoader(test_hard_data, batch_size=args.batch_size // 2, shuffle=False)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c70307208b84d698e5449b26148bb3e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ff54f76d9304ff8be97fdc02d7b9085","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c9346e864234645bb228ac76f0323ed","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","train fraction of examples within context window (64 tokens): 1.000\n","test_hard fraction of examples within context window (64 tokens): 1.000\n","test fraction of examples within context window (64 tokens): 0.999\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3aOnvaNu5hKo","executionInfo":{"status":"ok","timestamp":1621105550806,"user_tz":-60,"elapsed":121556,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"293d4ccb-9227-49a2-dcea-dcc8815395fe"},"source":["evaluate(model, test_dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Acc 0.795\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.7951331114808652"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"hnLI98Xm5l-X"},"source":["for name, param in model.named_parameters():\n","    if name != 'module.classifier.out_proj.weight' and name != 'module.classifier.out_proj.bias':\n","      param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XyT6dE8q6EdQ","executionInfo":{"status":"ok","timestamp":1621127790566,"user_tz":-60,"elapsed":399,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"7760cc75-0b3d-4a97-a02f-c078fa5a3658"},"source":["for name, param in model.named_parameters():\n","    if param.requires_grad:\n","        print(name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["module.classifier.out_proj.weight\n","module.classifier.out_proj.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"th7KkcOB6GoR"},"source":["trainable_parameters = [model.module.classifier.out_proj.weight, model.module.classifier.out_proj.bias]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4sG476v6IUw"},"source":["args.learning_rate = 1e-5\n","args.batch_size = 8\n","args.nepochs = 10\n","betas = (0.9,0.995)\n","train_mc_samples = 5\n","eval_mc_samples = 20"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wVKFv9xz6J1z"},"source":["optimizer_vadam_last_layer = Vadam(trainable_parameters,\n","                lr = args.learning_rate,\n","                betas = betas,\n","                prior_prec = 1.0,\n","                prec_init = 1.0,\n","                num_samples = train_mc_samples,\n","                train_set_size = len(train_data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VvSVbRaetqvX"},"source":["current_precisions = None\n","precisions_difference = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bzZL-NXV6Qth","executionInfo":{"status":"ok","timestamp":1621134857907,"user_tz":-60,"elapsed":5675035,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"55ffa097-81d0-4990-e5ec-b8bfa07ccb6f"},"source":["for epoch in range(args.nepochs):\n","  print()\n","  train_variational(model, optimizer_vadam_last_layer, train_dataloader, epoch, verbose=True)\n","  if epoch > 0:\n","    precisions_difference.append(torch.norm(optimizer_vadam_last_layer.get_weight_precs()[0][0][0] - current_precisions[0][0][0]))\n","    print(precisions_difference)\n","  epoch += 1\n","  current_precisions = copy.deepcopy(optimizer_vadam_last_layer.get_weight_precs())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Train Epoch: 0 [10/1718 (1%)]\tLoss: 0.006286\n","Train Epoch: 0 [20/1718 (1%)]\tLoss: 0.399527\n","Train Epoch: 0 [30/1718 (2%)]\tLoss: 0.013437\n","Train Epoch: 0 [40/1718 (2%)]\tLoss: 0.112780\n","Train Epoch: 0 [50/1718 (3%)]\tLoss: 0.026368\n","Train Epoch: 0 [60/1718 (3%)]\tLoss: 0.003922\n","Train Epoch: 0 [70/1718 (4%)]\tLoss: 0.428415\n","Train Epoch: 0 [80/1718 (5%)]\tLoss: 1.213376\n","Train Epoch: 0 [90/1718 (5%)]\tLoss: 0.040242\n","Train Epoch: 0 [100/1718 (6%)]\tLoss: 0.000012\n","Train Epoch: 0 [110/1718 (6%)]\tLoss: 0.013660\n","Train Epoch: 0 [120/1718 (7%)]\tLoss: 0.009063\n","Train Epoch: 0 [130/1718 (8%)]\tLoss: 0.392876\n","Train Epoch: 0 [140/1718 (8%)]\tLoss: 0.112663\n","Train Epoch: 0 [150/1718 (9%)]\tLoss: 0.445972\n","Train Epoch: 0 [160/1718 (9%)]\tLoss: 0.313800\n","Train Epoch: 0 [170/1718 (10%)]\tLoss: 0.001037\n","Train Epoch: 0 [180/1718 (10%)]\tLoss: 0.072593\n","Train Epoch: 0 [190/1718 (11%)]\tLoss: 0.861905\n","Train Epoch: 0 [200/1718 (12%)]\tLoss: 0.424671\n","Train Epoch: 0 [210/1718 (12%)]\tLoss: 0.000181\n","Train Epoch: 0 [220/1718 (13%)]\tLoss: 0.001080\n","Train Epoch: 0 [230/1718 (13%)]\tLoss: 0.194410\n","Train Epoch: 0 [240/1718 (14%)]\tLoss: 0.144475\n","Train Epoch: 0 [250/1718 (15%)]\tLoss: 0.036921\n","Train Epoch: 0 [260/1718 (15%)]\tLoss: 0.013189\n","Train Epoch: 0 [270/1718 (16%)]\tLoss: 0.187596\n","Train Epoch: 0 [280/1718 (16%)]\tLoss: 0.077216\n","Train Epoch: 0 [290/1718 (17%)]\tLoss: 0.385464\n","Train Epoch: 0 [300/1718 (17%)]\tLoss: 0.182190\n","Train Epoch: 0 [310/1718 (18%)]\tLoss: 0.250925\n","Train Epoch: 0 [320/1718 (19%)]\tLoss: 0.009111\n","Train Epoch: 0 [330/1718 (19%)]\tLoss: 0.006346\n","Train Epoch: 0 [340/1718 (20%)]\tLoss: 0.146095\n","Train Epoch: 0 [350/1718 (20%)]\tLoss: 0.149971\n","Train Epoch: 0 [360/1718 (21%)]\tLoss: 0.058618\n","Train Epoch: 0 [370/1718 (22%)]\tLoss: 1.754582\n","Train Epoch: 0 [380/1718 (22%)]\tLoss: 0.310486\n","Train Epoch: 0 [390/1718 (23%)]\tLoss: 0.442972\n","Train Epoch: 0 [400/1718 (23%)]\tLoss: 0.036307\n","Train Epoch: 0 [410/1718 (24%)]\tLoss: 0.339566\n","Train Epoch: 0 [420/1718 (24%)]\tLoss: 0.211137\n","Train Epoch: 0 [430/1718 (25%)]\tLoss: 0.015024\n","Train Epoch: 0 [440/1718 (26%)]\tLoss: 0.243412\n","Train Epoch: 0 [450/1718 (26%)]\tLoss: 0.020323\n","Train Epoch: 0 [460/1718 (27%)]\tLoss: 0.183155\n","Train Epoch: 0 [470/1718 (27%)]\tLoss: 0.036263\n","Train Epoch: 0 [480/1718 (28%)]\tLoss: 0.031869\n","Train Epoch: 0 [490/1718 (29%)]\tLoss: 0.188561\n","Train Epoch: 0 [500/1718 (29%)]\tLoss: 0.005945\n","Train Epoch: 0 [510/1718 (30%)]\tLoss: 0.953005\n","Train Epoch: 0 [520/1718 (30%)]\tLoss: 0.003630\n","Train Epoch: 0 [530/1718 (31%)]\tLoss: 2.336066\n","Train Epoch: 0 [540/1718 (31%)]\tLoss: 0.600146\n","Train Epoch: 0 [550/1718 (32%)]\tLoss: 0.003783\n","Train Epoch: 0 [560/1718 (33%)]\tLoss: 0.817571\n","Train Epoch: 0 [570/1718 (33%)]\tLoss: 0.631552\n","Train Epoch: 0 [580/1718 (34%)]\tLoss: 1.150930\n","Train Epoch: 0 [590/1718 (34%)]\tLoss: 0.170574\n","Train Epoch: 0 [600/1718 (35%)]\tLoss: 0.001885\n","Train Epoch: 0 [610/1718 (36%)]\tLoss: 0.203576\n","Train Epoch: 0 [620/1718 (36%)]\tLoss: 0.040255\n","Train Epoch: 0 [630/1718 (37%)]\tLoss: 0.116763\n","Train Epoch: 0 [640/1718 (37%)]\tLoss: 0.046118\n","Train Epoch: 0 [650/1718 (38%)]\tLoss: 0.010656\n","Train Epoch: 0 [660/1718 (38%)]\tLoss: 0.067947\n","Train Epoch: 0 [670/1718 (39%)]\tLoss: 0.403442\n","Train Epoch: 0 [680/1718 (40%)]\tLoss: 0.992749\n","Train Epoch: 0 [690/1718 (40%)]\tLoss: 0.606273\n","Train Epoch: 0 [700/1718 (41%)]\tLoss: 0.563172\n","Train Epoch: 0 [710/1718 (41%)]\tLoss: 0.493143\n","Train Epoch: 0 [720/1718 (42%)]\tLoss: 0.730286\n","Train Epoch: 0 [730/1718 (42%)]\tLoss: 0.003458\n","Train Epoch: 0 [740/1718 (43%)]\tLoss: 0.516288\n","Train Epoch: 0 [750/1718 (44%)]\tLoss: 0.004957\n","Train Epoch: 0 [760/1718 (44%)]\tLoss: 0.736654\n","Train Epoch: 0 [770/1718 (45%)]\tLoss: 1.918948\n","Train Epoch: 0 [780/1718 (45%)]\tLoss: 0.232653\n","Train Epoch: 0 [790/1718 (46%)]\tLoss: 0.028705\n","Train Epoch: 0 [800/1718 (47%)]\tLoss: 0.637186\n","Train Epoch: 0 [810/1718 (47%)]\tLoss: 0.390860\n","Train Epoch: 0 [820/1718 (48%)]\tLoss: 0.990335\n","Train Epoch: 0 [830/1718 (48%)]\tLoss: 0.031737\n","Train Epoch: 0 [840/1718 (49%)]\tLoss: 0.786009\n","Train Epoch: 0 [850/1718 (49%)]\tLoss: 0.380829\n","Train Epoch: 0 [860/1718 (50%)]\tLoss: 0.084494\n","Train Epoch: 0 [870/1718 (51%)]\tLoss: 0.363505\n","Train Epoch: 0 [880/1718 (51%)]\tLoss: 2.187154\n","Train Epoch: 0 [890/1718 (52%)]\tLoss: 0.713241\n","Train Epoch: 0 [900/1718 (52%)]\tLoss: 0.039292\n","Train Epoch: 0 [910/1718 (53%)]\tLoss: 0.291665\n","Train Epoch: 0 [920/1718 (54%)]\tLoss: 0.000962\n","Train Epoch: 0 [930/1718 (54%)]\tLoss: 0.458394\n","Train Epoch: 0 [940/1718 (55%)]\tLoss: 0.562569\n","Train Epoch: 0 [950/1718 (55%)]\tLoss: 0.039482\n","Train Epoch: 0 [960/1718 (56%)]\tLoss: 0.401960\n","Train Epoch: 0 [970/1718 (56%)]\tLoss: 0.038643\n","Train Epoch: 0 [980/1718 (57%)]\tLoss: 0.347048\n","Train Epoch: 0 [990/1718 (58%)]\tLoss: 0.023055\n","Train Epoch: 0 [1000/1718 (58%)]\tLoss: 0.550887\n","Train Epoch: 0 [1010/1718 (59%)]\tLoss: 0.160303\n","Train Epoch: 0 [1020/1718 (59%)]\tLoss: 0.043926\n","Train Epoch: 0 [1030/1718 (60%)]\tLoss: 0.007888\n","Train Epoch: 0 [1040/1718 (61%)]\tLoss: 0.286087\n","Train Epoch: 0 [1050/1718 (61%)]\tLoss: 0.270806\n","Train Epoch: 0 [1060/1718 (62%)]\tLoss: 0.159676\n","Train Epoch: 0 [1070/1718 (62%)]\tLoss: 0.209303\n","Train Epoch: 0 [1080/1718 (63%)]\tLoss: 0.025216\n","Train Epoch: 0 [1090/1718 (63%)]\tLoss: 0.008703\n","Train Epoch: 0 [1100/1718 (64%)]\tLoss: 0.010947\n","Train Epoch: 0 [1110/1718 (65%)]\tLoss: 0.145767\n","Train Epoch: 0 [1120/1718 (65%)]\tLoss: 1.501878\n","Train Epoch: 0 [1130/1718 (66%)]\tLoss: 0.004469\n","Train Epoch: 0 [1140/1718 (66%)]\tLoss: 0.005286\n","Train Epoch: 0 [1150/1718 (67%)]\tLoss: 0.889789\n","Train Epoch: 0 [1160/1718 (68%)]\tLoss: 0.523613\n","Train Epoch: 0 [1170/1718 (68%)]\tLoss: 0.289464\n","Train Epoch: 0 [1180/1718 (69%)]\tLoss: 0.575885\n","Train Epoch: 0 [1190/1718 (69%)]\tLoss: 0.035345\n","Train Epoch: 0 [1200/1718 (70%)]\tLoss: 0.034361\n","Train Epoch: 0 [1210/1718 (70%)]\tLoss: 0.003184\n","Train Epoch: 0 [1220/1718 (71%)]\tLoss: 0.000158\n","Train Epoch: 0 [1230/1718 (72%)]\tLoss: 0.779575\n","Train Epoch: 0 [1240/1718 (72%)]\tLoss: 0.000924\n","Train Epoch: 0 [1250/1718 (73%)]\tLoss: 0.602517\n","Train Epoch: 0 [1260/1718 (73%)]\tLoss: 0.594059\n","Train Epoch: 0 [1270/1718 (74%)]\tLoss: 0.424938\n","Train Epoch: 0 [1280/1718 (75%)]\tLoss: 0.297696\n","Train Epoch: 0 [1290/1718 (75%)]\tLoss: 0.798868\n","Train Epoch: 0 [1300/1718 (76%)]\tLoss: 0.017588\n","Train Epoch: 0 [1310/1718 (76%)]\tLoss: 0.165259\n","Train Epoch: 0 [1320/1718 (77%)]\tLoss: 0.002798\n","Train Epoch: 0 [1330/1718 (77%)]\tLoss: 0.066863\n","Train Epoch: 0 [1340/1718 (78%)]\tLoss: 0.507887\n","Train Epoch: 0 [1350/1718 (79%)]\tLoss: 0.006363\n","Train Epoch: 0 [1360/1718 (79%)]\tLoss: 0.741904\n","Train Epoch: 0 [1370/1718 (80%)]\tLoss: 1.287799\n","Train Epoch: 0 [1380/1718 (80%)]\tLoss: 0.152882\n","Train Epoch: 0 [1390/1718 (81%)]\tLoss: 0.019439\n","Train Epoch: 0 [1400/1718 (81%)]\tLoss: 0.067611\n","Train Epoch: 0 [1410/1718 (82%)]\tLoss: 0.035877\n","Train Epoch: 0 [1420/1718 (83%)]\tLoss: 0.005542\n","Train Epoch: 0 [1430/1718 (83%)]\tLoss: 0.012720\n","Train Epoch: 0 [1440/1718 (84%)]\tLoss: 0.439590\n","Train Epoch: 0 [1450/1718 (84%)]\tLoss: 1.013030\n","Train Epoch: 0 [1460/1718 (85%)]\tLoss: 0.005697\n","Train Epoch: 0 [1470/1718 (86%)]\tLoss: 0.124720\n","Train Epoch: 0 [1480/1718 (86%)]\tLoss: 0.027893\n","Train Epoch: 0 [1490/1718 (87%)]\tLoss: 1.195928\n","Train Epoch: 0 [1500/1718 (87%)]\tLoss: 0.004041\n","Train Epoch: 0 [1510/1718 (88%)]\tLoss: 0.022254\n","Train Epoch: 0 [1520/1718 (88%)]\tLoss: 0.401382\n","Train Epoch: 0 [1530/1718 (89%)]\tLoss: 0.192755\n","Train Epoch: 0 [1540/1718 (90%)]\tLoss: 0.000658\n","Train Epoch: 0 [1550/1718 (90%)]\tLoss: 0.005883\n","Train Epoch: 0 [1560/1718 (91%)]\tLoss: 0.587104\n","Train Epoch: 0 [1570/1718 (91%)]\tLoss: 0.000074\n","Train Epoch: 0 [1580/1718 (92%)]\tLoss: 0.003552\n","Train Epoch: 0 [1590/1718 (93%)]\tLoss: 0.007332\n","Train Epoch: 0 [1600/1718 (93%)]\tLoss: 0.278087\n","Train Epoch: 0 [1610/1718 (94%)]\tLoss: 0.703595\n","Train Epoch: 0 [1620/1718 (94%)]\tLoss: 0.045961\n","Train Epoch: 0 [1630/1718 (95%)]\tLoss: 0.003063\n","Train Epoch: 0 [1640/1718 (95%)]\tLoss: 0.054780\n","Train Epoch: 0 [1650/1718 (96%)]\tLoss: 0.000010\n","Train Epoch: 0 [1660/1718 (97%)]\tLoss: 0.041535\n","Train Epoch: 0 [1670/1718 (97%)]\tLoss: 0.002521\n","Train Epoch: 0 [1680/1718 (98%)]\tLoss: 0.002248\n","Train Epoch: 0 [1690/1718 (98%)]\tLoss: 0.088575\n","Train Epoch: 0 [1700/1718 (99%)]\tLoss: 0.602130\n","Train Epoch: 0 [1710/1718 (100%)]\tLoss: 0.033518\n","\n","Train Epoch: 1 [10/1718 (1%)]\tLoss: 0.026616\n","Train Epoch: 1 [20/1718 (1%)]\tLoss: 0.688301\n","Train Epoch: 1 [30/1718 (2%)]\tLoss: 1.259776\n","Train Epoch: 1 [40/1718 (2%)]\tLoss: 0.002972\n","Train Epoch: 1 [50/1718 (3%)]\tLoss: 0.011098\n","Train Epoch: 1 [60/1718 (3%)]\tLoss: 0.109644\n","Train Epoch: 1 [70/1718 (4%)]\tLoss: 0.000037\n","Train Epoch: 1 [80/1718 (5%)]\tLoss: 0.031224\n","Train Epoch: 1 [90/1718 (5%)]\tLoss: 0.411610\n","Train Epoch: 1 [100/1718 (6%)]\tLoss: 0.012833\n","Train Epoch: 1 [110/1718 (6%)]\tLoss: 0.271436\n","Train Epoch: 1 [120/1718 (7%)]\tLoss: 0.000425\n","Train Epoch: 1 [130/1718 (8%)]\tLoss: 0.254829\n","Train Epoch: 1 [140/1718 (8%)]\tLoss: 0.620699\n","Train Epoch: 1 [150/1718 (9%)]\tLoss: 1.265060\n","Train Epoch: 1 [160/1718 (9%)]\tLoss: 0.001160\n","Train Epoch: 1 [170/1718 (10%)]\tLoss: 0.406223\n","Train Epoch: 1 [180/1718 (10%)]\tLoss: 0.000670\n","Train Epoch: 1 [190/1718 (11%)]\tLoss: 0.002600\n","Train Epoch: 1 [200/1718 (12%)]\tLoss: 0.022860\n","Train Epoch: 1 [210/1718 (12%)]\tLoss: 0.037875\n","Train Epoch: 1 [220/1718 (13%)]\tLoss: 0.228013\n","Train Epoch: 1 [230/1718 (13%)]\tLoss: 0.000255\n","Train Epoch: 1 [240/1718 (14%)]\tLoss: 0.101382\n","Train Epoch: 1 [250/1718 (15%)]\tLoss: 0.261502\n","Train Epoch: 1 [260/1718 (15%)]\tLoss: 0.000013\n","Train Epoch: 1 [270/1718 (16%)]\tLoss: 0.001186\n","Train Epoch: 1 [280/1718 (16%)]\tLoss: 0.207819\n","Train Epoch: 1 [290/1718 (17%)]\tLoss: 0.811679\n","Train Epoch: 1 [300/1718 (17%)]\tLoss: 0.062773\n","Train Epoch: 1 [310/1718 (18%)]\tLoss: 0.017492\n","Train Epoch: 1 [320/1718 (19%)]\tLoss: 0.208339\n","Train Epoch: 1 [330/1718 (19%)]\tLoss: 0.170648\n","Train Epoch: 1 [340/1718 (20%)]\tLoss: 0.007455\n","Train Epoch: 1 [350/1718 (20%)]\tLoss: 0.294672\n","Train Epoch: 1 [360/1718 (21%)]\tLoss: 0.091896\n","Train Epoch: 1 [370/1718 (22%)]\tLoss: 0.024710\n","Train Epoch: 1 [380/1718 (22%)]\tLoss: 0.000427\n","Train Epoch: 1 [390/1718 (23%)]\tLoss: 0.116660\n","Train Epoch: 1 [400/1718 (23%)]\tLoss: 0.007719\n","Train Epoch: 1 [410/1718 (24%)]\tLoss: 1.000137\n","Train Epoch: 1 [420/1718 (24%)]\tLoss: 0.031235\n","Train Epoch: 1 [430/1718 (25%)]\tLoss: 0.012062\n","Train Epoch: 1 [440/1718 (26%)]\tLoss: 0.000377\n","Train Epoch: 1 [450/1718 (26%)]\tLoss: 0.003670\n","Train Epoch: 1 [460/1718 (27%)]\tLoss: 0.080125\n","Train Epoch: 1 [470/1718 (27%)]\tLoss: 0.303483\n","Train Epoch: 1 [480/1718 (28%)]\tLoss: 0.176594\n","Train Epoch: 1 [490/1718 (29%)]\tLoss: 0.308168\n","Train Epoch: 1 [500/1718 (29%)]\tLoss: 0.111054\n","Train Epoch: 1 [510/1718 (30%)]\tLoss: 0.007337\n","Train Epoch: 1 [520/1718 (30%)]\tLoss: 0.040639\n","Train Epoch: 1 [530/1718 (31%)]\tLoss: 0.039301\n","Train Epoch: 1 [540/1718 (31%)]\tLoss: 0.532578\n","Train Epoch: 1 [550/1718 (32%)]\tLoss: 0.066981\n","Train Epoch: 1 [560/1718 (33%)]\tLoss: 0.001209\n","Train Epoch: 1 [570/1718 (33%)]\tLoss: 0.015595\n","Train Epoch: 1 [580/1718 (34%)]\tLoss: 0.752352\n","Train Epoch: 1 [590/1718 (34%)]\tLoss: 0.671316\n","Train Epoch: 1 [600/1718 (35%)]\tLoss: 0.115999\n","Train Epoch: 1 [610/1718 (36%)]\tLoss: 0.108023\n","Train Epoch: 1 [620/1718 (36%)]\tLoss: 0.002488\n","Train Epoch: 1 [630/1718 (37%)]\tLoss: 0.017101\n","Train Epoch: 1 [640/1718 (37%)]\tLoss: 0.375148\n","Train Epoch: 1 [650/1718 (38%)]\tLoss: 1.632962\n","Train Epoch: 1 [660/1718 (38%)]\tLoss: 0.142712\n","Train Epoch: 1 [670/1718 (39%)]\tLoss: 0.000213\n","Train Epoch: 1 [680/1718 (40%)]\tLoss: 0.882555\n","Train Epoch: 1 [690/1718 (40%)]\tLoss: 0.061160\n","Train Epoch: 1 [700/1718 (41%)]\tLoss: 0.043557\n","Train Epoch: 1 [710/1718 (41%)]\tLoss: 0.059114\n","Train Epoch: 1 [720/1718 (42%)]\tLoss: 0.001548\n","Train Epoch: 1 [730/1718 (42%)]\tLoss: 0.000137\n","Train Epoch: 1 [740/1718 (43%)]\tLoss: 0.000024\n","Train Epoch: 1 [750/1718 (44%)]\tLoss: 0.313983\n","Train Epoch: 1 [760/1718 (44%)]\tLoss: 0.197839\n","Train Epoch: 1 [770/1718 (45%)]\tLoss: 0.414395\n","Train Epoch: 1 [780/1718 (45%)]\tLoss: 0.026808\n","Train Epoch: 1 [790/1718 (46%)]\tLoss: 0.107953\n","Train Epoch: 1 [800/1718 (47%)]\tLoss: 0.030222\n","Train Epoch: 1 [810/1718 (47%)]\tLoss: 0.038744\n","Train Epoch: 1 [820/1718 (48%)]\tLoss: 0.136087\n","Train Epoch: 1 [830/1718 (48%)]\tLoss: 0.005194\n","Train Epoch: 1 [840/1718 (49%)]\tLoss: 0.076523\n","Train Epoch: 1 [850/1718 (49%)]\tLoss: 0.423079\n","Train Epoch: 1 [860/1718 (50%)]\tLoss: 0.222189\n","Train Epoch: 1 [870/1718 (51%)]\tLoss: 0.145610\n","Train Epoch: 1 [880/1718 (51%)]\tLoss: 0.042883\n","Train Epoch: 1 [890/1718 (52%)]\tLoss: 0.024886\n","Train Epoch: 1 [900/1718 (52%)]\tLoss: 0.416195\n","Train Epoch: 1 [910/1718 (53%)]\tLoss: 0.000251\n","Train Epoch: 1 [920/1718 (54%)]\tLoss: 0.146655\n","Train Epoch: 1 [930/1718 (54%)]\tLoss: 1.115057\n","Train Epoch: 1 [940/1718 (55%)]\tLoss: 1.312371\n","Train Epoch: 1 [950/1718 (55%)]\tLoss: 0.242141\n","Train Epoch: 1 [960/1718 (56%)]\tLoss: 0.012538\n","Train Epoch: 1 [970/1718 (56%)]\tLoss: 0.720660\n","Train Epoch: 1 [980/1718 (57%)]\tLoss: 0.017237\n","Train Epoch: 1 [990/1718 (58%)]\tLoss: 0.008769\n","Train Epoch: 1 [1000/1718 (58%)]\tLoss: 1.367530\n","Train Epoch: 1 [1010/1718 (59%)]\tLoss: 0.008600\n","Train Epoch: 1 [1020/1718 (59%)]\tLoss: 1.061086\n","Train Epoch: 1 [1030/1718 (60%)]\tLoss: 0.426764\n","Train Epoch: 1 [1040/1718 (61%)]\tLoss: 0.179768\n","Train Epoch: 1 [1050/1718 (61%)]\tLoss: 0.076400\n","Train Epoch: 1 [1060/1718 (62%)]\tLoss: 0.030619\n","Train Epoch: 1 [1070/1718 (62%)]\tLoss: 1.007638\n","Train Epoch: 1 [1080/1718 (63%)]\tLoss: 1.299276\n","Train Epoch: 1 [1090/1718 (63%)]\tLoss: 0.641034\n","Train Epoch: 1 [1100/1718 (64%)]\tLoss: 1.374630\n","Train Epoch: 1 [1110/1718 (65%)]\tLoss: 0.002999\n","Train Epoch: 1 [1120/1718 (65%)]\tLoss: 0.153332\n","Train Epoch: 1 [1130/1718 (66%)]\tLoss: 0.605730\n","Train Epoch: 1 [1140/1718 (66%)]\tLoss: 0.002871\n","Train Epoch: 1 [1150/1718 (67%)]\tLoss: 0.208102\n","Train Epoch: 1 [1160/1718 (68%)]\tLoss: 0.200243\n","Train Epoch: 1 [1170/1718 (68%)]\tLoss: 0.370935\n","Train Epoch: 1 [1180/1718 (69%)]\tLoss: 0.048053\n","Train Epoch: 1 [1190/1718 (69%)]\tLoss: 0.000520\n","Train Epoch: 1 [1200/1718 (70%)]\tLoss: 0.002492\n","Train Epoch: 1 [1210/1718 (70%)]\tLoss: 1.324811\n","Train Epoch: 1 [1220/1718 (71%)]\tLoss: 0.215773\n","Train Epoch: 1 [1230/1718 (72%)]\tLoss: 0.256545\n","Train Epoch: 1 [1240/1718 (72%)]\tLoss: 0.029168\n","Train Epoch: 1 [1250/1718 (73%)]\tLoss: 0.022679\n","Train Epoch: 1 [1260/1718 (73%)]\tLoss: 0.629270\n","Train Epoch: 1 [1270/1718 (74%)]\tLoss: 0.048024\n","Train Epoch: 1 [1280/1718 (75%)]\tLoss: 0.000231\n","Train Epoch: 1 [1290/1718 (75%)]\tLoss: 0.047027\n","Train Epoch: 1 [1300/1718 (76%)]\tLoss: 0.410743\n","Train Epoch: 1 [1310/1718 (76%)]\tLoss: 0.844521\n","Train Epoch: 1 [1320/1718 (77%)]\tLoss: 0.500313\n","Train Epoch: 1 [1330/1718 (77%)]\tLoss: 0.005628\n","Train Epoch: 1 [1340/1718 (78%)]\tLoss: 0.824485\n","Train Epoch: 1 [1350/1718 (79%)]\tLoss: 0.000337\n","Train Epoch: 1 [1360/1718 (79%)]\tLoss: 0.000644\n","Train Epoch: 1 [1370/1718 (80%)]\tLoss: 0.008163\n","Train Epoch: 1 [1380/1718 (80%)]\tLoss: 0.026540\n","Train Epoch: 1 [1390/1718 (81%)]\tLoss: 0.002066\n","Train Epoch: 1 [1400/1718 (81%)]\tLoss: 1.926033\n","Train Epoch: 1 [1410/1718 (82%)]\tLoss: 0.033976\n","Train Epoch: 1 [1420/1718 (83%)]\tLoss: 1.039845\n","Train Epoch: 1 [1430/1718 (83%)]\tLoss: 0.131839\n","Train Epoch: 1 [1440/1718 (84%)]\tLoss: 0.015590\n","Train Epoch: 1 [1450/1718 (84%)]\tLoss: 0.000023\n","Train Epoch: 1 [1460/1718 (85%)]\tLoss: 0.002613\n","Train Epoch: 1 [1470/1718 (86%)]\tLoss: 0.020839\n","Train Epoch: 1 [1480/1718 (86%)]\tLoss: 0.042113\n","Train Epoch: 1 [1490/1718 (87%)]\tLoss: 0.000014\n","Train Epoch: 1 [1500/1718 (87%)]\tLoss: 0.000403\n","Train Epoch: 1 [1510/1718 (88%)]\tLoss: 1.457906\n","Train Epoch: 1 [1520/1718 (88%)]\tLoss: 0.712955\n","Train Epoch: 1 [1530/1718 (89%)]\tLoss: 0.006566\n","Train Epoch: 1 [1540/1718 (90%)]\tLoss: 0.000927\n","Train Epoch: 1 [1550/1718 (90%)]\tLoss: 0.488962\n","Train Epoch: 1 [1560/1718 (91%)]\tLoss: 0.004111\n","Train Epoch: 1 [1570/1718 (91%)]\tLoss: 0.288714\n","Train Epoch: 1 [1580/1718 (92%)]\tLoss: 0.051938\n","Train Epoch: 1 [1590/1718 (93%)]\tLoss: 0.665566\n","Train Epoch: 1 [1600/1718 (93%)]\tLoss: 0.001965\n","Train Epoch: 1 [1610/1718 (94%)]\tLoss: 0.005920\n","Train Epoch: 1 [1620/1718 (94%)]\tLoss: 1.001212\n","Train Epoch: 1 [1630/1718 (95%)]\tLoss: 0.043262\n","Train Epoch: 1 [1640/1718 (95%)]\tLoss: 0.132173\n","Train Epoch: 1 [1650/1718 (96%)]\tLoss: 0.114424\n","Train Epoch: 1 [1660/1718 (97%)]\tLoss: 0.142560\n","Train Epoch: 1 [1670/1718 (97%)]\tLoss: 0.000711\n","Train Epoch: 1 [1680/1718 (98%)]\tLoss: 0.412152\n","Train Epoch: 1 [1690/1718 (98%)]\tLoss: 0.046505\n","Train Epoch: 1 [1700/1718 (99%)]\tLoss: 0.002208\n","Train Epoch: 1 [1710/1718 (100%)]\tLoss: 0.595030\n","[tensor(183.8548, device='cuda:0')]\n","\n","Train Epoch: 2 [10/1718 (1%)]\tLoss: 1.003286\n","Train Epoch: 2 [20/1718 (1%)]\tLoss: 0.000022\n","Train Epoch: 2 [30/1718 (2%)]\tLoss: 0.448676\n","Train Epoch: 2 [40/1718 (2%)]\tLoss: 0.038096\n","Train Epoch: 2 [50/1718 (3%)]\tLoss: 0.541666\n","Train Epoch: 2 [60/1718 (3%)]\tLoss: 0.288734\n","Train Epoch: 2 [70/1718 (4%)]\tLoss: 0.078620\n","Train Epoch: 2 [80/1718 (5%)]\tLoss: 0.845906\n","Train Epoch: 2 [90/1718 (5%)]\tLoss: 0.001568\n","Train Epoch: 2 [100/1718 (6%)]\tLoss: 0.000821\n","Train Epoch: 2 [110/1718 (6%)]\tLoss: 0.000032\n","Train Epoch: 2 [120/1718 (7%)]\tLoss: 0.029209\n","Train Epoch: 2 [130/1718 (8%)]\tLoss: 0.002833\n","Train Epoch: 2 [140/1718 (8%)]\tLoss: 0.529731\n","Train Epoch: 2 [150/1718 (9%)]\tLoss: 0.001982\n","Train Epoch: 2 [160/1718 (9%)]\tLoss: 0.702721\n","Train Epoch: 2 [170/1718 (10%)]\tLoss: 0.361315\n","Train Epoch: 2 [180/1718 (10%)]\tLoss: 0.326827\n","Train Epoch: 2 [190/1718 (11%)]\tLoss: 0.037479\n","Train Epoch: 2 [200/1718 (12%)]\tLoss: 0.226302\n","Train Epoch: 2 [210/1718 (12%)]\tLoss: 0.001394\n","Train Epoch: 2 [220/1718 (13%)]\tLoss: 0.002729\n","Train Epoch: 2 [230/1718 (13%)]\tLoss: 0.054805\n","Train Epoch: 2 [240/1718 (14%)]\tLoss: 0.570200\n","Train Epoch: 2 [250/1718 (15%)]\tLoss: 0.000458\n","Train Epoch: 2 [260/1718 (15%)]\tLoss: 0.000080\n","Train Epoch: 2 [270/1718 (16%)]\tLoss: 0.989147\n","Train Epoch: 2 [280/1718 (16%)]\tLoss: 0.001416\n","Train Epoch: 2 [290/1718 (17%)]\tLoss: 0.003901\n","Train Epoch: 2 [300/1718 (17%)]\tLoss: 0.099836\n","Train Epoch: 2 [310/1718 (18%)]\tLoss: 0.006380\n","Train Epoch: 2 [320/1718 (19%)]\tLoss: 0.011704\n","Train Epoch: 2 [330/1718 (19%)]\tLoss: 0.118141\n","Train Epoch: 2 [340/1718 (20%)]\tLoss: 0.222616\n","Train Epoch: 2 [350/1718 (20%)]\tLoss: 0.406532\n","Train Epoch: 2 [360/1718 (21%)]\tLoss: 0.126863\n","Train Epoch: 2 [370/1718 (22%)]\tLoss: 0.000148\n","Train Epoch: 2 [380/1718 (22%)]\tLoss: 0.372752\n","Train Epoch: 2 [390/1718 (23%)]\tLoss: 0.628792\n","Train Epoch: 2 [400/1718 (23%)]\tLoss: 0.001241\n","Train Epoch: 2 [410/1718 (24%)]\tLoss: 0.110448\n","Train Epoch: 2 [420/1718 (24%)]\tLoss: 0.000714\n","Train Epoch: 2 [430/1718 (25%)]\tLoss: 0.009558\n","Train Epoch: 2 [440/1718 (26%)]\tLoss: 0.001934\n","Train Epoch: 2 [450/1718 (26%)]\tLoss: 0.066595\n","Train Epoch: 2 [460/1718 (27%)]\tLoss: 0.040986\n","Train Epoch: 2 [470/1718 (27%)]\tLoss: 0.624391\n","Train Epoch: 2 [480/1718 (28%)]\tLoss: 0.813266\n","Train Epoch: 2 [490/1718 (29%)]\tLoss: 0.386194\n","Train Epoch: 2 [500/1718 (29%)]\tLoss: 0.371812\n","Train Epoch: 2 [510/1718 (30%)]\tLoss: 0.002395\n","Train Epoch: 2 [520/1718 (30%)]\tLoss: 0.018009\n","Train Epoch: 2 [530/1718 (31%)]\tLoss: 0.235903\n","Train Epoch: 2 [540/1718 (31%)]\tLoss: 0.000710\n","Train Epoch: 2 [550/1718 (32%)]\tLoss: 0.607798\n","Train Epoch: 2 [560/1718 (33%)]\tLoss: 0.268582\n","Train Epoch: 2 [570/1718 (33%)]\tLoss: 1.254572\n","Train Epoch: 2 [580/1718 (34%)]\tLoss: 0.363148\n","Train Epoch: 2 [590/1718 (34%)]\tLoss: 0.542346\n","Train Epoch: 2 [600/1718 (35%)]\tLoss: 0.002251\n","Train Epoch: 2 [610/1718 (36%)]\tLoss: 0.112481\n","Train Epoch: 2 [620/1718 (36%)]\tLoss: 0.829215\n","Train Epoch: 2 [630/1718 (37%)]\tLoss: 1.168779\n","Train Epoch: 2 [640/1718 (37%)]\tLoss: 0.590136\n","Train Epoch: 2 [650/1718 (38%)]\tLoss: 0.341364\n","Train Epoch: 2 [660/1718 (38%)]\tLoss: 0.376197\n","Train Epoch: 2 [670/1718 (39%)]\tLoss: 0.241437\n","Train Epoch: 2 [680/1718 (40%)]\tLoss: 0.513942\n","Train Epoch: 2 [690/1718 (40%)]\tLoss: 0.558848\n","Train Epoch: 2 [700/1718 (41%)]\tLoss: 1.072610\n","Train Epoch: 2 [710/1718 (41%)]\tLoss: 0.014319\n","Train Epoch: 2 [720/1718 (42%)]\tLoss: 0.058762\n","Train Epoch: 2 [730/1718 (42%)]\tLoss: 0.035754\n","Train Epoch: 2 [740/1718 (43%)]\tLoss: 0.015194\n","Train Epoch: 2 [750/1718 (44%)]\tLoss: 0.278681\n","Train Epoch: 2 [760/1718 (44%)]\tLoss: 0.094394\n","Train Epoch: 2 [770/1718 (45%)]\tLoss: 0.566084\n","Train Epoch: 2 [780/1718 (45%)]\tLoss: 1.000250\n","Train Epoch: 2 [790/1718 (46%)]\tLoss: 0.209511\n","Train Epoch: 2 [800/1718 (47%)]\tLoss: 0.001985\n","Train Epoch: 2 [810/1718 (47%)]\tLoss: 0.579780\n","Train Epoch: 2 [820/1718 (48%)]\tLoss: 0.080146\n","Train Epoch: 2 [830/1718 (48%)]\tLoss: 0.188310\n","Train Epoch: 2 [840/1718 (49%)]\tLoss: 0.002513\n","Train Epoch: 2 [850/1718 (49%)]\tLoss: 0.035895\n","Train Epoch: 2 [860/1718 (50%)]\tLoss: 0.667679\n","Train Epoch: 2 [870/1718 (51%)]\tLoss: 0.001556\n","Train Epoch: 2 [880/1718 (51%)]\tLoss: 0.854265\n","Train Epoch: 2 [890/1718 (52%)]\tLoss: 0.335240\n","Train Epoch: 2 [900/1718 (52%)]\tLoss: 0.011905\n","Train Epoch: 2 [910/1718 (53%)]\tLoss: 0.035292\n","Train Epoch: 2 [920/1718 (54%)]\tLoss: 0.038828\n","Train Epoch: 2 [930/1718 (54%)]\tLoss: 0.198268\n","Train Epoch: 2 [940/1718 (55%)]\tLoss: 0.136827\n","Train Epoch: 2 [950/1718 (55%)]\tLoss: 0.233845\n","Train Epoch: 2 [960/1718 (56%)]\tLoss: 0.043579\n","Train Epoch: 2 [970/1718 (56%)]\tLoss: 0.000206\n","Train Epoch: 2 [980/1718 (57%)]\tLoss: 0.000672\n","Train Epoch: 2 [990/1718 (58%)]\tLoss: 0.000675\n","Train Epoch: 2 [1000/1718 (58%)]\tLoss: 0.381323\n","Train Epoch: 2 [1010/1718 (59%)]\tLoss: 0.000034\n","Train Epoch: 2 [1020/1718 (59%)]\tLoss: 0.005332\n","Train Epoch: 2 [1030/1718 (60%)]\tLoss: 0.003197\n","Train Epoch: 2 [1040/1718 (61%)]\tLoss: 0.000000\n","Train Epoch: 2 [1050/1718 (61%)]\tLoss: 0.000539\n","Train Epoch: 2 [1060/1718 (62%)]\tLoss: 0.008424\n","Train Epoch: 2 [1070/1718 (62%)]\tLoss: 0.010119\n","Train Epoch: 2 [1080/1718 (63%)]\tLoss: 0.439869\n","Train Epoch: 2 [1090/1718 (63%)]\tLoss: 0.000063\n","Train Epoch: 2 [1100/1718 (64%)]\tLoss: 0.001461\n","Train Epoch: 2 [1110/1718 (65%)]\tLoss: 0.619362\n","Train Epoch: 2 [1120/1718 (65%)]\tLoss: 0.051413\n","Train Epoch: 2 [1130/1718 (66%)]\tLoss: 0.836578\n","Train Epoch: 2 [1140/1718 (66%)]\tLoss: 0.130698\n","Train Epoch: 2 [1150/1718 (67%)]\tLoss: 0.092454\n","Train Epoch: 2 [1160/1718 (68%)]\tLoss: 0.047868\n","Train Epoch: 2 [1170/1718 (68%)]\tLoss: 0.283795\n","Train Epoch: 2 [1180/1718 (69%)]\tLoss: 0.032022\n","Train Epoch: 2 [1190/1718 (69%)]\tLoss: 0.176870\n","Train Epoch: 2 [1200/1718 (70%)]\tLoss: 0.835170\n","Train Epoch: 2 [1210/1718 (70%)]\tLoss: 0.001304\n","Train Epoch: 2 [1220/1718 (71%)]\tLoss: 0.115513\n","Train Epoch: 2 [1230/1718 (72%)]\tLoss: 0.251699\n","Train Epoch: 2 [1240/1718 (72%)]\tLoss: 0.383111\n","Train Epoch: 2 [1250/1718 (73%)]\tLoss: 0.191963\n","Train Epoch: 2 [1260/1718 (73%)]\tLoss: 0.465774\n","Train Epoch: 2 [1270/1718 (74%)]\tLoss: 0.850255\n","Train Epoch: 2 [1280/1718 (75%)]\tLoss: 0.093596\n","Train Epoch: 2 [1290/1718 (75%)]\tLoss: 0.010944\n","Train Epoch: 2 [1300/1718 (76%)]\tLoss: 0.001416\n","Train Epoch: 2 [1310/1718 (76%)]\tLoss: 0.000013\n","Train Epoch: 2 [1320/1718 (77%)]\tLoss: 0.280294\n","Train Epoch: 2 [1330/1718 (77%)]\tLoss: 0.730331\n","Train Epoch: 2 [1340/1718 (78%)]\tLoss: 0.003097\n","Train Epoch: 2 [1350/1718 (79%)]\tLoss: 0.000004\n","Train Epoch: 2 [1360/1718 (79%)]\tLoss: 0.005253\n","Train Epoch: 2 [1370/1718 (80%)]\tLoss: 0.374491\n","Train Epoch: 2 [1380/1718 (80%)]\tLoss: 0.038661\n","Train Epoch: 2 [1390/1718 (81%)]\tLoss: 0.001184\n","Train Epoch: 2 [1400/1718 (81%)]\tLoss: 0.000440\n","Train Epoch: 2 [1410/1718 (82%)]\tLoss: 0.006585\n","Train Epoch: 2 [1420/1718 (83%)]\tLoss: 0.000599\n","Train Epoch: 2 [1430/1718 (83%)]\tLoss: 0.003064\n","Train Epoch: 2 [1440/1718 (84%)]\tLoss: 0.000407\n","Train Epoch: 2 [1450/1718 (84%)]\tLoss: 0.160750\n","Train Epoch: 2 [1460/1718 (85%)]\tLoss: 0.129276\n","Train Epoch: 2 [1470/1718 (86%)]\tLoss: 0.320107\n","Train Epoch: 2 [1480/1718 (86%)]\tLoss: 0.570482\n","Train Epoch: 2 [1490/1718 (87%)]\tLoss: 0.000037\n","Train Epoch: 2 [1500/1718 (87%)]\tLoss: 0.001250\n","Train Epoch: 2 [1510/1718 (88%)]\tLoss: 0.017787\n","Train Epoch: 2 [1520/1718 (88%)]\tLoss: 0.056968\n","Train Epoch: 2 [1530/1718 (89%)]\tLoss: 0.002704\n","Train Epoch: 2 [1540/1718 (90%)]\tLoss: 0.506444\n","Train Epoch: 2 [1550/1718 (90%)]\tLoss: 0.222965\n","Train Epoch: 2 [1560/1718 (91%)]\tLoss: 0.186533\n","Train Epoch: 2 [1570/1718 (91%)]\tLoss: 0.038314\n","Train Epoch: 2 [1580/1718 (92%)]\tLoss: 0.052928\n","Train Epoch: 2 [1590/1718 (93%)]\tLoss: 0.000355\n","Train Epoch: 2 [1600/1718 (93%)]\tLoss: 0.053439\n","Train Epoch: 2 [1610/1718 (94%)]\tLoss: 0.174517\n","Train Epoch: 2 [1620/1718 (94%)]\tLoss: 0.003724\n","Train Epoch: 2 [1630/1718 (95%)]\tLoss: 0.011499\n","Train Epoch: 2 [1640/1718 (95%)]\tLoss: 0.000037\n","Train Epoch: 2 [1650/1718 (96%)]\tLoss: 0.029455\n","Train Epoch: 2 [1660/1718 (97%)]\tLoss: 0.131109\n","Train Epoch: 2 [1670/1718 (97%)]\tLoss: 0.273781\n","Train Epoch: 2 [1680/1718 (98%)]\tLoss: 0.002265\n","Train Epoch: 2 [1690/1718 (98%)]\tLoss: 0.157378\n","Train Epoch: 2 [1700/1718 (99%)]\tLoss: 0.001947\n","Train Epoch: 2 [1710/1718 (100%)]\tLoss: 0.000255\n","[tensor(183.8548, device='cuda:0'), tensor(129.5867, device='cuda:0')]\n","\n","Train Epoch: 3 [10/1718 (1%)]\tLoss: 0.389171\n","Train Epoch: 3 [20/1718 (1%)]\tLoss: 0.779517\n","Train Epoch: 3 [30/1718 (2%)]\tLoss: 0.127959\n","Train Epoch: 3 [40/1718 (2%)]\tLoss: 0.002272\n","Train Epoch: 3 [50/1718 (3%)]\tLoss: 0.016031\n","Train Epoch: 3 [60/1718 (3%)]\tLoss: 0.000049\n","Train Epoch: 3 [70/1718 (4%)]\tLoss: 0.280554\n","Train Epoch: 3 [80/1718 (5%)]\tLoss: 0.000004\n","Train Epoch: 3 [90/1718 (5%)]\tLoss: 0.509249\n","Train Epoch: 3 [100/1718 (6%)]\tLoss: 0.001022\n","Train Epoch: 3 [110/1718 (6%)]\tLoss: 0.015981\n","Train Epoch: 3 [120/1718 (7%)]\tLoss: 0.120791\n","Train Epoch: 3 [130/1718 (8%)]\tLoss: 0.675527\n","Train Epoch: 3 [140/1718 (8%)]\tLoss: 0.273471\n","Train Epoch: 3 [150/1718 (9%)]\tLoss: 0.034468\n","Train Epoch: 3 [160/1718 (9%)]\tLoss: 0.001636\n","Train Epoch: 3 [170/1718 (10%)]\tLoss: 0.000032\n","Train Epoch: 3 [180/1718 (10%)]\tLoss: 0.000597\n","Train Epoch: 3 [190/1718 (11%)]\tLoss: 1.100979\n","Train Epoch: 3 [200/1718 (12%)]\tLoss: 0.205330\n","Train Epoch: 3 [210/1718 (12%)]\tLoss: 0.254825\n","Train Epoch: 3 [220/1718 (13%)]\tLoss: 0.009106\n","Train Epoch: 3 [230/1718 (13%)]\tLoss: 0.058330\n","Train Epoch: 3 [240/1718 (14%)]\tLoss: 0.391270\n","Train Epoch: 3 [250/1718 (15%)]\tLoss: 0.050094\n","Train Epoch: 3 [260/1718 (15%)]\tLoss: 0.008515\n","Train Epoch: 3 [270/1718 (16%)]\tLoss: 0.001298\n","Train Epoch: 3 [280/1718 (16%)]\tLoss: 0.000434\n","Train Epoch: 3 [290/1718 (17%)]\tLoss: 0.012638\n","Train Epoch: 3 [300/1718 (17%)]\tLoss: 0.000008\n","Train Epoch: 3 [310/1718 (18%)]\tLoss: 0.477244\n","Train Epoch: 3 [320/1718 (19%)]\tLoss: 0.533412\n","Train Epoch: 3 [330/1718 (19%)]\tLoss: 0.022747\n","Train Epoch: 3 [340/1718 (20%)]\tLoss: 0.121820\n","Train Epoch: 3 [350/1718 (20%)]\tLoss: 0.976348\n","Train Epoch: 3 [360/1718 (21%)]\tLoss: 0.007861\n","Train Epoch: 3 [370/1718 (22%)]\tLoss: 0.000060\n","Train Epoch: 3 [380/1718 (22%)]\tLoss: 0.836925\n","Train Epoch: 3 [390/1718 (23%)]\tLoss: 0.551138\n","Train Epoch: 3 [400/1718 (23%)]\tLoss: 0.005242\n","Train Epoch: 3 [410/1718 (24%)]\tLoss: 0.222019\n","Train Epoch: 3 [420/1718 (24%)]\tLoss: 0.003610\n","Train Epoch: 3 [430/1718 (25%)]\tLoss: 0.066951\n","Train Epoch: 3 [440/1718 (26%)]\tLoss: 0.480680\n","Train Epoch: 3 [450/1718 (26%)]\tLoss: 0.402375\n","Train Epoch: 3 [460/1718 (27%)]\tLoss: 0.863127\n","Train Epoch: 3 [470/1718 (27%)]\tLoss: 0.017504\n","Train Epoch: 3 [480/1718 (28%)]\tLoss: 0.381838\n","Train Epoch: 3 [490/1718 (29%)]\tLoss: 0.140138\n","Train Epoch: 3 [500/1718 (29%)]\tLoss: 0.329361\n","Train Epoch: 3 [510/1718 (30%)]\tLoss: 0.337606\n","Train Epoch: 3 [520/1718 (30%)]\tLoss: 1.010078\n","Train Epoch: 3 [530/1718 (31%)]\tLoss: 0.018246\n","Train Epoch: 3 [540/1718 (31%)]\tLoss: 0.000402\n","Train Epoch: 3 [550/1718 (32%)]\tLoss: 0.137041\n","Train Epoch: 3 [560/1718 (33%)]\tLoss: 0.000083\n","Train Epoch: 3 [570/1718 (33%)]\tLoss: 0.000042\n","Train Epoch: 3 [580/1718 (34%)]\tLoss: 0.028180\n","Train Epoch: 3 [590/1718 (34%)]\tLoss: 0.141360\n","Train Epoch: 3 [600/1718 (35%)]\tLoss: 0.052245\n","Train Epoch: 3 [610/1718 (36%)]\tLoss: 0.463467\n","Train Epoch: 3 [620/1718 (36%)]\tLoss: 0.005971\n","Train Epoch: 3 [630/1718 (37%)]\tLoss: 0.001811\n","Train Epoch: 3 [640/1718 (37%)]\tLoss: 0.000002\n","Train Epoch: 3 [650/1718 (38%)]\tLoss: 0.402516\n","Train Epoch: 3 [660/1718 (38%)]\tLoss: 0.001253\n","Train Epoch: 3 [670/1718 (39%)]\tLoss: 0.025547\n","Train Epoch: 3 [680/1718 (40%)]\tLoss: 0.000418\n","Train Epoch: 3 [690/1718 (40%)]\tLoss: 0.037551\n","Train Epoch: 3 [700/1718 (41%)]\tLoss: 0.196868\n","Train Epoch: 3 [710/1718 (41%)]\tLoss: 0.015712\n","Train Epoch: 3 [720/1718 (42%)]\tLoss: 0.590608\n","Train Epoch: 3 [730/1718 (42%)]\tLoss: 0.031091\n","Train Epoch: 3 [740/1718 (43%)]\tLoss: 0.329257\n","Train Epoch: 3 [750/1718 (44%)]\tLoss: 0.146940\n","Train Epoch: 3 [760/1718 (44%)]\tLoss: 0.016153\n","Train Epoch: 3 [770/1718 (45%)]\tLoss: 1.387660\n","Train Epoch: 3 [780/1718 (45%)]\tLoss: 0.114784\n","Train Epoch: 3 [790/1718 (46%)]\tLoss: 0.202237\n","Train Epoch: 3 [800/1718 (47%)]\tLoss: 0.334866\n","Train Epoch: 3 [810/1718 (47%)]\tLoss: 0.000014\n","Train Epoch: 3 [820/1718 (48%)]\tLoss: 0.374096\n","Train Epoch: 3 [830/1718 (48%)]\tLoss: 0.005217\n","Train Epoch: 3 [840/1718 (49%)]\tLoss: 0.174146\n","Train Epoch: 3 [850/1718 (49%)]\tLoss: 0.000001\n","Train Epoch: 3 [860/1718 (50%)]\tLoss: 0.012421\n","Train Epoch: 3 [870/1718 (51%)]\tLoss: 0.000251\n","Train Epoch: 3 [880/1718 (51%)]\tLoss: 0.000582\n","Train Epoch: 3 [890/1718 (52%)]\tLoss: 0.014973\n","Train Epoch: 3 [900/1718 (52%)]\tLoss: 0.000013\n","Train Epoch: 3 [910/1718 (53%)]\tLoss: 0.013849\n","Train Epoch: 3 [920/1718 (54%)]\tLoss: 1.726793\n","Train Epoch: 3 [930/1718 (54%)]\tLoss: 0.032184\n","Train Epoch: 3 [940/1718 (55%)]\tLoss: 0.020970\n","Train Epoch: 3 [950/1718 (55%)]\tLoss: 0.000094\n","Train Epoch: 3 [960/1718 (56%)]\tLoss: 0.025659\n","Train Epoch: 3 [970/1718 (56%)]\tLoss: 0.014114\n","Train Epoch: 3 [980/1718 (57%)]\tLoss: 0.067354\n","Train Epoch: 3 [990/1718 (58%)]\tLoss: 0.001175\n","Train Epoch: 3 [1000/1718 (58%)]\tLoss: 0.014554\n","Train Epoch: 3 [1010/1718 (59%)]\tLoss: 0.004456\n","Train Epoch: 3 [1020/1718 (59%)]\tLoss: 0.001423\n","Train Epoch: 3 [1030/1718 (60%)]\tLoss: 0.127254\n","Train Epoch: 3 [1040/1718 (61%)]\tLoss: 0.259928\n","Train Epoch: 3 [1050/1718 (61%)]\tLoss: 0.012268\n","Train Epoch: 3 [1060/1718 (62%)]\tLoss: 0.163652\n","Train Epoch: 3 [1070/1718 (62%)]\tLoss: 0.065689\n","Train Epoch: 3 [1080/1718 (63%)]\tLoss: 0.052095\n","Train Epoch: 3 [1090/1718 (63%)]\tLoss: 0.000016\n","Train Epoch: 3 [1100/1718 (64%)]\tLoss: 0.567252\n","Train Epoch: 3 [1110/1718 (65%)]\tLoss: 0.789303\n","Train Epoch: 3 [1120/1718 (65%)]\tLoss: 0.000129\n","Train Epoch: 3 [1130/1718 (66%)]\tLoss: 0.048788\n","Train Epoch: 3 [1140/1718 (66%)]\tLoss: 0.001881\n","Train Epoch: 3 [1150/1718 (67%)]\tLoss: 0.000507\n","Train Epoch: 3 [1160/1718 (68%)]\tLoss: 0.000774\n","Train Epoch: 3 [1170/1718 (68%)]\tLoss: 0.300356\n","Train Epoch: 3 [1180/1718 (69%)]\tLoss: 0.789423\n","Train Epoch: 3 [1190/1718 (69%)]\tLoss: 0.006343\n","Train Epoch: 3 [1200/1718 (70%)]\tLoss: 0.027127\n","Train Epoch: 3 [1210/1718 (70%)]\tLoss: 0.030369\n","Train Epoch: 3 [1220/1718 (71%)]\tLoss: 0.067205\n","Train Epoch: 3 [1230/1718 (72%)]\tLoss: 0.030546\n","Train Epoch: 3 [1240/1718 (72%)]\tLoss: 0.306374\n","Train Epoch: 3 [1250/1718 (73%)]\tLoss: 0.035690\n","Train Epoch: 3 [1260/1718 (73%)]\tLoss: 0.003945\n","Train Epoch: 3 [1270/1718 (74%)]\tLoss: 0.005935\n","Train Epoch: 3 [1280/1718 (75%)]\tLoss: 0.000075\n","Train Epoch: 3 [1290/1718 (75%)]\tLoss: 0.006080\n","Train Epoch: 3 [1300/1718 (76%)]\tLoss: 0.006029\n","Train Epoch: 3 [1310/1718 (76%)]\tLoss: 0.061503\n","Train Epoch: 3 [1320/1718 (77%)]\tLoss: 0.022220\n","Train Epoch: 3 [1330/1718 (77%)]\tLoss: 0.234819\n","Train Epoch: 3 [1340/1718 (78%)]\tLoss: 0.880206\n","Train Epoch: 3 [1350/1718 (79%)]\tLoss: 0.019909\n","Train Epoch: 3 [1360/1718 (79%)]\tLoss: 0.030420\n","Train Epoch: 3 [1370/1718 (80%)]\tLoss: 0.000020\n","Train Epoch: 3 [1380/1718 (80%)]\tLoss: 0.115839\n","Train Epoch: 3 [1390/1718 (81%)]\tLoss: 0.000967\n","Train Epoch: 3 [1400/1718 (81%)]\tLoss: 0.071031\n","Train Epoch: 3 [1410/1718 (82%)]\tLoss: 0.000414\n","Train Epoch: 3 [1420/1718 (83%)]\tLoss: 0.855176\n","Train Epoch: 3 [1430/1718 (83%)]\tLoss: 0.028432\n","Train Epoch: 3 [1440/1718 (84%)]\tLoss: 0.002057\n","Train Epoch: 3 [1450/1718 (84%)]\tLoss: 1.269859\n","Train Epoch: 3 [1460/1718 (85%)]\tLoss: 0.468161\n","Train Epoch: 3 [1470/1718 (86%)]\tLoss: 0.001688\n","Train Epoch: 3 [1480/1718 (86%)]\tLoss: 0.003789\n","Train Epoch: 3 [1490/1718 (87%)]\tLoss: 0.000708\n","Train Epoch: 3 [1500/1718 (87%)]\tLoss: 0.009202\n","Train Epoch: 3 [1510/1718 (88%)]\tLoss: 0.001910\n","Train Epoch: 3 [1520/1718 (88%)]\tLoss: 0.209839\n","Train Epoch: 3 [1530/1718 (89%)]\tLoss: 0.001212\n","Train Epoch: 3 [1540/1718 (90%)]\tLoss: 1.201900\n","Train Epoch: 3 [1550/1718 (90%)]\tLoss: 0.015722\n","Train Epoch: 3 [1560/1718 (91%)]\tLoss: 0.078905\n","Train Epoch: 3 [1570/1718 (91%)]\tLoss: 0.000000\n","Train Epoch: 3 [1580/1718 (92%)]\tLoss: 0.144450\n","Train Epoch: 3 [1590/1718 (93%)]\tLoss: 0.001400\n","Train Epoch: 3 [1600/1718 (93%)]\tLoss: 1.178318\n","Train Epoch: 3 [1610/1718 (94%)]\tLoss: 0.398709\n","Train Epoch: 3 [1620/1718 (94%)]\tLoss: 0.661315\n","Train Epoch: 3 [1630/1718 (95%)]\tLoss: 0.002321\n","Train Epoch: 3 [1640/1718 (95%)]\tLoss: 0.237011\n","Train Epoch: 3 [1650/1718 (96%)]\tLoss: 0.100346\n","Train Epoch: 3 [1660/1718 (97%)]\tLoss: 0.067078\n","Train Epoch: 3 [1670/1718 (97%)]\tLoss: 0.140212\n","Train Epoch: 3 [1680/1718 (98%)]\tLoss: 0.228930\n","Train Epoch: 3 [1690/1718 (98%)]\tLoss: 2.753522\n","Train Epoch: 3 [1700/1718 (99%)]\tLoss: 0.160555\n","Train Epoch: 3 [1710/1718 (100%)]\tLoss: 0.544989\n","[tensor(183.8548, device='cuda:0'), tensor(129.5867, device='cuda:0'), tensor(42.7446, device='cuda:0')]\n","\n","Train Epoch: 4 [10/1718 (1%)]\tLoss: 0.045370\n","Train Epoch: 4 [20/1718 (1%)]\tLoss: 0.181351\n","Train Epoch: 4 [30/1718 (2%)]\tLoss: 0.304536\n","Train Epoch: 4 [40/1718 (2%)]\tLoss: 0.000676\n","Train Epoch: 4 [50/1718 (3%)]\tLoss: 0.376449\n","Train Epoch: 4 [60/1718 (3%)]\tLoss: 0.038180\n","Train Epoch: 4 [70/1718 (4%)]\tLoss: 0.000040\n","Train Epoch: 4 [80/1718 (5%)]\tLoss: 0.000262\n","Train Epoch: 4 [90/1718 (5%)]\tLoss: 0.006739\n","Train Epoch: 4 [100/1718 (6%)]\tLoss: 0.000001\n","Train Epoch: 4 [110/1718 (6%)]\tLoss: 0.417876\n","Train Epoch: 4 [120/1718 (7%)]\tLoss: 0.064346\n","Train Epoch: 4 [130/1718 (8%)]\tLoss: 0.120800\n","Train Epoch: 4 [140/1718 (8%)]\tLoss: 0.000677\n","Train Epoch: 4 [150/1718 (9%)]\tLoss: 0.051050\n","Train Epoch: 4 [160/1718 (9%)]\tLoss: 0.012722\n","Train Epoch: 4 [170/1718 (10%)]\tLoss: 0.001008\n","Train Epoch: 4 [180/1718 (10%)]\tLoss: 0.000001\n","Train Epoch: 4 [190/1718 (11%)]\tLoss: 0.001143\n","Train Epoch: 4 [200/1718 (12%)]\tLoss: 0.215475\n","Train Epoch: 4 [210/1718 (12%)]\tLoss: 0.941705\n","Train Epoch: 4 [220/1718 (13%)]\tLoss: 0.724439\n","Train Epoch: 4 [230/1718 (13%)]\tLoss: 0.005417\n","Train Epoch: 4 [240/1718 (14%)]\tLoss: 0.354069\n","Train Epoch: 4 [250/1718 (15%)]\tLoss: 0.252296\n","Train Epoch: 4 [260/1718 (15%)]\tLoss: 0.000204\n","Train Epoch: 4 [270/1718 (16%)]\tLoss: 0.000942\n","Train Epoch: 4 [280/1718 (16%)]\tLoss: 0.171313\n","Train Epoch: 4 [290/1718 (17%)]\tLoss: 0.001652\n","Train Epoch: 4 [300/1718 (17%)]\tLoss: 0.002002\n","Train Epoch: 4 [310/1718 (18%)]\tLoss: 0.046777\n","Train Epoch: 4 [320/1718 (19%)]\tLoss: 0.008977\n","Train Epoch: 4 [330/1718 (19%)]\tLoss: 0.112964\n","Train Epoch: 4 [340/1718 (20%)]\tLoss: 0.040383\n","Train Epoch: 4 [350/1718 (20%)]\tLoss: 0.100551\n","Train Epoch: 4 [360/1718 (21%)]\tLoss: 0.000081\n","Train Epoch: 4 [370/1718 (22%)]\tLoss: 0.000479\n","Train Epoch: 4 [380/1718 (22%)]\tLoss: 0.014784\n","Train Epoch: 4 [390/1718 (23%)]\tLoss: 0.076737\n","Train Epoch: 4 [400/1718 (23%)]\tLoss: 0.135952\n","Train Epoch: 4 [410/1718 (24%)]\tLoss: 0.001496\n","Train Epoch: 4 [420/1718 (24%)]\tLoss: 0.556102\n","Train Epoch: 4 [430/1718 (25%)]\tLoss: 0.002218\n","Train Epoch: 4 [440/1718 (26%)]\tLoss: 0.003864\n","Train Epoch: 4 [450/1718 (26%)]\tLoss: 0.000016\n","Train Epoch: 4 [460/1718 (27%)]\tLoss: 1.460344\n","Train Epoch: 4 [470/1718 (27%)]\tLoss: 0.000196\n","Train Epoch: 4 [480/1718 (28%)]\tLoss: 0.000162\n","Train Epoch: 4 [490/1718 (29%)]\tLoss: 0.377429\n","Train Epoch: 4 [500/1718 (29%)]\tLoss: 0.120643\n","Train Epoch: 4 [510/1718 (30%)]\tLoss: 0.217895\n","Train Epoch: 4 [520/1718 (30%)]\tLoss: 0.000245\n","Train Epoch: 4 [530/1718 (31%)]\tLoss: 0.057350\n","Train Epoch: 4 [540/1718 (31%)]\tLoss: 0.412802\n","Train Epoch: 4 [550/1718 (32%)]\tLoss: 0.000973\n","Train Epoch: 4 [560/1718 (33%)]\tLoss: 0.002390\n","Train Epoch: 4 [570/1718 (33%)]\tLoss: 0.039023\n","Train Epoch: 4 [580/1718 (34%)]\tLoss: 0.029111\n","Train Epoch: 4 [590/1718 (34%)]\tLoss: 0.000199\n","Train Epoch: 4 [600/1718 (35%)]\tLoss: 0.164601\n","Train Epoch: 4 [610/1718 (36%)]\tLoss: 0.158257\n","Train Epoch: 4 [620/1718 (36%)]\tLoss: 0.000006\n","Train Epoch: 4 [630/1718 (37%)]\tLoss: 0.000003\n","Train Epoch: 4 [640/1718 (37%)]\tLoss: 0.024650\n","Train Epoch: 4 [650/1718 (38%)]\tLoss: 0.001135\n","Train Epoch: 4 [660/1718 (38%)]\tLoss: 0.029164\n","Train Epoch: 4 [670/1718 (39%)]\tLoss: 0.572507\n","Train Epoch: 4 [680/1718 (40%)]\tLoss: 0.105556\n","Train Epoch: 4 [690/1718 (40%)]\tLoss: 0.186286\n","Train Epoch: 4 [700/1718 (41%)]\tLoss: 0.150557\n","Train Epoch: 4 [710/1718 (41%)]\tLoss: 1.412822\n","Train Epoch: 4 [720/1718 (42%)]\tLoss: 0.109329\n","Train Epoch: 4 [730/1718 (42%)]\tLoss: 0.159043\n","Train Epoch: 4 [740/1718 (43%)]\tLoss: 0.000106\n","Train Epoch: 4 [750/1718 (44%)]\tLoss: 0.064554\n","Train Epoch: 4 [760/1718 (44%)]\tLoss: 0.000206\n","Train Epoch: 4 [770/1718 (45%)]\tLoss: 0.431477\n","Train Epoch: 4 [780/1718 (45%)]\tLoss: 0.000011\n","Train Epoch: 4 [790/1718 (46%)]\tLoss: 0.003200\n","Train Epoch: 4 [800/1718 (47%)]\tLoss: 0.371086\n","Train Epoch: 4 [810/1718 (47%)]\tLoss: 0.705624\n","Train Epoch: 4 [820/1718 (48%)]\tLoss: 0.000588\n","Train Epoch: 4 [830/1718 (48%)]\tLoss: 0.382546\n","Train Epoch: 4 [840/1718 (49%)]\tLoss: 0.009644\n","Train Epoch: 4 [850/1718 (49%)]\tLoss: 0.001620\n","Train Epoch: 4 [860/1718 (50%)]\tLoss: 1.061273\n","Train Epoch: 4 [870/1718 (51%)]\tLoss: 0.866488\n","Train Epoch: 4 [880/1718 (51%)]\tLoss: 0.000497\n","Train Epoch: 4 [890/1718 (52%)]\tLoss: 0.000920\n","Train Epoch: 4 [900/1718 (52%)]\tLoss: 1.366403\n","Train Epoch: 4 [910/1718 (53%)]\tLoss: 0.015885\n","Train Epoch: 4 [920/1718 (54%)]\tLoss: 0.001598\n","Train Epoch: 4 [930/1718 (54%)]\tLoss: 0.000008\n","Train Epoch: 4 [940/1718 (55%)]\tLoss: 0.007904\n","Train Epoch: 4 [950/1718 (55%)]\tLoss: 0.337842\n","Train Epoch: 4 [960/1718 (56%)]\tLoss: 0.110268\n","Train Epoch: 4 [970/1718 (56%)]\tLoss: 0.000069\n","Train Epoch: 4 [980/1718 (57%)]\tLoss: 0.759355\n","Train Epoch: 4 [990/1718 (58%)]\tLoss: 1.161494\n","Train Epoch: 4 [1000/1718 (58%)]\tLoss: 0.000315\n","Train Epoch: 4 [1010/1718 (59%)]\tLoss: 0.068643\n","Train Epoch: 4 [1020/1718 (59%)]\tLoss: 0.000488\n","Train Epoch: 4 [1030/1718 (60%)]\tLoss: 0.027406\n","Train Epoch: 4 [1040/1718 (61%)]\tLoss: 0.075554\n","Train Epoch: 4 [1050/1718 (61%)]\tLoss: 0.010188\n","Train Epoch: 4 [1060/1718 (62%)]\tLoss: 0.000934\n","Train Epoch: 4 [1070/1718 (62%)]\tLoss: 0.007167\n","Train Epoch: 4 [1080/1718 (63%)]\tLoss: 0.005140\n","Train Epoch: 4 [1090/1718 (63%)]\tLoss: 0.130652\n","Train Epoch: 4 [1100/1718 (64%)]\tLoss: 0.002519\n","Train Epoch: 4 [1110/1718 (65%)]\tLoss: 0.045767\n","Train Epoch: 4 [1120/1718 (65%)]\tLoss: 0.365978\n","Train Epoch: 4 [1130/1718 (66%)]\tLoss: 0.045986\n","Train Epoch: 4 [1140/1718 (66%)]\tLoss: 0.012370\n","Train Epoch: 4 [1150/1718 (67%)]\tLoss: 0.002200\n","Train Epoch: 4 [1160/1718 (68%)]\tLoss: 0.403491\n","Train Epoch: 4 [1170/1718 (68%)]\tLoss: 0.000175\n","Train Epoch: 4 [1180/1718 (69%)]\tLoss: 0.630148\n","Train Epoch: 4 [1190/1718 (69%)]\tLoss: 0.014366\n","Train Epoch: 4 [1200/1718 (70%)]\tLoss: 0.000013\n","Train Epoch: 4 [1210/1718 (70%)]\tLoss: 0.168198\n","Train Epoch: 4 [1220/1718 (71%)]\tLoss: 0.006931\n","Train Epoch: 4 [1230/1718 (72%)]\tLoss: 0.279669\n","Train Epoch: 4 [1240/1718 (72%)]\tLoss: 1.977880\n","Train Epoch: 4 [1250/1718 (73%)]\tLoss: 0.228701\n","Train Epoch: 4 [1260/1718 (73%)]\tLoss: 0.000922\n","Train Epoch: 4 [1270/1718 (74%)]\tLoss: 0.004255\n","Train Epoch: 4 [1280/1718 (75%)]\tLoss: 0.017358\n","Train Epoch: 4 [1290/1718 (75%)]\tLoss: 0.000165\n","Train Epoch: 4 [1300/1718 (76%)]\tLoss: 0.647576\n","Train Epoch: 4 [1310/1718 (76%)]\tLoss: 0.000033\n","Train Epoch: 4 [1320/1718 (77%)]\tLoss: 0.000816\n","Train Epoch: 4 [1330/1718 (77%)]\tLoss: 0.289590\n","Train Epoch: 4 [1340/1718 (78%)]\tLoss: 0.000892\n","Train Epoch: 4 [1350/1718 (79%)]\tLoss: 0.076369\n","Train Epoch: 4 [1360/1718 (79%)]\tLoss: 0.453684\n","Train Epoch: 4 [1370/1718 (80%)]\tLoss: 0.376562\n","Train Epoch: 4 [1380/1718 (80%)]\tLoss: 0.744895\n","Train Epoch: 4 [1390/1718 (81%)]\tLoss: 0.537078\n","Train Epoch: 4 [1400/1718 (81%)]\tLoss: 0.264646\n","Train Epoch: 4 [1410/1718 (82%)]\tLoss: 0.000527\n","Train Epoch: 4 [1420/1718 (83%)]\tLoss: 1.335053\n","Train Epoch: 4 [1430/1718 (83%)]\tLoss: 0.003204\n","Train Epoch: 4 [1440/1718 (84%)]\tLoss: 0.014606\n","Train Epoch: 4 [1450/1718 (84%)]\tLoss: 0.055024\n","Train Epoch: 4 [1460/1718 (85%)]\tLoss: 0.000992\n","Train Epoch: 4 [1470/1718 (86%)]\tLoss: 0.006758\n","Train Epoch: 4 [1480/1718 (86%)]\tLoss: 0.005426\n","Train Epoch: 4 [1490/1718 (87%)]\tLoss: 0.033331\n","Train Epoch: 4 [1500/1718 (87%)]\tLoss: 0.002023\n","Train Epoch: 4 [1510/1718 (88%)]\tLoss: 1.993554\n","Train Epoch: 4 [1520/1718 (88%)]\tLoss: 0.050977\n","Train Epoch: 4 [1530/1718 (89%)]\tLoss: 0.146773\n","Train Epoch: 4 [1540/1718 (90%)]\tLoss: 0.000004\n","Train Epoch: 4 [1550/1718 (90%)]\tLoss: 0.027492\n","Train Epoch: 4 [1560/1718 (91%)]\tLoss: 0.062843\n","Train Epoch: 4 [1570/1718 (91%)]\tLoss: 0.017562\n","Train Epoch: 4 [1580/1718 (92%)]\tLoss: 0.942669\n","Train Epoch: 4 [1590/1718 (93%)]\tLoss: 0.050393\n","Train Epoch: 4 [1600/1718 (93%)]\tLoss: 0.001892\n","Train Epoch: 4 [1610/1718 (94%)]\tLoss: 0.132872\n","Train Epoch: 4 [1620/1718 (94%)]\tLoss: 0.014251\n","Train Epoch: 4 [1630/1718 (95%)]\tLoss: 0.002267\n","Train Epoch: 4 [1640/1718 (95%)]\tLoss: 0.001467\n","Train Epoch: 4 [1650/1718 (96%)]\tLoss: 0.000458\n","Train Epoch: 4 [1660/1718 (97%)]\tLoss: 0.000000\n","Train Epoch: 4 [1670/1718 (97%)]\tLoss: 0.438549\n","Train Epoch: 4 [1680/1718 (98%)]\tLoss: 1.740369\n","Train Epoch: 4 [1690/1718 (98%)]\tLoss: 0.002044\n","Train Epoch: 4 [1700/1718 (99%)]\tLoss: 0.046041\n","Train Epoch: 4 [1710/1718 (100%)]\tLoss: 0.442408\n","[tensor(183.8548, device='cuda:0'), tensor(129.5867, device='cuda:0'), tensor(42.7446, device='cuda:0'), tensor(102.3077, device='cuda:0')]\n","\n","Train Epoch: 5 [10/1718 (1%)]\tLoss: 0.463885\n","Train Epoch: 5 [20/1718 (1%)]\tLoss: 0.017787\n","Train Epoch: 5 [30/1718 (2%)]\tLoss: 0.656614\n","Train Epoch: 5 [40/1718 (2%)]\tLoss: 0.033188\n","Train Epoch: 5 [50/1718 (3%)]\tLoss: 0.093454\n","Train Epoch: 5 [60/1718 (3%)]\tLoss: 0.015109\n","Train Epoch: 5 [70/1718 (4%)]\tLoss: 0.077775\n","Train Epoch: 5 [80/1718 (5%)]\tLoss: 0.000024\n","Train Epoch: 5 [90/1718 (5%)]\tLoss: 0.000197\n","Train Epoch: 5 [100/1718 (6%)]\tLoss: 0.003983\n","Train Epoch: 5 [110/1718 (6%)]\tLoss: 0.080645\n","Train Epoch: 5 [120/1718 (7%)]\tLoss: 0.256512\n","Train Epoch: 5 [130/1718 (8%)]\tLoss: 0.662381\n","Train Epoch: 5 [140/1718 (8%)]\tLoss: 0.683611\n","Train Epoch: 5 [150/1718 (9%)]\tLoss: 0.005547\n","Train Epoch: 5 [160/1718 (9%)]\tLoss: 0.000265\n","Train Epoch: 5 [170/1718 (10%)]\tLoss: 0.011272\n","Train Epoch: 5 [180/1718 (10%)]\tLoss: 1.093964\n","Train Epoch: 5 [190/1718 (11%)]\tLoss: 0.007349\n","Train Epoch: 5 [200/1718 (12%)]\tLoss: 0.005128\n","Train Epoch: 5 [210/1718 (12%)]\tLoss: 0.000437\n","Train Epoch: 5 [220/1718 (13%)]\tLoss: 0.497924\n","Train Epoch: 5 [230/1718 (13%)]\tLoss: 0.000043\n","Train Epoch: 5 [240/1718 (14%)]\tLoss: 0.000000\n","Train Epoch: 5 [250/1718 (15%)]\tLoss: 0.288899\n","Train Epoch: 5 [260/1718 (15%)]\tLoss: 0.043943\n","Train Epoch: 5 [270/1718 (16%)]\tLoss: 0.015709\n","Train Epoch: 5 [280/1718 (16%)]\tLoss: 0.000027\n","Train Epoch: 5 [290/1718 (17%)]\tLoss: 0.083778\n","Train Epoch: 5 [300/1718 (17%)]\tLoss: 0.010114\n","Train Epoch: 5 [310/1718 (18%)]\tLoss: 1.591297\n","Train Epoch: 5 [320/1718 (19%)]\tLoss: 0.000077\n","Train Epoch: 5 [330/1718 (19%)]\tLoss: 0.000004\n","Train Epoch: 5 [340/1718 (20%)]\tLoss: 0.033023\n","Train Epoch: 5 [350/1718 (20%)]\tLoss: 0.000001\n","Train Epoch: 5 [360/1718 (21%)]\tLoss: 0.000098\n","Train Epoch: 5 [370/1718 (22%)]\tLoss: 0.000539\n","Train Epoch: 5 [380/1718 (22%)]\tLoss: 0.788497\n","Train Epoch: 5 [390/1718 (23%)]\tLoss: 1.587756\n","Train Epoch: 5 [400/1718 (23%)]\tLoss: 0.097020\n","Train Epoch: 5 [410/1718 (24%)]\tLoss: 0.002705\n","Train Epoch: 5 [420/1718 (24%)]\tLoss: 0.022430\n","Train Epoch: 5 [430/1718 (25%)]\tLoss: 0.000515\n","Train Epoch: 5 [440/1718 (26%)]\tLoss: 0.000289\n","Train Epoch: 5 [450/1718 (26%)]\tLoss: 0.000000\n","Train Epoch: 5 [460/1718 (27%)]\tLoss: 0.643898\n","Train Epoch: 5 [470/1718 (27%)]\tLoss: 0.000278\n","Train Epoch: 5 [480/1718 (28%)]\tLoss: 0.000067\n","Train Epoch: 5 [490/1718 (29%)]\tLoss: 0.060665\n","Train Epoch: 5 [500/1718 (29%)]\tLoss: 0.595454\n","Train Epoch: 5 [510/1718 (30%)]\tLoss: 0.289567\n","Train Epoch: 5 [520/1718 (30%)]\tLoss: 0.000338\n","Train Epoch: 5 [530/1718 (31%)]\tLoss: 0.000011\n","Train Epoch: 5 [540/1718 (31%)]\tLoss: 0.000051\n","Train Epoch: 5 [550/1718 (32%)]\tLoss: 0.278163\n","Train Epoch: 5 [560/1718 (33%)]\tLoss: 0.002407\n","Train Epoch: 5 [570/1718 (33%)]\tLoss: 0.002810\n","Train Epoch: 5 [580/1718 (34%)]\tLoss: 0.256665\n","Train Epoch: 5 [590/1718 (34%)]\tLoss: 0.073615\n","Train Epoch: 5 [600/1718 (35%)]\tLoss: 0.000580\n","Train Epoch: 5 [610/1718 (36%)]\tLoss: 0.017816\n","Train Epoch: 5 [620/1718 (36%)]\tLoss: 0.971892\n","Train Epoch: 5 [630/1718 (37%)]\tLoss: 0.036968\n","Train Epoch: 5 [640/1718 (37%)]\tLoss: 0.367090\n","Train Epoch: 5 [650/1718 (38%)]\tLoss: 0.003285\n","Train Epoch: 5 [660/1718 (38%)]\tLoss: 0.000008\n","Train Epoch: 5 [670/1718 (39%)]\tLoss: 0.061338\n","Train Epoch: 5 [680/1718 (40%)]\tLoss: 0.231064\n","Train Epoch: 5 [690/1718 (40%)]\tLoss: 0.013141\n","Train Epoch: 5 [700/1718 (41%)]\tLoss: 0.007139\n","Train Epoch: 5 [710/1718 (41%)]\tLoss: 0.595000\n","Train Epoch: 5 [720/1718 (42%)]\tLoss: 0.244275\n","Train Epoch: 5 [730/1718 (42%)]\tLoss: 0.000053\n","Train Epoch: 5 [740/1718 (43%)]\tLoss: 0.000154\n","Train Epoch: 5 [750/1718 (44%)]\tLoss: 0.021915\n","Train Epoch: 5 [760/1718 (44%)]\tLoss: 0.000697\n","Train Epoch: 5 [770/1718 (45%)]\tLoss: 0.160856\n","Train Epoch: 5 [780/1718 (45%)]\tLoss: 0.920771\n","Train Epoch: 5 [790/1718 (46%)]\tLoss: 0.123788\n","Train Epoch: 5 [800/1718 (47%)]\tLoss: 0.009183\n","Train Epoch: 5 [810/1718 (47%)]\tLoss: 0.009531\n","Train Epoch: 5 [820/1718 (48%)]\tLoss: 0.001795\n","Train Epoch: 5 [830/1718 (48%)]\tLoss: 0.022230\n","Train Epoch: 5 [840/1718 (49%)]\tLoss: 0.000124\n","Train Epoch: 5 [850/1718 (49%)]\tLoss: 0.000174\n","Train Epoch: 5 [860/1718 (50%)]\tLoss: 0.000069\n","Train Epoch: 5 [870/1718 (51%)]\tLoss: 1.095867\n","Train Epoch: 5 [880/1718 (51%)]\tLoss: 0.000085\n","Train Epoch: 5 [890/1718 (52%)]\tLoss: 0.010863\n","Train Epoch: 5 [900/1718 (52%)]\tLoss: 0.011254\n","Train Epoch: 5 [910/1718 (53%)]\tLoss: 0.000000\n","Train Epoch: 5 [920/1718 (54%)]\tLoss: 0.000000\n","Train Epoch: 5 [930/1718 (54%)]\tLoss: 0.366557\n","Train Epoch: 5 [940/1718 (55%)]\tLoss: 0.118834\n","Train Epoch: 5 [950/1718 (55%)]\tLoss: 0.000950\n","Train Epoch: 5 [960/1718 (56%)]\tLoss: 0.010823\n","Train Epoch: 5 [970/1718 (56%)]\tLoss: 0.686461\n","Train Epoch: 5 [980/1718 (57%)]\tLoss: 0.002561\n","Train Epoch: 5 [990/1718 (58%)]\tLoss: 0.107620\n","Train Epoch: 5 [1000/1718 (58%)]\tLoss: 1.080604\n","Train Epoch: 5 [1010/1718 (59%)]\tLoss: 0.000458\n","Train Epoch: 5 [1020/1718 (59%)]\tLoss: 0.000371\n","Train Epoch: 5 [1030/1718 (60%)]\tLoss: 0.000004\n","Train Epoch: 5 [1040/1718 (61%)]\tLoss: 0.004690\n","Train Epoch: 5 [1050/1718 (61%)]\tLoss: 0.022313\n","Train Epoch: 5 [1060/1718 (62%)]\tLoss: 0.614919\n","Train Epoch: 5 [1070/1718 (62%)]\tLoss: 0.153929\n","Train Epoch: 5 [1080/1718 (63%)]\tLoss: 0.142431\n","Train Epoch: 5 [1090/1718 (63%)]\tLoss: 0.548101\n","Train Epoch: 5 [1100/1718 (64%)]\tLoss: 1.333075\n","Train Epoch: 5 [1110/1718 (65%)]\tLoss: 0.000238\n","Train Epoch: 5 [1120/1718 (65%)]\tLoss: 0.000399\n","Train Epoch: 5 [1130/1718 (66%)]\tLoss: 0.208848\n","Train Epoch: 5 [1140/1718 (66%)]\tLoss: 0.000005\n","Train Epoch: 5 [1150/1718 (67%)]\tLoss: 0.000827\n","Train Epoch: 5 [1160/1718 (68%)]\tLoss: 0.002880\n","Train Epoch: 5 [1170/1718 (68%)]\tLoss: 0.018465\n","Train Epoch: 5 [1180/1718 (69%)]\tLoss: 0.162010\n","Train Epoch: 5 [1190/1718 (69%)]\tLoss: 0.021396\n","Train Epoch: 5 [1200/1718 (70%)]\tLoss: 0.035446\n","Train Epoch: 5 [1210/1718 (70%)]\tLoss: 0.000422\n","Train Epoch: 5 [1220/1718 (71%)]\tLoss: 0.008339\n","Train Epoch: 5 [1230/1718 (72%)]\tLoss: 0.003944\n","Train Epoch: 5 [1240/1718 (72%)]\tLoss: 0.290047\n","Train Epoch: 5 [1250/1718 (73%)]\tLoss: 0.000008\n","Train Epoch: 5 [1260/1718 (73%)]\tLoss: 0.000016\n","Train Epoch: 5 [1270/1718 (74%)]\tLoss: 0.001973\n","Train Epoch: 5 [1280/1718 (75%)]\tLoss: 0.026175\n","Train Epoch: 5 [1290/1718 (75%)]\tLoss: 0.000939\n","Train Epoch: 5 [1300/1718 (76%)]\tLoss: 0.034598\n","Train Epoch: 5 [1310/1718 (76%)]\tLoss: 0.616553\n","Train Epoch: 5 [1320/1718 (77%)]\tLoss: 0.000684\n","Train Epoch: 5 [1330/1718 (77%)]\tLoss: 0.009244\n","Train Epoch: 5 [1340/1718 (78%)]\tLoss: 1.055611\n","Train Epoch: 5 [1350/1718 (79%)]\tLoss: 0.002561\n","Train Epoch: 5 [1360/1718 (79%)]\tLoss: 0.000003\n","Train Epoch: 5 [1370/1718 (80%)]\tLoss: 0.160569\n","Train Epoch: 5 [1380/1718 (80%)]\tLoss: 0.060556\n","Train Epoch: 5 [1390/1718 (81%)]\tLoss: 0.071150\n","Train Epoch: 5 [1400/1718 (81%)]\tLoss: 0.082790\n","Train Epoch: 5 [1410/1718 (82%)]\tLoss: 0.037938\n","Train Epoch: 5 [1420/1718 (83%)]\tLoss: 0.461082\n","Train Epoch: 5 [1430/1718 (83%)]\tLoss: 1.099803\n","Train Epoch: 5 [1440/1718 (84%)]\tLoss: 0.417695\n","Train Epoch: 5 [1450/1718 (84%)]\tLoss: 0.004835\n","Train Epoch: 5 [1460/1718 (85%)]\tLoss: 0.051926\n","Train Epoch: 5 [1470/1718 (86%)]\tLoss: 0.000662\n","Train Epoch: 5 [1480/1718 (86%)]\tLoss: 0.010627\n","Train Epoch: 5 [1490/1718 (87%)]\tLoss: 0.017832\n","Train Epoch: 5 [1500/1718 (87%)]\tLoss: 0.130665\n","Train Epoch: 5 [1510/1718 (88%)]\tLoss: 0.034397\n","Train Epoch: 5 [1520/1718 (88%)]\tLoss: 0.003207\n","Train Epoch: 5 [1530/1718 (89%)]\tLoss: 0.674172\n","Train Epoch: 5 [1540/1718 (90%)]\tLoss: 0.128626\n","Train Epoch: 5 [1550/1718 (90%)]\tLoss: 0.000111\n","Train Epoch: 5 [1560/1718 (91%)]\tLoss: 0.031099\n","Train Epoch: 5 [1570/1718 (91%)]\tLoss: 0.022326\n","Train Epoch: 5 [1580/1718 (92%)]\tLoss: 0.000023\n","Train Epoch: 5 [1590/1718 (93%)]\tLoss: 0.382712\n","Train Epoch: 5 [1600/1718 (93%)]\tLoss: 0.003310\n","Train Epoch: 5 [1610/1718 (94%)]\tLoss: 0.421803\n","Train Epoch: 5 [1620/1718 (94%)]\tLoss: 0.177484\n","Train Epoch: 5 [1630/1718 (95%)]\tLoss: 0.015384\n","Train Epoch: 5 [1640/1718 (95%)]\tLoss: 0.042034\n","Train Epoch: 5 [1650/1718 (96%)]\tLoss: 0.000418\n","Train Epoch: 5 [1660/1718 (97%)]\tLoss: 0.000026\n","Train Epoch: 5 [1670/1718 (97%)]\tLoss: 0.000041\n","Train Epoch: 5 [1680/1718 (98%)]\tLoss: 1.016450\n","Train Epoch: 5 [1690/1718 (98%)]\tLoss: 0.531977\n","Train Epoch: 5 [1700/1718 (99%)]\tLoss: 0.500092\n","Train Epoch: 5 [1710/1718 (100%)]\tLoss: 0.027252\n","[tensor(183.8548, device='cuda:0'), tensor(129.5867, device='cuda:0'), tensor(42.7446, device='cuda:0'), tensor(102.3077, device='cuda:0'), tensor(41.9390, device='cuda:0')]\n","\n","Train Epoch: 6 [10/1718 (1%)]\tLoss: 0.000003\n","Train Epoch: 6 [20/1718 (1%)]\tLoss: 0.222242\n","Train Epoch: 6 [30/1718 (2%)]\tLoss: 0.092922\n","Train Epoch: 6 [40/1718 (2%)]\tLoss: 0.000088\n","Train Epoch: 6 [50/1718 (3%)]\tLoss: 0.549641\n","Train Epoch: 6 [60/1718 (3%)]\tLoss: 0.071933\n","Train Epoch: 6 [70/1718 (4%)]\tLoss: 0.007798\n","Train Epoch: 6 [80/1718 (5%)]\tLoss: 0.195470\n","Train Epoch: 6 [90/1718 (5%)]\tLoss: 2.132038\n","Train Epoch: 6 [100/1718 (6%)]\tLoss: 0.000889\n","Train Epoch: 6 [110/1718 (6%)]\tLoss: 0.000000\n","Train Epoch: 6 [120/1718 (7%)]\tLoss: 0.112391\n","Train Epoch: 6 [130/1718 (8%)]\tLoss: 0.139281\n","Train Epoch: 6 [140/1718 (8%)]\tLoss: 0.063943\n","Train Epoch: 6 [150/1718 (9%)]\tLoss: 0.077133\n","Train Epoch: 6 [160/1718 (9%)]\tLoss: 0.000016\n","Train Epoch: 6 [170/1718 (10%)]\tLoss: 0.817428\n","Train Epoch: 6 [180/1718 (10%)]\tLoss: 0.021562\n","Train Epoch: 6 [190/1718 (11%)]\tLoss: 0.097810\n","Train Epoch: 6 [200/1718 (12%)]\tLoss: 0.036549\n","Train Epoch: 6 [210/1718 (12%)]\tLoss: 0.172613\n","Train Epoch: 6 [220/1718 (13%)]\tLoss: 0.005437\n","Train Epoch: 6 [230/1718 (13%)]\tLoss: 0.143683\n","Train Epoch: 6 [240/1718 (14%)]\tLoss: 0.002887\n","Train Epoch: 6 [250/1718 (15%)]\tLoss: 0.005583\n","Train Epoch: 6 [260/1718 (15%)]\tLoss: 0.000024\n","Train Epoch: 6 [270/1718 (16%)]\tLoss: 0.259434\n","Train Epoch: 6 [280/1718 (16%)]\tLoss: 0.022741\n","Train Epoch: 6 [290/1718 (17%)]\tLoss: 0.049761\n","Train Epoch: 6 [300/1718 (17%)]\tLoss: 0.409614\n","Train Epoch: 6 [310/1718 (18%)]\tLoss: 0.000311\n","Train Epoch: 6 [320/1718 (19%)]\tLoss: 0.019584\n","Train Epoch: 6 [330/1718 (19%)]\tLoss: 0.000581\n","Train Epoch: 6 [340/1718 (20%)]\tLoss: 0.491971\n","Train Epoch: 6 [350/1718 (20%)]\tLoss: 0.017874\n","Train Epoch: 6 [360/1718 (21%)]\tLoss: 0.000000\n","Train Epoch: 6 [370/1718 (22%)]\tLoss: 0.007605\n","Train Epoch: 6 [380/1718 (22%)]\tLoss: 0.000089\n","Train Epoch: 6 [390/1718 (23%)]\tLoss: 0.000966\n","Train Epoch: 6 [400/1718 (23%)]\tLoss: 0.027436\n","Train Epoch: 6 [410/1718 (24%)]\tLoss: 1.126305\n","Train Epoch: 6 [420/1718 (24%)]\tLoss: 0.024182\n","Train Epoch: 6 [430/1718 (25%)]\tLoss: 0.633475\n","Train Epoch: 6 [440/1718 (26%)]\tLoss: 0.000077\n","Train Epoch: 6 [450/1718 (26%)]\tLoss: 0.075202\n","Train Epoch: 6 [460/1718 (27%)]\tLoss: 0.086913\n","Train Epoch: 6 [470/1718 (27%)]\tLoss: 0.000288\n","Train Epoch: 6 [480/1718 (28%)]\tLoss: 0.065930\n","Train Epoch: 6 [490/1718 (29%)]\tLoss: 0.008351\n","Train Epoch: 6 [500/1718 (29%)]\tLoss: 1.443161\n","Train Epoch: 6 [510/1718 (30%)]\tLoss: 0.000000\n","Train Epoch: 6 [520/1718 (30%)]\tLoss: 0.005342\n","Train Epoch: 6 [530/1718 (31%)]\tLoss: 0.000783\n","Train Epoch: 6 [540/1718 (31%)]\tLoss: 0.012528\n","Train Epoch: 6 [550/1718 (32%)]\tLoss: 0.006018\n","Train Epoch: 6 [560/1718 (33%)]\tLoss: 0.633227\n","Train Epoch: 6 [570/1718 (33%)]\tLoss: 0.011985\n","Train Epoch: 6 [580/1718 (34%)]\tLoss: 0.099543\n","Train Epoch: 6 [590/1718 (34%)]\tLoss: 0.006520\n","Train Epoch: 6 [600/1718 (35%)]\tLoss: 0.210658\n","Train Epoch: 6 [610/1718 (36%)]\tLoss: 1.015439\n","Train Epoch: 6 [620/1718 (36%)]\tLoss: 1.045975\n","Train Epoch: 6 [630/1718 (37%)]\tLoss: 0.015714\n","Train Epoch: 6 [640/1718 (37%)]\tLoss: 0.287890\n","Train Epoch: 6 [650/1718 (38%)]\tLoss: 0.003432\n","Train Epoch: 6 [660/1718 (38%)]\tLoss: 0.283819\n","Train Epoch: 6 [670/1718 (39%)]\tLoss: 1.332048\n","Train Epoch: 6 [680/1718 (40%)]\tLoss: 0.000197\n","Train Epoch: 6 [690/1718 (40%)]\tLoss: 0.509556\n","Train Epoch: 6 [700/1718 (41%)]\tLoss: 0.104252\n","Train Epoch: 6 [710/1718 (41%)]\tLoss: 0.000837\n","Train Epoch: 6 [720/1718 (42%)]\tLoss: 0.002012\n","Train Epoch: 6 [730/1718 (42%)]\tLoss: 0.006489\n","Train Epoch: 6 [740/1718 (43%)]\tLoss: 0.014527\n","Train Epoch: 6 [750/1718 (44%)]\tLoss: 0.000054\n","Train Epoch: 6 [760/1718 (44%)]\tLoss: 0.001687\n","Train Epoch: 6 [770/1718 (45%)]\tLoss: 0.226200\n","Train Epoch: 6 [780/1718 (45%)]\tLoss: 1.851530\n","Train Epoch: 6 [790/1718 (46%)]\tLoss: 0.004642\n","Train Epoch: 6 [800/1718 (47%)]\tLoss: 0.001721\n","Train Epoch: 6 [810/1718 (47%)]\tLoss: 0.009959\n","Train Epoch: 6 [820/1718 (48%)]\tLoss: 0.000092\n","Train Epoch: 6 [830/1718 (48%)]\tLoss: 0.065317\n","Train Epoch: 6 [840/1718 (49%)]\tLoss: 0.006494\n","Train Epoch: 6 [850/1718 (49%)]\tLoss: 0.268200\n","Train Epoch: 6 [860/1718 (50%)]\tLoss: 0.868769\n","Train Epoch: 6 [870/1718 (51%)]\tLoss: 0.007192\n","Train Epoch: 6 [880/1718 (51%)]\tLoss: 0.066638\n","Train Epoch: 6 [890/1718 (52%)]\tLoss: 0.001397\n","Train Epoch: 6 [900/1718 (52%)]\tLoss: 0.431099\n","Train Epoch: 6 [910/1718 (53%)]\tLoss: 0.000068\n","Train Epoch: 6 [920/1718 (54%)]\tLoss: 0.000468\n","Train Epoch: 6 [930/1718 (54%)]\tLoss: 0.000087\n","Train Epoch: 6 [940/1718 (55%)]\tLoss: 0.000000\n","Train Epoch: 6 [950/1718 (55%)]\tLoss: 0.145012\n","Train Epoch: 6 [960/1718 (56%)]\tLoss: 0.000035\n","Train Epoch: 6 [970/1718 (56%)]\tLoss: 0.001065\n","Train Epoch: 6 [980/1718 (57%)]\tLoss: 0.000007\n","Train Epoch: 6 [990/1718 (58%)]\tLoss: 0.000002\n","Train Epoch: 6 [1000/1718 (58%)]\tLoss: 0.000023\n","Train Epoch: 6 [1010/1718 (59%)]\tLoss: 1.206244\n","Train Epoch: 6 [1020/1718 (59%)]\tLoss: 0.387578\n","Train Epoch: 6 [1030/1718 (60%)]\tLoss: 0.403963\n","Train Epoch: 6 [1040/1718 (61%)]\tLoss: 0.000013\n","Train Epoch: 6 [1050/1718 (61%)]\tLoss: 0.122084\n","Train Epoch: 6 [1060/1718 (62%)]\tLoss: 0.238247\n","Train Epoch: 6 [1070/1718 (62%)]\tLoss: 0.000015\n","Train Epoch: 6 [1080/1718 (63%)]\tLoss: 0.101256\n","Train Epoch: 6 [1090/1718 (63%)]\tLoss: 0.101945\n","Train Epoch: 6 [1100/1718 (64%)]\tLoss: 0.001185\n","Train Epoch: 6 [1110/1718 (65%)]\tLoss: 0.003940\n","Train Epoch: 6 [1120/1718 (65%)]\tLoss: 0.123908\n","Train Epoch: 6 [1130/1718 (66%)]\tLoss: 0.001849\n","Train Epoch: 6 [1140/1718 (66%)]\tLoss: 0.000167\n","Train Epoch: 6 [1150/1718 (67%)]\tLoss: 0.001580\n","Train Epoch: 6 [1160/1718 (68%)]\tLoss: 0.195239\n","Train Epoch: 6 [1170/1718 (68%)]\tLoss: 0.005336\n","Train Epoch: 6 [1180/1718 (69%)]\tLoss: 0.739103\n","Train Epoch: 6 [1190/1718 (69%)]\tLoss: 0.000015\n","Train Epoch: 6 [1200/1718 (70%)]\tLoss: 0.000068\n","Train Epoch: 6 [1210/1718 (70%)]\tLoss: 0.109383\n","Train Epoch: 6 [1220/1718 (71%)]\tLoss: 0.000246\n","Train Epoch: 6 [1230/1718 (72%)]\tLoss: 0.000756\n","Train Epoch: 6 [1240/1718 (72%)]\tLoss: 0.000293\n","Train Epoch: 6 [1250/1718 (73%)]\tLoss: 0.000084\n","Train Epoch: 6 [1260/1718 (73%)]\tLoss: 0.000371\n","Train Epoch: 6 [1270/1718 (74%)]\tLoss: 0.005211\n","Train Epoch: 6 [1280/1718 (75%)]\tLoss: 0.010788\n","Train Epoch: 6 [1290/1718 (75%)]\tLoss: 1.185807\n","Train Epoch: 6 [1300/1718 (76%)]\tLoss: 0.015937\n","Train Epoch: 6 [1310/1718 (76%)]\tLoss: 0.000272\n","Train Epoch: 6 [1320/1718 (77%)]\tLoss: 1.779246\n","Train Epoch: 6 [1330/1718 (77%)]\tLoss: 0.012430\n","Train Epoch: 6 [1340/1718 (78%)]\tLoss: 0.000046\n","Train Epoch: 6 [1350/1718 (79%)]\tLoss: 0.003271\n","Train Epoch: 6 [1360/1718 (79%)]\tLoss: 0.000374\n","Train Epoch: 6 [1370/1718 (80%)]\tLoss: 0.000672\n","Train Epoch: 6 [1380/1718 (80%)]\tLoss: 0.005568\n","Train Epoch: 6 [1390/1718 (81%)]\tLoss: 1.372410\n","Train Epoch: 6 [1400/1718 (81%)]\tLoss: 0.001787\n","Train Epoch: 6 [1410/1718 (82%)]\tLoss: 0.085550\n","Train Epoch: 6 [1420/1718 (83%)]\tLoss: 0.000022\n","Train Epoch: 6 [1430/1718 (83%)]\tLoss: 0.303192\n","Train Epoch: 6 [1440/1718 (84%)]\tLoss: 0.000013\n","Train Epoch: 6 [1450/1718 (84%)]\tLoss: 0.000126\n","Train Epoch: 6 [1460/1718 (85%)]\tLoss: 0.003057\n","Train Epoch: 6 [1470/1718 (86%)]\tLoss: 0.037176\n","Train Epoch: 6 [1480/1718 (86%)]\tLoss: 0.291098\n","Train Epoch: 6 [1490/1718 (87%)]\tLoss: 0.100384\n","Train Epoch: 6 [1500/1718 (87%)]\tLoss: 0.001086\n","Train Epoch: 6 [1510/1718 (88%)]\tLoss: 0.107021\n","Train Epoch: 6 [1520/1718 (88%)]\tLoss: 0.009142\n","Train Epoch: 6 [1530/1718 (89%)]\tLoss: 0.000012\n","Train Epoch: 6 [1540/1718 (90%)]\tLoss: 0.003095\n","Train Epoch: 6 [1550/1718 (90%)]\tLoss: 0.001014\n","Train Epoch: 6 [1560/1718 (91%)]\tLoss: 0.546503\n","Train Epoch: 6 [1570/1718 (91%)]\tLoss: 0.001738\n","Train Epoch: 6 [1580/1718 (92%)]\tLoss: 0.014271\n","Train Epoch: 6 [1590/1718 (93%)]\tLoss: 0.490434\n","Train Epoch: 6 [1600/1718 (93%)]\tLoss: 1.079004\n","Train Epoch: 6 [1610/1718 (94%)]\tLoss: 0.001554\n","Train Epoch: 6 [1620/1718 (94%)]\tLoss: 0.606195\n","Train Epoch: 6 [1630/1718 (95%)]\tLoss: 0.258880\n","Train Epoch: 6 [1640/1718 (95%)]\tLoss: 0.294584\n","Train Epoch: 6 [1650/1718 (96%)]\tLoss: 0.103023\n","Train Epoch: 6 [1660/1718 (97%)]\tLoss: 0.000288\n","Train Epoch: 6 [1670/1718 (97%)]\tLoss: 0.000035\n","Train Epoch: 6 [1680/1718 (98%)]\tLoss: 0.760025\n","Train Epoch: 6 [1690/1718 (98%)]\tLoss: 0.128714\n","Train Epoch: 6 [1700/1718 (99%)]\tLoss: 0.000605\n","Train Epoch: 6 [1710/1718 (100%)]\tLoss: 0.029474\n","[tensor(183.8548, device='cuda:0'), tensor(129.5867, device='cuda:0'), tensor(42.7446, device='cuda:0'), tensor(102.3077, device='cuda:0'), tensor(41.9390, device='cuda:0'), tensor(76.2712, device='cuda:0')]\n","\n","Train Epoch: 7 [10/1718 (1%)]\tLoss: 0.015043\n","Train Epoch: 7 [20/1718 (1%)]\tLoss: 0.209073\n","Train Epoch: 7 [30/1718 (2%)]\tLoss: 0.182779\n","Train Epoch: 7 [40/1718 (2%)]\tLoss: 0.000000\n","Train Epoch: 7 [50/1718 (3%)]\tLoss: 0.001510\n","Train Epoch: 7 [60/1718 (3%)]\tLoss: 0.070228\n","Train Epoch: 7 [70/1718 (4%)]\tLoss: 0.002862\n","Train Epoch: 7 [80/1718 (5%)]\tLoss: 0.001381\n","Train Epoch: 7 [90/1718 (5%)]\tLoss: 0.396739\n","Train Epoch: 7 [100/1718 (6%)]\tLoss: 1.517456\n","Train Epoch: 7 [110/1718 (6%)]\tLoss: 0.102333\n","Train Epoch: 7 [120/1718 (7%)]\tLoss: 0.817231\n","Train Epoch: 7 [130/1718 (8%)]\tLoss: 0.566145\n","Train Epoch: 7 [140/1718 (8%)]\tLoss: 0.001928\n","Train Epoch: 7 [150/1718 (9%)]\tLoss: 0.047359\n","Train Epoch: 7 [160/1718 (9%)]\tLoss: 0.399197\n","Train Epoch: 7 [170/1718 (10%)]\tLoss: 0.343846\n","Train Epoch: 7 [180/1718 (10%)]\tLoss: 0.003212\n","Train Epoch: 7 [190/1718 (11%)]\tLoss: 0.001210\n","Train Epoch: 7 [200/1718 (12%)]\tLoss: 0.009413\n","Train Epoch: 7 [210/1718 (12%)]\tLoss: 0.140423\n","Train Epoch: 7 [220/1718 (13%)]\tLoss: 0.000393\n","Train Epoch: 7 [230/1718 (13%)]\tLoss: 0.197587\n","Train Epoch: 7 [240/1718 (14%)]\tLoss: 0.147777\n","Train Epoch: 7 [250/1718 (15%)]\tLoss: 0.048053\n","Train Epoch: 7 [260/1718 (15%)]\tLoss: 0.014013\n","Train Epoch: 7 [270/1718 (16%)]\tLoss: 0.441073\n","Train Epoch: 7 [280/1718 (16%)]\tLoss: 0.000017\n","Train Epoch: 7 [290/1718 (17%)]\tLoss: 0.000891\n","Train Epoch: 7 [300/1718 (17%)]\tLoss: 0.147533\n","Train Epoch: 7 [310/1718 (18%)]\tLoss: 0.389588\n","Train Epoch: 7 [320/1718 (19%)]\tLoss: 0.693743\n","Train Epoch: 7 [330/1718 (19%)]\tLoss: 0.024813\n","Train Epoch: 7 [340/1718 (20%)]\tLoss: 0.000113\n","Train Epoch: 7 [350/1718 (20%)]\tLoss: 0.708396\n","Train Epoch: 7 [360/1718 (21%)]\tLoss: 0.102197\n","Train Epoch: 7 [370/1718 (22%)]\tLoss: 0.001485\n","Train Epoch: 7 [380/1718 (22%)]\tLoss: 0.422450\n","Train Epoch: 7 [390/1718 (23%)]\tLoss: 0.262665\n","Train Epoch: 7 [400/1718 (23%)]\tLoss: 0.000129\n","Train Epoch: 7 [410/1718 (24%)]\tLoss: 0.012529\n","Train Epoch: 7 [420/1718 (24%)]\tLoss: 0.001213\n","Train Epoch: 7 [430/1718 (25%)]\tLoss: 0.891088\n","Train Epoch: 7 [440/1718 (26%)]\tLoss: 0.650680\n","Train Epoch: 7 [450/1718 (26%)]\tLoss: 0.025069\n","Train Epoch: 7 [460/1718 (27%)]\tLoss: 0.014983\n","Train Epoch: 7 [470/1718 (27%)]\tLoss: 0.925796\n","Train Epoch: 7 [480/1718 (28%)]\tLoss: 0.001978\n","Train Epoch: 7 [490/1718 (29%)]\tLoss: 0.000006\n","Train Epoch: 7 [500/1718 (29%)]\tLoss: 0.009071\n","Train Epoch: 7 [510/1718 (30%)]\tLoss: 0.003545\n","Train Epoch: 7 [520/1718 (30%)]\tLoss: 0.013904\n","Train Epoch: 7 [530/1718 (31%)]\tLoss: 0.000239\n","Train Epoch: 7 [540/1718 (31%)]\tLoss: 0.000000\n","Train Epoch: 7 [550/1718 (32%)]\tLoss: 0.201856\n","Train Epoch: 7 [560/1718 (33%)]\tLoss: 0.537266\n","Train Epoch: 7 [570/1718 (33%)]\tLoss: 0.000273\n","Train Epoch: 7 [580/1718 (34%)]\tLoss: 0.000000\n","Train Epoch: 7 [590/1718 (34%)]\tLoss: 0.067592\n","Train Epoch: 7 [600/1718 (35%)]\tLoss: 0.345128\n","Train Epoch: 7 [610/1718 (36%)]\tLoss: 0.001936\n","Train Epoch: 7 [620/1718 (36%)]\tLoss: 0.000668\n","Train Epoch: 7 [630/1718 (37%)]\tLoss: 0.000149\n","Train Epoch: 7 [640/1718 (37%)]\tLoss: 0.015448\n","Train Epoch: 7 [650/1718 (38%)]\tLoss: 0.040913\n","Train Epoch: 7 [660/1718 (38%)]\tLoss: 0.869534\n","Train Epoch: 7 [670/1718 (39%)]\tLoss: 0.180273\n","Train Epoch: 7 [680/1718 (40%)]\tLoss: 0.201121\n","Train Epoch: 7 [690/1718 (40%)]\tLoss: 0.000012\n","Train Epoch: 7 [700/1718 (41%)]\tLoss: 0.004870\n","Train Epoch: 7 [710/1718 (41%)]\tLoss: 0.000246\n","Train Epoch: 7 [720/1718 (42%)]\tLoss: 0.015660\n","Train Epoch: 7 [730/1718 (42%)]\tLoss: 0.528616\n","Train Epoch: 7 [740/1718 (43%)]\tLoss: 0.223537\n","Train Epoch: 7 [750/1718 (44%)]\tLoss: 0.004238\n","Train Epoch: 7 [760/1718 (44%)]\tLoss: 0.044797\n","Train Epoch: 7 [770/1718 (45%)]\tLoss: 0.006068\n","Train Epoch: 7 [780/1718 (45%)]\tLoss: 0.080771\n","Train Epoch: 7 [790/1718 (46%)]\tLoss: 0.000046\n","Train Epoch: 7 [800/1718 (47%)]\tLoss: 0.010530\n","Train Epoch: 7 [810/1718 (47%)]\tLoss: 0.000002\n","Train Epoch: 7 [820/1718 (48%)]\tLoss: 0.006816\n","Train Epoch: 7 [830/1718 (48%)]\tLoss: 0.007982\n","Train Epoch: 7 [840/1718 (49%)]\tLoss: 0.009636\n","Train Epoch: 7 [850/1718 (49%)]\tLoss: 0.000002\n","Train Epoch: 7 [860/1718 (50%)]\tLoss: 0.000058\n","Train Epoch: 7 [870/1718 (51%)]\tLoss: 0.000001\n","Train Epoch: 7 [880/1718 (51%)]\tLoss: 0.071377\n","Train Epoch: 7 [890/1718 (52%)]\tLoss: 0.142143\n","Train Epoch: 7 [900/1718 (52%)]\tLoss: 1.712857\n","Train Epoch: 7 [910/1718 (53%)]\tLoss: 0.211411\n","Train Epoch: 7 [920/1718 (54%)]\tLoss: 0.001545\n","Train Epoch: 7 [930/1718 (54%)]\tLoss: 0.582411\n","Train Epoch: 7 [940/1718 (55%)]\tLoss: 2.592312\n","Train Epoch: 7 [950/1718 (55%)]\tLoss: 0.000000\n","Train Epoch: 7 [960/1718 (56%)]\tLoss: 0.006927\n","Train Epoch: 7 [970/1718 (56%)]\tLoss: 0.020692\n","Train Epoch: 7 [980/1718 (57%)]\tLoss: 0.048285\n","Train Epoch: 7 [990/1718 (58%)]\tLoss: 0.027657\n","Train Epoch: 7 [1000/1718 (58%)]\tLoss: 0.010802\n","Train Epoch: 7 [1010/1718 (59%)]\tLoss: 0.002125\n","Train Epoch: 7 [1020/1718 (59%)]\tLoss: 0.015047\n","Train Epoch: 7 [1030/1718 (60%)]\tLoss: 0.004205\n","Train Epoch: 7 [1040/1718 (61%)]\tLoss: 0.065930\n","Train Epoch: 7 [1050/1718 (61%)]\tLoss: 0.016849\n","Train Epoch: 7 [1060/1718 (62%)]\tLoss: 0.307240\n","Train Epoch: 7 [1070/1718 (62%)]\tLoss: 0.011461\n","Train Epoch: 7 [1080/1718 (63%)]\tLoss: 0.054486\n","Train Epoch: 7 [1090/1718 (63%)]\tLoss: 0.000028\n","Train Epoch: 7 [1100/1718 (64%)]\tLoss: 0.002475\n","Train Epoch: 7 [1110/1718 (65%)]\tLoss: 0.002975\n","Train Epoch: 7 [1120/1718 (65%)]\tLoss: 0.000000\n","Train Epoch: 7 [1130/1718 (66%)]\tLoss: 0.002941\n","Train Epoch: 7 [1140/1718 (66%)]\tLoss: 0.115466\n","Train Epoch: 7 [1150/1718 (67%)]\tLoss: 0.927181\n","Train Epoch: 7 [1160/1718 (68%)]\tLoss: 0.001405\n","Train Epoch: 7 [1170/1718 (68%)]\tLoss: 0.553711\n","Train Epoch: 7 [1180/1718 (69%)]\tLoss: 0.000751\n","Train Epoch: 7 [1190/1718 (69%)]\tLoss: 0.004385\n","Train Epoch: 7 [1200/1718 (70%)]\tLoss: 0.000011\n","Train Epoch: 7 [1210/1718 (70%)]\tLoss: 0.000062\n","Train Epoch: 7 [1220/1718 (71%)]\tLoss: 0.000271\n","Train Epoch: 7 [1230/1718 (72%)]\tLoss: 1.115557\n","Train Epoch: 7 [1240/1718 (72%)]\tLoss: 0.366820\n","Train Epoch: 7 [1250/1718 (73%)]\tLoss: 0.035539\n","Train Epoch: 7 [1260/1718 (73%)]\tLoss: 0.174549\n","Train Epoch: 7 [1270/1718 (74%)]\tLoss: 0.000016\n","Train Epoch: 7 [1280/1718 (75%)]\tLoss: 0.859163\n","Train Epoch: 7 [1290/1718 (75%)]\tLoss: 0.000055\n","Train Epoch: 7 [1300/1718 (76%)]\tLoss: 0.000007\n","Train Epoch: 7 [1310/1718 (76%)]\tLoss: 0.004100\n","Train Epoch: 7 [1320/1718 (77%)]\tLoss: 0.014177\n","Train Epoch: 7 [1330/1718 (77%)]\tLoss: 0.000004\n","Train Epoch: 7 [1340/1718 (78%)]\tLoss: 0.850846\n","Train Epoch: 7 [1350/1718 (79%)]\tLoss: 0.182400\n","Train Epoch: 7 [1360/1718 (79%)]\tLoss: 0.880651\n","Train Epoch: 7 [1370/1718 (80%)]\tLoss: 0.018158\n","Train Epoch: 7 [1380/1718 (80%)]\tLoss: 0.000110\n","Train Epoch: 7 [1390/1718 (81%)]\tLoss: 0.000294\n","Train Epoch: 7 [1400/1718 (81%)]\tLoss: 0.000006\n","Train Epoch: 7 [1410/1718 (82%)]\tLoss: 0.001493\n","Train Epoch: 7 [1420/1718 (83%)]\tLoss: 0.020963\n","Train Epoch: 7 [1430/1718 (83%)]\tLoss: 0.000013\n","Train Epoch: 7 [1440/1718 (84%)]\tLoss: 0.022044\n","Train Epoch: 7 [1450/1718 (84%)]\tLoss: 0.302029\n","Train Epoch: 7 [1460/1718 (85%)]\tLoss: 0.000071\n","Train Epoch: 7 [1470/1718 (86%)]\tLoss: 0.057904\n","Train Epoch: 7 [1480/1718 (86%)]\tLoss: 0.000010\n","Train Epoch: 7 [1490/1718 (87%)]\tLoss: 0.000312\n","Train Epoch: 7 [1500/1718 (87%)]\tLoss: 0.004230\n","Train Epoch: 7 [1510/1718 (88%)]\tLoss: 0.042999\n","Train Epoch: 7 [1520/1718 (88%)]\tLoss: 0.003760\n","Train Epoch: 7 [1530/1718 (89%)]\tLoss: 0.185705\n","Train Epoch: 7 [1540/1718 (90%)]\tLoss: 0.000008\n","Train Epoch: 7 [1550/1718 (90%)]\tLoss: 0.000012\n","Train Epoch: 7 [1560/1718 (91%)]\tLoss: 0.118238\n","Train Epoch: 7 [1570/1718 (91%)]\tLoss: 0.000007\n","Train Epoch: 7 [1580/1718 (92%)]\tLoss: 0.175703\n","Train Epoch: 7 [1590/1718 (93%)]\tLoss: 0.285450\n","Train Epoch: 7 [1600/1718 (93%)]\tLoss: 0.009565\n","Train Epoch: 7 [1610/1718 (94%)]\tLoss: 0.167216\n","Train Epoch: 7 [1620/1718 (94%)]\tLoss: 0.691884\n","Train Epoch: 7 [1630/1718 (95%)]\tLoss: 1.308823\n","Train Epoch: 7 [1640/1718 (95%)]\tLoss: 0.078975\n","Train Epoch: 7 [1650/1718 (96%)]\tLoss: 0.001185\n","Train Epoch: 7 [1660/1718 (97%)]\tLoss: 0.006393\n","Train Epoch: 7 [1670/1718 (97%)]\tLoss: 0.211337\n","Train Epoch: 7 [1680/1718 (98%)]\tLoss: 0.001899\n","Train Epoch: 7 [1690/1718 (98%)]\tLoss: 0.445189\n","Train Epoch: 7 [1700/1718 (99%)]\tLoss: 0.000369\n","Train Epoch: 7 [1710/1718 (100%)]\tLoss: 0.000018\n","[tensor(183.8548, device='cuda:0'), tensor(129.5867, device='cuda:0'), tensor(42.7446, device='cuda:0'), tensor(102.3077, device='cuda:0'), tensor(41.9390, device='cuda:0'), tensor(76.2712, device='cuda:0'), tensor(69.3225, device='cuda:0')]\n","\n","Train Epoch: 8 [10/1718 (1%)]\tLoss: 0.084453\n","Train Epoch: 8 [20/1718 (1%)]\tLoss: 0.159667\n","Train Epoch: 8 [30/1718 (2%)]\tLoss: 0.002220\n","Train Epoch: 8 [40/1718 (2%)]\tLoss: 0.545101\n","Train Epoch: 8 [50/1718 (3%)]\tLoss: 0.131908\n","Train Epoch: 8 [60/1718 (3%)]\tLoss: 0.032344\n","Train Epoch: 8 [70/1718 (4%)]\tLoss: 1.171954\n","Train Epoch: 8 [80/1718 (5%)]\tLoss: 0.000000\n","Train Epoch: 8 [90/1718 (5%)]\tLoss: 0.000149\n","Train Epoch: 8 [100/1718 (6%)]\tLoss: 0.000030\n","Train Epoch: 8 [110/1718 (6%)]\tLoss: 0.000075\n","Train Epoch: 8 [120/1718 (7%)]\tLoss: 0.003029\n","Train Epoch: 8 [130/1718 (8%)]\tLoss: 0.255892\n","Train Epoch: 8 [140/1718 (8%)]\tLoss: 0.005964\n","Train Epoch: 8 [150/1718 (9%)]\tLoss: 0.231046\n","Train Epoch: 8 [160/1718 (9%)]\tLoss: 0.055197\n","Train Epoch: 8 [170/1718 (10%)]\tLoss: 0.461374\n","Train Epoch: 8 [180/1718 (10%)]\tLoss: 0.153877\n","Train Epoch: 8 [190/1718 (11%)]\tLoss: 0.000027\n","Train Epoch: 8 [200/1718 (12%)]\tLoss: 0.412232\n","Train Epoch: 8 [210/1718 (12%)]\tLoss: 0.000297\n","Train Epoch: 8 [220/1718 (13%)]\tLoss: 0.000002\n","Train Epoch: 8 [230/1718 (13%)]\tLoss: 1.067090\n","Train Epoch: 8 [240/1718 (14%)]\tLoss: 0.000802\n","Train Epoch: 8 [250/1718 (15%)]\tLoss: 0.005599\n","Train Epoch: 8 [260/1718 (15%)]\tLoss: 0.113509\n","Train Epoch: 8 [270/1718 (16%)]\tLoss: 0.195907\n","Train Epoch: 8 [280/1718 (16%)]\tLoss: 0.192001\n","Train Epoch: 8 [290/1718 (17%)]\tLoss: 0.000029\n","Train Epoch: 8 [300/1718 (17%)]\tLoss: 0.128573\n","Train Epoch: 8 [310/1718 (18%)]\tLoss: 0.113854\n","Train Epoch: 8 [320/1718 (19%)]\tLoss: 0.000365\n","Train Epoch: 8 [330/1718 (19%)]\tLoss: 0.000689\n","Train Epoch: 8 [340/1718 (20%)]\tLoss: 0.005543\n","Train Epoch: 8 [350/1718 (20%)]\tLoss: 0.061462\n","Train Epoch: 8 [360/1718 (21%)]\tLoss: 1.065487\n","Train Epoch: 8 [370/1718 (22%)]\tLoss: 0.564892\n","Train Epoch: 8 [380/1718 (22%)]\tLoss: 0.077746\n","Train Epoch: 8 [390/1718 (23%)]\tLoss: 0.016614\n","Train Epoch: 8 [400/1718 (23%)]\tLoss: 0.000219\n","Train Epoch: 8 [410/1718 (24%)]\tLoss: 0.020651\n","Train Epoch: 8 [420/1718 (24%)]\tLoss: 0.000127\n","Train Epoch: 8 [430/1718 (25%)]\tLoss: 0.014853\n","Train Epoch: 8 [440/1718 (26%)]\tLoss: 0.940568\n","Train Epoch: 8 [450/1718 (26%)]\tLoss: 0.000001\n","Train Epoch: 8 [460/1718 (27%)]\tLoss: 0.030590\n","Train Epoch: 8 [470/1718 (27%)]\tLoss: 0.006919\n","Train Epoch: 8 [480/1718 (28%)]\tLoss: 0.002183\n","Train Epoch: 8 [490/1718 (29%)]\tLoss: 0.000730\n","Train Epoch: 8 [500/1718 (29%)]\tLoss: 0.000014\n","Train Epoch: 8 [510/1718 (30%)]\tLoss: 0.369582\n","Train Epoch: 8 [520/1718 (30%)]\tLoss: 0.000001\n","Train Epoch: 8 [530/1718 (31%)]\tLoss: 0.391463\n","Train Epoch: 8 [540/1718 (31%)]\tLoss: 0.005924\n","Train Epoch: 8 [550/1718 (32%)]\tLoss: 0.156699\n","Train Epoch: 8 [560/1718 (33%)]\tLoss: 0.003380\n","Train Epoch: 8 [570/1718 (33%)]\tLoss: 0.000335\n","Train Epoch: 8 [580/1718 (34%)]\tLoss: 0.364176\n","Train Epoch: 8 [590/1718 (34%)]\tLoss: 0.190451\n","Train Epoch: 8 [600/1718 (35%)]\tLoss: 0.009893\n","Train Epoch: 8 [610/1718 (36%)]\tLoss: 0.139562\n","Train Epoch: 8 [620/1718 (36%)]\tLoss: 0.001724\n","Train Epoch: 8 [630/1718 (37%)]\tLoss: 0.010115\n","Train Epoch: 8 [640/1718 (37%)]\tLoss: 0.000827\n","Train Epoch: 8 [650/1718 (38%)]\tLoss: 0.000000\n","Train Epoch: 8 [660/1718 (38%)]\tLoss: 0.000057\n","Train Epoch: 8 [670/1718 (39%)]\tLoss: 0.000010\n","Train Epoch: 8 [680/1718 (40%)]\tLoss: 0.001731\n","Train Epoch: 8 [690/1718 (40%)]\tLoss: 0.755720\n","Train Epoch: 8 [700/1718 (41%)]\tLoss: 0.001274\n","Train Epoch: 8 [710/1718 (41%)]\tLoss: 0.000001\n","Train Epoch: 8 [720/1718 (42%)]\tLoss: 0.000264\n","Train Epoch: 8 [730/1718 (42%)]\tLoss: 0.086070\n","Train Epoch: 8 [740/1718 (43%)]\tLoss: 0.010964\n","Train Epoch: 8 [750/1718 (44%)]\tLoss: 0.296684\n","Train Epoch: 8 [760/1718 (44%)]\tLoss: 0.524814\n","Train Epoch: 8 [770/1718 (45%)]\tLoss: 0.000032\n","Train Epoch: 8 [780/1718 (45%)]\tLoss: 0.000386\n","Train Epoch: 8 [790/1718 (46%)]\tLoss: 0.000356\n","Train Epoch: 8 [800/1718 (47%)]\tLoss: 0.943237\n","Train Epoch: 8 [810/1718 (47%)]\tLoss: 0.003320\n","Train Epoch: 8 [820/1718 (48%)]\tLoss: 0.000035\n","Train Epoch: 8 [830/1718 (48%)]\tLoss: 0.000483\n","Train Epoch: 8 [840/1718 (49%)]\tLoss: 0.000020\n","Train Epoch: 8 [850/1718 (49%)]\tLoss: 0.849153\n","Train Epoch: 8 [860/1718 (50%)]\tLoss: 1.258391\n","Train Epoch: 8 [870/1718 (51%)]\tLoss: 0.006571\n","Train Epoch: 8 [880/1718 (51%)]\tLoss: 0.003495\n","Train Epoch: 8 [890/1718 (52%)]\tLoss: 0.030958\n","Train Epoch: 8 [900/1718 (52%)]\tLoss: 0.459842\n","Train Epoch: 8 [910/1718 (53%)]\tLoss: 0.000799\n","Train Epoch: 8 [920/1718 (54%)]\tLoss: 1.153574\n","Train Epoch: 8 [930/1718 (54%)]\tLoss: 0.000118\n","Train Epoch: 8 [940/1718 (55%)]\tLoss: 0.006718\n","Train Epoch: 8 [950/1718 (55%)]\tLoss: 0.000000\n","Train Epoch: 8 [960/1718 (56%)]\tLoss: 0.001590\n","Train Epoch: 8 [970/1718 (56%)]\tLoss: 0.033660\n","Train Epoch: 8 [980/1718 (57%)]\tLoss: 0.013081\n","Train Epoch: 8 [990/1718 (58%)]\tLoss: 1.360355\n","Train Epoch: 8 [1000/1718 (58%)]\tLoss: 0.000000\n","Train Epoch: 8 [1010/1718 (59%)]\tLoss: 0.000005\n","Train Epoch: 8 [1020/1718 (59%)]\tLoss: 1.580017\n","Train Epoch: 8 [1030/1718 (60%)]\tLoss: 0.001852\n","Train Epoch: 8 [1040/1718 (61%)]\tLoss: 0.009678\n","Train Epoch: 8 [1050/1718 (61%)]\tLoss: 0.009368\n","Train Epoch: 8 [1060/1718 (62%)]\tLoss: 0.000446\n","Train Epoch: 8 [1070/1718 (62%)]\tLoss: 0.000128\n","Train Epoch: 8 [1080/1718 (63%)]\tLoss: 0.197451\n","Train Epoch: 8 [1090/1718 (63%)]\tLoss: 0.141632\n","Train Epoch: 8 [1100/1718 (64%)]\tLoss: 0.043908\n","Train Epoch: 8 [1110/1718 (65%)]\tLoss: 0.380947\n","Train Epoch: 8 [1120/1718 (65%)]\tLoss: 0.000236\n","Train Epoch: 8 [1130/1718 (66%)]\tLoss: 0.000778\n","Train Epoch: 8 [1140/1718 (66%)]\tLoss: 0.530810\n","Train Epoch: 8 [1150/1718 (67%)]\tLoss: 0.000007\n","Train Epoch: 8 [1160/1718 (68%)]\tLoss: 0.051397\n","Train Epoch: 8 [1170/1718 (68%)]\tLoss: 0.000112\n","Train Epoch: 8 [1180/1718 (69%)]\tLoss: 0.004569\n","Train Epoch: 8 [1190/1718 (69%)]\tLoss: 0.040991\n","Train Epoch: 8 [1200/1718 (70%)]\tLoss: 0.000176\n","Train Epoch: 8 [1210/1718 (70%)]\tLoss: 0.001990\n","Train Epoch: 8 [1220/1718 (71%)]\tLoss: 0.022291\n","Train Epoch: 8 [1230/1718 (72%)]\tLoss: 0.024432\n","Train Epoch: 8 [1240/1718 (72%)]\tLoss: 0.000122\n","Train Epoch: 8 [1250/1718 (73%)]\tLoss: 0.001839\n","Train Epoch: 8 [1260/1718 (73%)]\tLoss: 0.815408\n","Train Epoch: 8 [1270/1718 (74%)]\tLoss: 0.000102\n","Train Epoch: 8 [1280/1718 (75%)]\tLoss: 0.160112\n","Train Epoch: 8 [1290/1718 (75%)]\tLoss: 0.000335\n","Train Epoch: 8 [1300/1718 (76%)]\tLoss: 0.894226\n","Train Epoch: 8 [1310/1718 (76%)]\tLoss: 0.000020\n","Train Epoch: 8 [1320/1718 (77%)]\tLoss: 0.000444\n","Train Epoch: 8 [1330/1718 (77%)]\tLoss: 1.670431\n","Train Epoch: 8 [1340/1718 (78%)]\tLoss: 0.004216\n","Train Epoch: 8 [1350/1718 (79%)]\tLoss: 0.000006\n","Train Epoch: 8 [1360/1718 (79%)]\tLoss: 0.008894\n","Train Epoch: 8 [1370/1718 (80%)]\tLoss: 0.000933\n","Train Epoch: 8 [1380/1718 (80%)]\tLoss: 0.000000\n","Train Epoch: 8 [1390/1718 (81%)]\tLoss: 0.624898\n","Train Epoch: 8 [1400/1718 (81%)]\tLoss: 0.111438\n","Train Epoch: 8 [1410/1718 (82%)]\tLoss: 1.028060\n","Train Epoch: 8 [1420/1718 (83%)]\tLoss: 0.000252\n","Train Epoch: 8 [1430/1718 (83%)]\tLoss: 0.000162\n","Train Epoch: 8 [1440/1718 (84%)]\tLoss: 0.000115\n","Train Epoch: 8 [1450/1718 (84%)]\tLoss: 0.524348\n","Train Epoch: 8 [1460/1718 (85%)]\tLoss: 0.000058\n","Train Epoch: 8 [1470/1718 (86%)]\tLoss: 0.000001\n","Train Epoch: 8 [1480/1718 (86%)]\tLoss: 0.744971\n","Train Epoch: 8 [1490/1718 (87%)]\tLoss: 0.414882\n","Train Epoch: 8 [1500/1718 (87%)]\tLoss: 0.100665\n","Train Epoch: 8 [1510/1718 (88%)]\tLoss: 0.469311\n","Train Epoch: 8 [1520/1718 (88%)]\tLoss: 0.036019\n","Train Epoch: 8 [1530/1718 (89%)]\tLoss: 0.002916\n","Train Epoch: 8 [1540/1718 (90%)]\tLoss: 0.000124\n","Train Epoch: 8 [1550/1718 (90%)]\tLoss: 0.000001\n","Train Epoch: 8 [1560/1718 (91%)]\tLoss: 0.000216\n","Train Epoch: 8 [1570/1718 (91%)]\tLoss: 0.047133\n","Train Epoch: 8 [1580/1718 (92%)]\tLoss: 0.001223\n","Train Epoch: 8 [1590/1718 (93%)]\tLoss: 0.002030\n","Train Epoch: 8 [1600/1718 (93%)]\tLoss: 0.000495\n","Train Epoch: 8 [1610/1718 (94%)]\tLoss: 0.010103\n","Train Epoch: 8 [1620/1718 (94%)]\tLoss: 0.000016\n","Train Epoch: 8 [1630/1718 (95%)]\tLoss: 0.479948\n","Train Epoch: 8 [1640/1718 (95%)]\tLoss: 0.000001\n","Train Epoch: 8 [1650/1718 (96%)]\tLoss: 0.113824\n","Train Epoch: 8 [1660/1718 (97%)]\tLoss: 0.054445\n","Train Epoch: 8 [1670/1718 (97%)]\tLoss: 0.021319\n","Train Epoch: 8 [1680/1718 (98%)]\tLoss: 0.017260\n","Train Epoch: 8 [1690/1718 (98%)]\tLoss: 0.000000\n","Train Epoch: 8 [1700/1718 (99%)]\tLoss: 0.002357\n","Train Epoch: 8 [1710/1718 (100%)]\tLoss: 0.007065\n","[tensor(183.8548, device='cuda:0'), tensor(129.5867, device='cuda:0'), tensor(42.7446, device='cuda:0'), tensor(102.3077, device='cuda:0'), tensor(41.9390, device='cuda:0'), tensor(76.2712, device='cuda:0'), tensor(69.3225, device='cuda:0'), tensor(80.6471, device='cuda:0')]\n","\n","Train Epoch: 9 [10/1718 (1%)]\tLoss: 0.000000\n","Train Epoch: 9 [20/1718 (1%)]\tLoss: 0.771364\n","Train Epoch: 9 [30/1718 (2%)]\tLoss: 0.178313\n","Train Epoch: 9 [40/1718 (2%)]\tLoss: 0.918044\n","Train Epoch: 9 [50/1718 (3%)]\tLoss: 0.000006\n","Train Epoch: 9 [60/1718 (3%)]\tLoss: 0.351104\n","Train Epoch: 9 [70/1718 (4%)]\tLoss: 0.222895\n","Train Epoch: 9 [80/1718 (5%)]\tLoss: 0.322976\n","Train Epoch: 9 [90/1718 (5%)]\tLoss: 0.743096\n","Train Epoch: 9 [100/1718 (6%)]\tLoss: 0.000000\n","Train Epoch: 9 [110/1718 (6%)]\tLoss: 0.704778\n","Train Epoch: 9 [120/1718 (7%)]\tLoss: 0.000001\n","Train Epoch: 9 [130/1718 (8%)]\tLoss: 0.707022\n","Train Epoch: 9 [140/1718 (8%)]\tLoss: 0.000000\n","Train Epoch: 9 [150/1718 (9%)]\tLoss: 0.000323\n","Train Epoch: 9 [160/1718 (9%)]\tLoss: 0.051061\n","Train Epoch: 9 [170/1718 (10%)]\tLoss: 0.026954\n","Train Epoch: 9 [180/1718 (10%)]\tLoss: 0.743973\n","Train Epoch: 9 [190/1718 (11%)]\tLoss: 0.000005\n","Train Epoch: 9 [200/1718 (12%)]\tLoss: 0.000253\n","Train Epoch: 9 [210/1718 (12%)]\tLoss: 0.199272\n","Train Epoch: 9 [220/1718 (13%)]\tLoss: 0.155282\n","Train Epoch: 9 [230/1718 (13%)]\tLoss: 0.023357\n","Train Epoch: 9 [240/1718 (14%)]\tLoss: 0.069067\n","Train Epoch: 9 [250/1718 (15%)]\tLoss: 0.058949\n","Train Epoch: 9 [260/1718 (15%)]\tLoss: 0.000604\n","Train Epoch: 9 [270/1718 (16%)]\tLoss: 0.054494\n","Train Epoch: 9 [280/1718 (16%)]\tLoss: 0.179775\n","Train Epoch: 9 [290/1718 (17%)]\tLoss: 0.000711\n","Train Epoch: 9 [300/1718 (17%)]\tLoss: 0.001139\n","Train Epoch: 9 [310/1718 (18%)]\tLoss: 0.007780\n","Train Epoch: 9 [320/1718 (19%)]\tLoss: 0.000011\n","Train Epoch: 9 [330/1718 (19%)]\tLoss: 0.002495\n","Train Epoch: 9 [340/1718 (20%)]\tLoss: 0.000208\n","Train Epoch: 9 [350/1718 (20%)]\tLoss: 0.001082\n","Train Epoch: 9 [360/1718 (21%)]\tLoss: 0.014834\n","Train Epoch: 9 [370/1718 (22%)]\tLoss: 0.146751\n","Train Epoch: 9 [380/1718 (22%)]\tLoss: 0.000000\n","Train Epoch: 9 [390/1718 (23%)]\tLoss: 0.000162\n","Train Epoch: 9 [400/1718 (23%)]\tLoss: 0.000082\n","Train Epoch: 9 [410/1718 (24%)]\tLoss: 0.256132\n","Train Epoch: 9 [420/1718 (24%)]\tLoss: 0.011408\n","Train Epoch: 9 [430/1718 (25%)]\tLoss: 0.027467\n","Train Epoch: 9 [440/1718 (26%)]\tLoss: 0.012212\n","Train Epoch: 9 [450/1718 (26%)]\tLoss: 0.019290\n","Train Epoch: 9 [460/1718 (27%)]\tLoss: 0.000000\n","Train Epoch: 9 [470/1718 (27%)]\tLoss: 0.011178\n","Train Epoch: 9 [480/1718 (28%)]\tLoss: 0.002733\n","Train Epoch: 9 [490/1718 (29%)]\tLoss: 0.823677\n","Train Epoch: 9 [500/1718 (29%)]\tLoss: 0.005658\n","Train Epoch: 9 [510/1718 (30%)]\tLoss: 0.162275\n","Train Epoch: 9 [520/1718 (30%)]\tLoss: 0.371684\n","Train Epoch: 9 [530/1718 (31%)]\tLoss: 0.096861\n","Train Epoch: 9 [540/1718 (31%)]\tLoss: 0.665075\n","Train Epoch: 9 [550/1718 (32%)]\tLoss: 0.000926\n","Train Epoch: 9 [560/1718 (33%)]\tLoss: 0.000527\n","Train Epoch: 9 [570/1718 (33%)]\tLoss: 0.000132\n","Train Epoch: 9 [580/1718 (34%)]\tLoss: 0.001739\n","Train Epoch: 9 [590/1718 (34%)]\tLoss: 0.000001\n","Train Epoch: 9 [600/1718 (35%)]\tLoss: 0.000000\n","Train Epoch: 9 [610/1718 (36%)]\tLoss: 0.012279\n","Train Epoch: 9 [620/1718 (36%)]\tLoss: 0.800354\n","Train Epoch: 9 [630/1718 (37%)]\tLoss: 0.051484\n","Train Epoch: 9 [640/1718 (37%)]\tLoss: 0.006185\n","Train Epoch: 9 [650/1718 (38%)]\tLoss: 0.003320\n","Train Epoch: 9 [660/1718 (38%)]\tLoss: 0.059585\n","Train Epoch: 9 [670/1718 (39%)]\tLoss: 0.043128\n","Train Epoch: 9 [680/1718 (40%)]\tLoss: 0.131509\n","Train Epoch: 9 [690/1718 (40%)]\tLoss: 0.060856\n","Train Epoch: 9 [700/1718 (41%)]\tLoss: 0.032501\n","Train Epoch: 9 [710/1718 (41%)]\tLoss: 0.009620\n","Train Epoch: 9 [720/1718 (42%)]\tLoss: 0.004989\n","Train Epoch: 9 [730/1718 (42%)]\tLoss: 0.000728\n","Train Epoch: 9 [740/1718 (43%)]\tLoss: 0.862428\n","Train Epoch: 9 [750/1718 (44%)]\tLoss: 0.000011\n","Train Epoch: 9 [760/1718 (44%)]\tLoss: 0.000011\n","Train Epoch: 9 [770/1718 (45%)]\tLoss: 0.001133\n","Train Epoch: 9 [780/1718 (45%)]\tLoss: 0.020031\n","Train Epoch: 9 [790/1718 (46%)]\tLoss: 0.596470\n","Train Epoch: 9 [800/1718 (47%)]\tLoss: 0.000003\n","Train Epoch: 9 [810/1718 (47%)]\tLoss: 0.003769\n","Train Epoch: 9 [820/1718 (48%)]\tLoss: 0.125305\n","Train Epoch: 9 [830/1718 (48%)]\tLoss: 0.008858\n","Train Epoch: 9 [840/1718 (49%)]\tLoss: 0.003077\n","Train Epoch: 9 [850/1718 (49%)]\tLoss: 0.058482\n","Train Epoch: 9 [860/1718 (50%)]\tLoss: 0.055315\n","Train Epoch: 9 [870/1718 (51%)]\tLoss: 0.000119\n","Train Epoch: 9 [880/1718 (51%)]\tLoss: 0.002119\n","Train Epoch: 9 [890/1718 (52%)]\tLoss: 0.000359\n","Train Epoch: 9 [900/1718 (52%)]\tLoss: 0.156615\n","Train Epoch: 9 [910/1718 (53%)]\tLoss: 0.123636\n","Train Epoch: 9 [920/1718 (54%)]\tLoss: 0.000028\n","Train Epoch: 9 [930/1718 (54%)]\tLoss: 0.014982\n","Train Epoch: 9 [940/1718 (55%)]\tLoss: 0.000002\n","Train Epoch: 9 [950/1718 (55%)]\tLoss: 0.000061\n","Train Epoch: 9 [960/1718 (56%)]\tLoss: 0.007806\n","Train Epoch: 9 [970/1718 (56%)]\tLoss: 0.009780\n","Train Epoch: 9 [980/1718 (57%)]\tLoss: 0.018344\n","Train Epoch: 9 [990/1718 (58%)]\tLoss: 0.018913\n","Train Epoch: 9 [1000/1718 (58%)]\tLoss: 0.014943\n","Train Epoch: 9 [1010/1718 (59%)]\tLoss: 0.331868\n","Train Epoch: 9 [1020/1718 (59%)]\tLoss: 0.045315\n","Train Epoch: 9 [1030/1718 (60%)]\tLoss: 0.465904\n","Train Epoch: 9 [1040/1718 (61%)]\tLoss: 0.000000\n","Train Epoch: 9 [1050/1718 (61%)]\tLoss: 0.218719\n","Train Epoch: 9 [1060/1718 (62%)]\tLoss: 0.336988\n","Train Epoch: 9 [1070/1718 (62%)]\tLoss: 0.000137\n","Train Epoch: 9 [1080/1718 (63%)]\tLoss: 0.001458\n","Train Epoch: 9 [1090/1718 (63%)]\tLoss: 0.519250\n","Train Epoch: 9 [1100/1718 (64%)]\tLoss: 0.043242\n","Train Epoch: 9 [1110/1718 (65%)]\tLoss: 0.231866\n","Train Epoch: 9 [1120/1718 (65%)]\tLoss: 0.004606\n","Train Epoch: 9 [1130/1718 (66%)]\tLoss: 0.073806\n","Train Epoch: 9 [1140/1718 (66%)]\tLoss: 0.002535\n","Train Epoch: 9 [1150/1718 (67%)]\tLoss: 0.568865\n","Train Epoch: 9 [1160/1718 (68%)]\tLoss: 0.000101\n","Train Epoch: 9 [1170/1718 (68%)]\tLoss: 0.000183\n","Train Epoch: 9 [1180/1718 (69%)]\tLoss: 0.000135\n","Train Epoch: 9 [1190/1718 (69%)]\tLoss: 0.397073\n","Train Epoch: 9 [1200/1718 (70%)]\tLoss: 0.000360\n","Train Epoch: 9 [1210/1718 (70%)]\tLoss: 0.059857\n","Train Epoch: 9 [1220/1718 (71%)]\tLoss: 0.000135\n","Train Epoch: 9 [1230/1718 (72%)]\tLoss: 0.001222\n","Train Epoch: 9 [1240/1718 (72%)]\tLoss: 0.000003\n","Train Epoch: 9 [1250/1718 (73%)]\tLoss: 0.218447\n","Train Epoch: 9 [1260/1718 (73%)]\tLoss: 0.000155\n","Train Epoch: 9 [1270/1718 (74%)]\tLoss: 0.000000\n","Train Epoch: 9 [1280/1718 (75%)]\tLoss: 0.000028\n","Train Epoch: 9 [1290/1718 (75%)]\tLoss: 0.017663\n","Train Epoch: 9 [1300/1718 (76%)]\tLoss: 0.589620\n","Train Epoch: 9 [1310/1718 (76%)]\tLoss: 0.326372\n","Train Epoch: 9 [1320/1718 (77%)]\tLoss: 0.002002\n","Train Epoch: 9 [1330/1718 (77%)]\tLoss: 0.000015\n","Train Epoch: 9 [1340/1718 (78%)]\tLoss: 0.005243\n","Train Epoch: 9 [1350/1718 (79%)]\tLoss: 0.000028\n","Train Epoch: 9 [1360/1718 (79%)]\tLoss: 0.000001\n","Train Epoch: 9 [1370/1718 (80%)]\tLoss: 0.347236\n","Train Epoch: 9 [1380/1718 (80%)]\tLoss: 0.000261\n","Train Epoch: 9 [1390/1718 (81%)]\tLoss: 4.851526\n","Train Epoch: 9 [1400/1718 (81%)]\tLoss: 0.486451\n","Train Epoch: 9 [1410/1718 (82%)]\tLoss: 0.609796\n","Train Epoch: 9 [1420/1718 (83%)]\tLoss: 0.000315\n","Train Epoch: 9 [1430/1718 (83%)]\tLoss: 0.002878\n","Train Epoch: 9 [1440/1718 (84%)]\tLoss: 0.159979\n","Train Epoch: 9 [1450/1718 (84%)]\tLoss: 1.423070\n","Train Epoch: 9 [1460/1718 (85%)]\tLoss: 0.046563\n","Train Epoch: 9 [1470/1718 (86%)]\tLoss: 0.000083\n","Train Epoch: 9 [1480/1718 (86%)]\tLoss: 0.381372\n","Train Epoch: 9 [1490/1718 (87%)]\tLoss: 0.000046\n","Train Epoch: 9 [1500/1718 (87%)]\tLoss: 0.001696\n","Train Epoch: 9 [1510/1718 (88%)]\tLoss: 0.058699\n","Train Epoch: 9 [1520/1718 (88%)]\tLoss: 0.100976\n","Train Epoch: 9 [1530/1718 (89%)]\tLoss: 0.043103\n","Train Epoch: 9 [1540/1718 (90%)]\tLoss: 0.000008\n","Train Epoch: 9 [1550/1718 (90%)]\tLoss: 0.000608\n","Train Epoch: 9 [1560/1718 (91%)]\tLoss: 0.118634\n","Train Epoch: 9 [1570/1718 (91%)]\tLoss: 0.061390\n","Train Epoch: 9 [1580/1718 (92%)]\tLoss: 0.004478\n","Train Epoch: 9 [1590/1718 (93%)]\tLoss: 0.033060\n","Train Epoch: 9 [1600/1718 (93%)]\tLoss: 0.011834\n","Train Epoch: 9 [1610/1718 (94%)]\tLoss: 0.001383\n","Train Epoch: 9 [1620/1718 (94%)]\tLoss: 1.038637\n","Train Epoch: 9 [1630/1718 (95%)]\tLoss: 0.001333\n","Train Epoch: 9 [1640/1718 (95%)]\tLoss: 0.026733\n","Train Epoch: 9 [1650/1718 (96%)]\tLoss: 0.000001\n","Train Epoch: 9 [1660/1718 (97%)]\tLoss: 0.233013\n","Train Epoch: 9 [1670/1718 (97%)]\tLoss: 0.000776\n","Train Epoch: 9 [1680/1718 (98%)]\tLoss: 0.925173\n","Train Epoch: 9 [1690/1718 (98%)]\tLoss: 1.144198\n","Train Epoch: 9 [1700/1718 (99%)]\tLoss: 0.957860\n","Train Epoch: 9 [1710/1718 (100%)]\tLoss: 0.000010\n","[tensor(183.8548, device='cuda:0'), tensor(129.5867, device='cuda:0'), tensor(42.7446, device='cuda:0'), tensor(102.3077, device='cuda:0'), tensor(41.9390, device='cuda:0'), tensor(76.2712, device='cuda:0'), tensor(69.3225, device='cuda:0'), tensor(80.6471, device='cuda:0'), tensor(33.6152, device='cuda:0')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZaAB9em46bun","executionInfo":{"status":"ok","timestamp":1621134929428,"user_tz":-60,"elapsed":38904,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"bc170c75-fbc7-40e7-b9fd-55473b0a17a5"},"source":["evaluate(model, test_dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Acc 0.795\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.7949251247920133"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fhmr54uwK2XA","executionInfo":{"status":"ok","timestamp":1621134931717,"user_tz":-60,"elapsed":666,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"33de7261-c33c-43d6-d07c-a01d6844651a"},"source":["precisions_difference"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor(183.8548, device='cuda:0'),\n"," tensor(129.5867, device='cuda:0'),\n"," tensor(42.7446, device='cuda:0'),\n"," tensor(102.3077, device='cuda:0'),\n"," tensor(41.9390, device='cuda:0'),\n"," tensor(76.2712, device='cuda:0'),\n"," tensor(69.3225, device='cuda:0'),\n"," tensor(80.6471, device='cuda:0'),\n"," tensor(33.6152, device='cuda:0')]"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"TcPV7oUvDIBn"},"source":["precs_roberta_original = optimizer_vadam_last_layer.get_weight_precs()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DOnJ3oVQLfJE","executionInfo":{"status":"ok","timestamp":1621135066684,"user_tz":-60,"elapsed":662,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"77c2e6cb-2947-4bcb-9e79-8d6b28a222da"},"source":["precs_roberta_original"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[tensor([[11.6384, 13.8135, 11.2259,  ..., 12.6498, 12.0761, 13.9614]],\n","         device='cuda:0'), tensor([1.], device='cuda:0')]]"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"RpdpuqiH5EHJ"},"source":["std_weights = torch.sqrt(1./precs_roberta_original[0][0][0])\n","std_bias = torch.sqrt(1./precs_roberta_original[0][1][0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUaINn50Ddw7"},"source":["#Save models\n","#f = open(\"variational_training_original_roberta.pkl\",\"wb\")\n","#pickle.dump(model,f)\n","#f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1YOuMK8uDhmG"},"source":["#Save precisions\n","#f = open(\"precisions_weights_biases_original_roberta.pkl\",\"wb\")\n","#pickle.dump(precs_roberta_original,f)\n","#f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ts38mkk55Vmy"},"source":["Once the model has been trained, to make predictions we sample from the posterior weights, do the predictions for each of these samples, and average the results."]},{"cell_type":"code","metadata":{"id":"z96Wkyx0AtXP"},"source":["results_roberta = variational_inference_uncertainties_roberta(model, std_weights, std_bias, test_dataloader, mc_samples = 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0oEm9MSbAtXQ"},"source":["results_roberta_hard = variational_inference_uncertainties_roberta(model, std_weights, std_bias, hard_test_dataloader, mc_samples = 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"ovW55x6HAtXR","executionInfo":{"status":"ok","timestamp":1622247833678,"user_tz":-60,"elapsed":1307,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"0d0b59e3-ba72-4da6-9f60-98dcc69d54f4"},"source":["conf, acc, bins, num_in_bins = split_in_bins(results_roberta['predictions'], results_roberta['confidence'])\n","conf_hard, acc_hard, bins_hard, num_in_bins_hard = split_in_bins(results_roberta_hard['predictions'], results_roberta_hard['confidence'])\n","ece_easy = get_ECE(conf, acc, num_in_bins)\n","print(f\"ECE easy test dataset: {ece_easy}\")\n","ece_hard = get_ECE(conf_hard, acc_hard, num_in_bins_hard)\n","print(f\"ECE hard test dataset: {ece_hard}\")\n","plot_reliability_diagram_original(acc, bins, acc_hard, bins_hard, \"vadam_roberta_original\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x360 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"padqruPYCNjo"},"source":["accuracy = np.mean(results_roberta['predictions'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FRsz-g0qtrBz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621491096410,"user_tz":-60,"elapsed":443,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"52f54351-3861-4f8c-8903-537837d96e99"},"source":["accuracy"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7945091514143094"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"S4wkyzVIUxTx"},"source":["accuracy_hard = np.mean(results_roberta_hard['predictions'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVFpy-d_UxT3","executionInfo":{"status":"ok","timestamp":1621491098728,"user_tz":-60,"elapsed":308,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"ee2b1e87-1bc4-4218-c10e-85753b98069f"},"source":["accuracy_hard"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6303838951310862"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"rFGC4jq8Bg23"},"source":["# Vadam: Approximating the posterior of the final layer after converging to a local optima in the reformulated dataset"]},{"cell_type":"markdown","metadata":{"id":"d6hLuqF55ZDS"},"source":["We now do the sam as above but for a RoBERTa model that has been trained in the reformulated dataset"]},{"cell_type":"code","metadata":{"id":"UgdsUkINH5JV"},"source":["args = MyArgs()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rqKN4XEhOPbC"},"source":["args = MyArgs(model='roberta-large', ngpus=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oaq4kPIOP3dG","executionInfo":{"status":"ok","timestamp":1620866741676,"user_tz":-60,"elapsed":9762,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"b2b2fbea-e5e5-474d-ef22-620911ec1621"},"source":["!pip install gdown\n","import gdown\n","!gdown https://drive.google.com/uc?id=1-Y19ljB76eESM6m8EVcZVeQjRfcNa7In"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Pretrained model \"bert-base-uncased\" loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cwmUYxJs5mZJ"},"source":["model, optimizer = load_model(args, load_path='final_rerelease_roberta-large_1e-05_16_2.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kq3TKrll5ooF"},"source":["data_dir = '4_reformulated_datasets'\n","train_name = 'util_train_no_test_overlap'\n","test_name = \"util_test_easy_matched\"\n","hard_test_name = \"util_test_hard_matched\"\n","unmatched_test_name = \"test_combined_unmatched\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nMofe2_w5rB6"},"source":["train_data = load_process_data(args, data_dir, \"util\", train_name)\n","test_hard_data = load_process_data(args, data_dir, \"util\", hard_test_name)\n","test_data = load_process_data(args, data_dir, \"util\", test_name)\n","test_unmatched_data = load_process_data(args, data_dir, \"util\", unmatched_test_name)\n","\n","train_dataloader = DataLoader(train_data, batch_size=args.batch_size // 2, shuffle=True)\n","test_dataloader = DataLoader(test_data, batch_size=args.batch_size // 2, shuffle=False)\n","hard_test_dataloader = DataLoader(test_hard_data, batch_size=args.batch_size // 2, shuffle=False)\n","unmatched_test_dataloader = DataLoader(test_unmatched_data, batch_size=args.batch_size // 2, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYnmKu45Y7bQ","executionInfo":{"status":"ok","timestamp":1621148687153,"user_tz":-60,"elapsed":50038,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"185a2cb5-78dd-41c6-c944-64cb1668fb21"},"source":["evaluate(model, test_dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Acc 0.976\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.9755371900826446"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Autey0lc68aN","executionInfo":{"status":"ok","timestamp":1621148709284,"user_tz":-60,"elapsed":71884,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"e1a1eef1-d950-4985-bd7b-ee50fdbc5a00"},"source":["evaluate(model, hard_test_dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Acc 0.727\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.7274323849666315"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"BMqE-e-K68aS"},"source":["for name, param in model.named_parameters():\n","    if name != 'module.classifier.out_proj.weight' and name != 'module.classifier.out_proj.bias':\n","      param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etdboHHK68aT","executionInfo":{"status":"ok","timestamp":1621148709286,"user_tz":-60,"elapsed":71326,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"e4b1e96e-ad57-48df-f027-6bf564e8220e"},"source":["for name, param in model.named_parameters():\n","    if param.requires_grad:\n","        print(name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["module.classifier.out_proj.weight\n","module.classifier.out_proj.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8iTMR3UM68aV"},"source":["trainable_parameters = [model.module.classifier.out_proj.weight, model.module.classifier.out_proj.bias]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p9GpgU0-68aV"},"source":["args.learning_rate = 1e-5\n","args.batch_size = 8\n","args.nepochs = 10\n","betas = (0.9,0.995)\n","train_mc_samples = 5\n","eval_mc_samples = 20"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"khoWTo5B68aW"},"source":["optimizer_vadam_last_layer = Vadam(trainable_parameters,\n","                lr = args.learning_rate,\n","                betas = betas,\n","                prior_prec = 1.0,\n","                prec_init = 1.0,\n","                num_samples = train_mc_samples,\n","                train_set_size = len(train_data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LFZmLaC4Mbod"},"source":["current_precisions = None\n","precisions_difference = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5QW35_hl68aX","executionInfo":{"status":"ok","timestamp":1621153553972,"user_tz":-60,"elapsed":4914572,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"17822180-a26a-4126-bb0e-1f917053c814"},"source":["for epoch in range(args.nepochs):\n","  print()\n","  train_variational(model, optimizer_vadam_last_layer, train_dataloader, epoch, verbose=True)\n","  if epoch > 0:\n","    precisions_difference.append(torch.norm(optimizer_vadam_last_layer.get_weight_precs()[0][0][0] - current_precisions[0][0][0]))\n","    print(precisions_difference)\n","  epoch += 1\n","  current_precisions = copy.deepcopy(optimizer_vadam_last_layer.get_weight_precs())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:79: UserWarning: This overload of addcdiv_ is deprecated:\n","\taddcdiv_(Number value, Tensor tensor1, Tensor tensor2)\n","Consider using one of the following signatures instead:\n","\taddcdiv_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 0 [10/1485 (1%)]\tLoss: 1.272528\n","Train Epoch: 0 [20/1485 (1%)]\tLoss: 0.727781\n","Train Epoch: 0 [30/1485 (2%)]\tLoss: 0.338296\n","Train Epoch: 0 [40/1485 (3%)]\tLoss: 0.435092\n","Train Epoch: 0 [50/1485 (3%)]\tLoss: 0.122471\n","Train Epoch: 0 [60/1485 (4%)]\tLoss: 0.269610\n","Train Epoch: 0 [70/1485 (5%)]\tLoss: 0.477961\n","Train Epoch: 0 [80/1485 (5%)]\tLoss: 0.553490\n","Train Epoch: 0 [90/1485 (6%)]\tLoss: 0.723457\n","Train Epoch: 0 [100/1485 (7%)]\tLoss: 0.032279\n","Train Epoch: 0 [110/1485 (7%)]\tLoss: 0.221996\n","Train Epoch: 0 [120/1485 (8%)]\tLoss: 1.084319\n","Train Epoch: 0 [130/1485 (9%)]\tLoss: 0.328190\n","Train Epoch: 0 [140/1485 (9%)]\tLoss: 0.197676\n","Train Epoch: 0 [150/1485 (10%)]\tLoss: 0.044588\n","Train Epoch: 0 [160/1485 (11%)]\tLoss: 0.235096\n","Train Epoch: 0 [170/1485 (11%)]\tLoss: 0.332862\n","Train Epoch: 0 [180/1485 (12%)]\tLoss: 0.041235\n","Train Epoch: 0 [190/1485 (13%)]\tLoss: 0.518321\n","Train Epoch: 0 [200/1485 (13%)]\tLoss: 0.316497\n","Train Epoch: 0 [210/1485 (14%)]\tLoss: 1.006649\n","Train Epoch: 0 [220/1485 (15%)]\tLoss: 0.033893\n","Train Epoch: 0 [230/1485 (15%)]\tLoss: 0.238423\n","Train Epoch: 0 [240/1485 (16%)]\tLoss: 0.101791\n","Train Epoch: 0 [250/1485 (17%)]\tLoss: 0.208277\n","Train Epoch: 0 [260/1485 (18%)]\tLoss: 0.028950\n","Train Epoch: 0 [270/1485 (18%)]\tLoss: 0.719119\n","Train Epoch: 0 [280/1485 (19%)]\tLoss: 0.443429\n","Train Epoch: 0 [290/1485 (20%)]\tLoss: 0.125437\n","Train Epoch: 0 [300/1485 (20%)]\tLoss: 0.019137\n","Train Epoch: 0 [310/1485 (21%)]\tLoss: 0.076524\n","Train Epoch: 0 [320/1485 (22%)]\tLoss: 0.455923\n","Train Epoch: 0 [330/1485 (22%)]\tLoss: 0.105201\n","Train Epoch: 0 [340/1485 (23%)]\tLoss: 0.018082\n","Train Epoch: 0 [350/1485 (24%)]\tLoss: 1.233104\n","Train Epoch: 0 [360/1485 (24%)]\tLoss: 0.230359\n","Train Epoch: 0 [370/1485 (25%)]\tLoss: 0.207882\n","Train Epoch: 0 [380/1485 (26%)]\tLoss: 0.426947\n","Train Epoch: 0 [390/1485 (26%)]\tLoss: 0.065184\n","Train Epoch: 0 [400/1485 (27%)]\tLoss: 0.119187\n","Train Epoch: 0 [410/1485 (28%)]\tLoss: 0.327088\n","Train Epoch: 0 [420/1485 (28%)]\tLoss: 0.388030\n","Train Epoch: 0 [430/1485 (29%)]\tLoss: 0.049859\n","Train Epoch: 0 [440/1485 (30%)]\tLoss: 0.619379\n","Train Epoch: 0 [450/1485 (30%)]\tLoss: 0.432808\n","Train Epoch: 0 [460/1485 (31%)]\tLoss: 0.035045\n","Train Epoch: 0 [470/1485 (32%)]\tLoss: 0.309250\n","Train Epoch: 0 [480/1485 (32%)]\tLoss: 0.432352\n","Train Epoch: 0 [490/1485 (33%)]\tLoss: 0.851974\n","Train Epoch: 0 [500/1485 (34%)]\tLoss: 0.249274\n","Train Epoch: 0 [510/1485 (34%)]\tLoss: 0.408305\n","Train Epoch: 0 [520/1485 (35%)]\tLoss: 0.132060\n","Train Epoch: 0 [530/1485 (36%)]\tLoss: 0.208493\n","Train Epoch: 0 [540/1485 (36%)]\tLoss: 0.782052\n","Train Epoch: 0 [550/1485 (37%)]\tLoss: 0.024086\n","Train Epoch: 0 [560/1485 (38%)]\tLoss: 0.300076\n","Train Epoch: 0 [570/1485 (38%)]\tLoss: 0.242218\n","Train Epoch: 0 [580/1485 (39%)]\tLoss: 0.022537\n","Train Epoch: 0 [590/1485 (40%)]\tLoss: 0.365364\n","Train Epoch: 0 [600/1485 (40%)]\tLoss: 0.220754\n","Train Epoch: 0 [610/1485 (41%)]\tLoss: 0.239591\n","Train Epoch: 0 [620/1485 (42%)]\tLoss: 0.085769\n","Train Epoch: 0 [630/1485 (42%)]\tLoss: 0.498202\n","Train Epoch: 0 [640/1485 (43%)]\tLoss: 0.394566\n","Train Epoch: 0 [650/1485 (44%)]\tLoss: 0.840981\n","Train Epoch: 0 [660/1485 (44%)]\tLoss: 0.045102\n","Train Epoch: 0 [670/1485 (45%)]\tLoss: 0.226338\n","Train Epoch: 0 [680/1485 (46%)]\tLoss: 0.015518\n","Train Epoch: 0 [690/1485 (46%)]\tLoss: 0.561650\n","Train Epoch: 0 [700/1485 (47%)]\tLoss: 0.165260\n","Train Epoch: 0 [710/1485 (48%)]\tLoss: 0.298387\n","Train Epoch: 0 [720/1485 (48%)]\tLoss: 0.018625\n","Train Epoch: 0 [730/1485 (49%)]\tLoss: 0.469556\n","Train Epoch: 0 [740/1485 (50%)]\tLoss: 0.167245\n","Train Epoch: 0 [750/1485 (51%)]\tLoss: 0.181314\n","Train Epoch: 0 [760/1485 (51%)]\tLoss: 0.783891\n","Train Epoch: 0 [770/1485 (52%)]\tLoss: 0.473594\n","Train Epoch: 0 [780/1485 (53%)]\tLoss: 0.361319\n","Train Epoch: 0 [790/1485 (53%)]\tLoss: 0.039520\n","Train Epoch: 0 [800/1485 (54%)]\tLoss: 0.250897\n","Train Epoch: 0 [810/1485 (55%)]\tLoss: 0.010160\n","Train Epoch: 0 [820/1485 (55%)]\tLoss: 0.003951\n","Train Epoch: 0 [830/1485 (56%)]\tLoss: 1.030907\n","Train Epoch: 0 [840/1485 (57%)]\tLoss: 0.087622\n","Train Epoch: 0 [850/1485 (57%)]\tLoss: 0.353907\n","Train Epoch: 0 [860/1485 (58%)]\tLoss: 0.205496\n","Train Epoch: 0 [870/1485 (59%)]\tLoss: 0.244463\n","Train Epoch: 0 [880/1485 (59%)]\tLoss: 0.009974\n","Train Epoch: 0 [890/1485 (60%)]\tLoss: 0.301855\n","Train Epoch: 0 [900/1485 (61%)]\tLoss: 0.276180\n","Train Epoch: 0 [910/1485 (61%)]\tLoss: 0.328212\n","Train Epoch: 0 [920/1485 (62%)]\tLoss: 0.191029\n","Train Epoch: 0 [930/1485 (63%)]\tLoss: 1.026937\n","Train Epoch: 0 [940/1485 (63%)]\tLoss: 0.159836\n","Train Epoch: 0 [950/1485 (64%)]\tLoss: 0.042234\n","Train Epoch: 0 [960/1485 (65%)]\tLoss: 0.795385\n","Train Epoch: 0 [970/1485 (65%)]\tLoss: 0.453613\n","Train Epoch: 0 [980/1485 (66%)]\tLoss: 0.605765\n","Train Epoch: 0 [990/1485 (67%)]\tLoss: 0.245673\n","Train Epoch: 0 [1000/1485 (67%)]\tLoss: 0.010031\n","Train Epoch: 0 [1010/1485 (68%)]\tLoss: 0.368720\n","Train Epoch: 0 [1020/1485 (69%)]\tLoss: 0.755094\n","Train Epoch: 0 [1030/1485 (69%)]\tLoss: 0.503714\n","Train Epoch: 0 [1040/1485 (70%)]\tLoss: 0.151431\n","Train Epoch: 0 [1050/1485 (71%)]\tLoss: 0.044538\n","Train Epoch: 0 [1060/1485 (71%)]\tLoss: 0.008607\n","Train Epoch: 0 [1070/1485 (72%)]\tLoss: 0.586238\n","Train Epoch: 0 [1080/1485 (73%)]\tLoss: 0.090629\n","Train Epoch: 0 [1090/1485 (73%)]\tLoss: 0.341625\n","Train Epoch: 0 [1100/1485 (74%)]\tLoss: 1.447116\n","Train Epoch: 0 [1110/1485 (75%)]\tLoss: 0.149295\n","Train Epoch: 0 [1120/1485 (75%)]\tLoss: 0.663182\n","Train Epoch: 0 [1130/1485 (76%)]\tLoss: 0.347168\n","Train Epoch: 0 [1140/1485 (77%)]\tLoss: 0.685399\n","Train Epoch: 0 [1150/1485 (77%)]\tLoss: 0.036966\n","Train Epoch: 0 [1160/1485 (78%)]\tLoss: 0.958774\n","Train Epoch: 0 [1170/1485 (79%)]\tLoss: 0.160824\n","Train Epoch: 0 [1180/1485 (79%)]\tLoss: 0.142411\n","Train Epoch: 0 [1190/1485 (80%)]\tLoss: 0.086765\n","Train Epoch: 0 [1200/1485 (81%)]\tLoss: 0.352986\n","Train Epoch: 0 [1210/1485 (81%)]\tLoss: 0.026699\n","Train Epoch: 0 [1220/1485 (82%)]\tLoss: 0.079724\n","Train Epoch: 0 [1230/1485 (83%)]\tLoss: 0.125482\n","Train Epoch: 0 [1240/1485 (84%)]\tLoss: 0.176303\n","Train Epoch: 0 [1250/1485 (84%)]\tLoss: 0.505451\n","Train Epoch: 0 [1260/1485 (85%)]\tLoss: 0.336525\n","Train Epoch: 0 [1270/1485 (86%)]\tLoss: 0.854520\n","Train Epoch: 0 [1280/1485 (86%)]\tLoss: 0.358224\n","Train Epoch: 0 [1290/1485 (87%)]\tLoss: 0.154953\n","Train Epoch: 0 [1300/1485 (88%)]\tLoss: 0.472736\n","Train Epoch: 0 [1310/1485 (88%)]\tLoss: 0.680923\n","Train Epoch: 0 [1320/1485 (89%)]\tLoss: 0.054514\n","Train Epoch: 0 [1330/1485 (90%)]\tLoss: 0.039877\n","Train Epoch: 0 [1340/1485 (90%)]\tLoss: 0.138211\n","Train Epoch: 0 [1350/1485 (91%)]\tLoss: 0.430239\n","Train Epoch: 0 [1360/1485 (92%)]\tLoss: 0.055335\n","Train Epoch: 0 [1370/1485 (92%)]\tLoss: 0.157898\n","Train Epoch: 0 [1380/1485 (93%)]\tLoss: 0.002167\n","Train Epoch: 0 [1390/1485 (94%)]\tLoss: 0.092230\n","Train Epoch: 0 [1400/1485 (94%)]\tLoss: 0.499190\n","Train Epoch: 0 [1410/1485 (95%)]\tLoss: 0.183178\n","Train Epoch: 0 [1420/1485 (96%)]\tLoss: 0.124156\n","Train Epoch: 0 [1430/1485 (96%)]\tLoss: 0.202922\n","Train Epoch: 0 [1440/1485 (97%)]\tLoss: 0.002949\n","Train Epoch: 0 [1450/1485 (98%)]\tLoss: 0.475505\n","Train Epoch: 0 [1460/1485 (98%)]\tLoss: 0.042601\n","Train Epoch: 0 [1470/1485 (99%)]\tLoss: 0.045463\n","Train Epoch: 0 [1480/1485 (100%)]\tLoss: 0.002927\n","\n","Train Epoch: 1 [10/1485 (1%)]\tLoss: 0.089496\n","Train Epoch: 1 [20/1485 (1%)]\tLoss: 0.255004\n","Train Epoch: 1 [30/1485 (2%)]\tLoss: 0.398632\n","Train Epoch: 1 [40/1485 (3%)]\tLoss: 0.047967\n","Train Epoch: 1 [50/1485 (3%)]\tLoss: 0.107892\n","Train Epoch: 1 [60/1485 (4%)]\tLoss: 0.093877\n","Train Epoch: 1 [70/1485 (5%)]\tLoss: 0.315248\n","Train Epoch: 1 [80/1485 (5%)]\tLoss: 1.112820\n","Train Epoch: 1 [90/1485 (6%)]\tLoss: 0.147754\n","Train Epoch: 1 [100/1485 (7%)]\tLoss: 0.387128\n","Train Epoch: 1 [110/1485 (7%)]\tLoss: 0.071879\n","Train Epoch: 1 [120/1485 (8%)]\tLoss: 0.291527\n","Train Epoch: 1 [130/1485 (9%)]\tLoss: 0.038593\n","Train Epoch: 1 [140/1485 (9%)]\tLoss: 0.551648\n","Train Epoch: 1 [150/1485 (10%)]\tLoss: 0.659358\n","Train Epoch: 1 [160/1485 (11%)]\tLoss: 0.371309\n","Train Epoch: 1 [170/1485 (11%)]\tLoss: 0.287326\n","Train Epoch: 1 [180/1485 (12%)]\tLoss: 0.877928\n","Train Epoch: 1 [190/1485 (13%)]\tLoss: 0.015289\n","Train Epoch: 1 [200/1485 (13%)]\tLoss: 0.117278\n","Train Epoch: 1 [210/1485 (14%)]\tLoss: 0.236348\n","Train Epoch: 1 [220/1485 (15%)]\tLoss: 0.026067\n","Train Epoch: 1 [230/1485 (15%)]\tLoss: 0.087577\n","Train Epoch: 1 [240/1485 (16%)]\tLoss: 0.487220\n","Train Epoch: 1 [250/1485 (17%)]\tLoss: 0.087920\n","Train Epoch: 1 [260/1485 (18%)]\tLoss: 0.102421\n","Train Epoch: 1 [270/1485 (18%)]\tLoss: 1.322734\n","Train Epoch: 1 [280/1485 (19%)]\tLoss: 0.090452\n","Train Epoch: 1 [290/1485 (20%)]\tLoss: 0.110117\n","Train Epoch: 1 [300/1485 (20%)]\tLoss: 0.003987\n","Train Epoch: 1 [310/1485 (21%)]\tLoss: 0.022128\n","Train Epoch: 1 [320/1485 (22%)]\tLoss: 0.102061\n","Train Epoch: 1 [330/1485 (22%)]\tLoss: 0.016404\n","Train Epoch: 1 [340/1485 (23%)]\tLoss: 0.187296\n","Train Epoch: 1 [350/1485 (24%)]\tLoss: 0.494635\n","Train Epoch: 1 [360/1485 (24%)]\tLoss: 0.106379\n","Train Epoch: 1 [370/1485 (25%)]\tLoss: 0.224207\n","Train Epoch: 1 [380/1485 (26%)]\tLoss: 0.020364\n","Train Epoch: 1 [390/1485 (26%)]\tLoss: 0.179834\n","Train Epoch: 1 [400/1485 (27%)]\tLoss: 0.079842\n","Train Epoch: 1 [410/1485 (28%)]\tLoss: 0.467775\n","Train Epoch: 1 [420/1485 (28%)]\tLoss: 0.018159\n","Train Epoch: 1 [430/1485 (29%)]\tLoss: 0.569184\n","Train Epoch: 1 [440/1485 (30%)]\tLoss: 0.013715\n","Train Epoch: 1 [450/1485 (30%)]\tLoss: 0.009957\n","Train Epoch: 1 [460/1485 (31%)]\tLoss: 0.028313\n","Train Epoch: 1 [470/1485 (32%)]\tLoss: 0.233475\n","Train Epoch: 1 [480/1485 (32%)]\tLoss: 0.406367\n","Train Epoch: 1 [490/1485 (33%)]\tLoss: 0.207214\n","Train Epoch: 1 [500/1485 (34%)]\tLoss: 0.016870\n","Train Epoch: 1 [510/1485 (34%)]\tLoss: 1.043893\n","Train Epoch: 1 [520/1485 (35%)]\tLoss: 0.289302\n","Train Epoch: 1 [530/1485 (36%)]\tLoss: 0.607713\n","Train Epoch: 1 [540/1485 (36%)]\tLoss: 0.415602\n","Train Epoch: 1 [550/1485 (37%)]\tLoss: 0.342464\n","Train Epoch: 1 [560/1485 (38%)]\tLoss: 0.264950\n","Train Epoch: 1 [570/1485 (38%)]\tLoss: 0.231140\n","Train Epoch: 1 [580/1485 (39%)]\tLoss: 0.016971\n","Train Epoch: 1 [590/1485 (40%)]\tLoss: 0.240925\n","Train Epoch: 1 [600/1485 (40%)]\tLoss: 0.289388\n","Train Epoch: 1 [610/1485 (41%)]\tLoss: 0.243091\n","Train Epoch: 1 [620/1485 (42%)]\tLoss: 0.014433\n","Train Epoch: 1 [630/1485 (42%)]\tLoss: 0.022470\n","Train Epoch: 1 [640/1485 (43%)]\tLoss: 0.428150\n","Train Epoch: 1 [650/1485 (44%)]\tLoss: 0.042860\n","Train Epoch: 1 [660/1485 (44%)]\tLoss: 0.060879\n","Train Epoch: 1 [670/1485 (45%)]\tLoss: 0.292674\n","Train Epoch: 1 [680/1485 (46%)]\tLoss: 0.134447\n","Train Epoch: 1 [690/1485 (46%)]\tLoss: 0.495063\n","Train Epoch: 1 [700/1485 (47%)]\tLoss: 0.021450\n","Train Epoch: 1 [710/1485 (48%)]\tLoss: 0.168828\n","Train Epoch: 1 [720/1485 (48%)]\tLoss: 0.044737\n","Train Epoch: 1 [730/1485 (49%)]\tLoss: 0.054321\n","Train Epoch: 1 [740/1485 (50%)]\tLoss: 0.274262\n","Train Epoch: 1 [750/1485 (51%)]\tLoss: 0.754276\n","Train Epoch: 1 [760/1485 (51%)]\tLoss: 0.147004\n","Train Epoch: 1 [770/1485 (52%)]\tLoss: 0.192048\n","Train Epoch: 1 [780/1485 (53%)]\tLoss: 0.605299\n","Train Epoch: 1 [790/1485 (53%)]\tLoss: 0.065782\n","Train Epoch: 1 [800/1485 (54%)]\tLoss: 0.303109\n","Train Epoch: 1 [810/1485 (55%)]\tLoss: 0.048968\n","Train Epoch: 1 [820/1485 (55%)]\tLoss: 0.077596\n","Train Epoch: 1 [830/1485 (56%)]\tLoss: 0.197907\n","Train Epoch: 1 [840/1485 (57%)]\tLoss: 0.159927\n","Train Epoch: 1 [850/1485 (57%)]\tLoss: 0.656558\n","Train Epoch: 1 [860/1485 (58%)]\tLoss: 0.062662\n","Train Epoch: 1 [870/1485 (59%)]\tLoss: 0.517970\n","Train Epoch: 1 [880/1485 (59%)]\tLoss: 0.316343\n","Train Epoch: 1 [890/1485 (60%)]\tLoss: 0.000087\n","Train Epoch: 1 [900/1485 (61%)]\tLoss: 0.376535\n","Train Epoch: 1 [910/1485 (61%)]\tLoss: 0.128842\n","Train Epoch: 1 [920/1485 (62%)]\tLoss: 0.249868\n","Train Epoch: 1 [930/1485 (63%)]\tLoss: 0.064842\n","Train Epoch: 1 [940/1485 (63%)]\tLoss: 0.403026\n","Train Epoch: 1 [950/1485 (64%)]\tLoss: 0.223769\n","Train Epoch: 1 [960/1485 (65%)]\tLoss: 0.578042\n","Train Epoch: 1 [970/1485 (65%)]\tLoss: 0.072974\n","Train Epoch: 1 [980/1485 (66%)]\tLoss: 0.500872\n","Train Epoch: 1 [990/1485 (67%)]\tLoss: 0.204661\n","Train Epoch: 1 [1000/1485 (67%)]\tLoss: 0.303618\n","Train Epoch: 1 [1010/1485 (68%)]\tLoss: 0.044669\n","Train Epoch: 1 [1020/1485 (69%)]\tLoss: 0.116820\n","Train Epoch: 1 [1030/1485 (69%)]\tLoss: 0.572340\n","Train Epoch: 1 [1040/1485 (70%)]\tLoss: 0.033699\n","Train Epoch: 1 [1050/1485 (71%)]\tLoss: 0.085932\n","Train Epoch: 1 [1060/1485 (71%)]\tLoss: 0.341228\n","Train Epoch: 1 [1070/1485 (72%)]\tLoss: 0.210148\n","Train Epoch: 1 [1080/1485 (73%)]\tLoss: 0.064827\n","Train Epoch: 1 [1090/1485 (73%)]\tLoss: 0.005207\n","Train Epoch: 1 [1100/1485 (74%)]\tLoss: 0.017678\n","Train Epoch: 1 [1110/1485 (75%)]\tLoss: 0.345480\n","Train Epoch: 1 [1120/1485 (75%)]\tLoss: 0.403062\n","Train Epoch: 1 [1130/1485 (76%)]\tLoss: 0.357527\n","Train Epoch: 1 [1140/1485 (77%)]\tLoss: 0.128273\n","Train Epoch: 1 [1150/1485 (77%)]\tLoss: 0.025249\n","Train Epoch: 1 [1160/1485 (78%)]\tLoss: 0.072505\n","Train Epoch: 1 [1170/1485 (79%)]\tLoss: 0.029964\n","Train Epoch: 1 [1180/1485 (79%)]\tLoss: 0.630914\n","Train Epoch: 1 [1190/1485 (80%)]\tLoss: 0.515663\n","Train Epoch: 1 [1200/1485 (81%)]\tLoss: 0.980343\n","Train Epoch: 1 [1210/1485 (81%)]\tLoss: 0.187960\n","Train Epoch: 1 [1220/1485 (82%)]\tLoss: 0.236164\n","Train Epoch: 1 [1230/1485 (83%)]\tLoss: 0.345078\n","Train Epoch: 1 [1240/1485 (84%)]\tLoss: 0.296023\n","Train Epoch: 1 [1250/1485 (84%)]\tLoss: 0.002984\n","Train Epoch: 1 [1260/1485 (85%)]\tLoss: 0.052193\n","Train Epoch: 1 [1270/1485 (86%)]\tLoss: 0.098239\n","Train Epoch: 1 [1280/1485 (86%)]\tLoss: 0.263084\n","Train Epoch: 1 [1290/1485 (87%)]\tLoss: 0.024801\n","Train Epoch: 1 [1300/1485 (88%)]\tLoss: 0.001885\n","Train Epoch: 1 [1310/1485 (88%)]\tLoss: 0.051581\n","Train Epoch: 1 [1320/1485 (89%)]\tLoss: 0.446666\n","Train Epoch: 1 [1330/1485 (90%)]\tLoss: 0.711824\n","Train Epoch: 1 [1340/1485 (90%)]\tLoss: 0.209477\n","Train Epoch: 1 [1350/1485 (91%)]\tLoss: 0.223935\n","Train Epoch: 1 [1360/1485 (92%)]\tLoss: 0.078866\n","Train Epoch: 1 [1370/1485 (92%)]\tLoss: 0.729436\n","Train Epoch: 1 [1380/1485 (93%)]\tLoss: 0.304361\n","Train Epoch: 1 [1390/1485 (94%)]\tLoss: 0.029691\n","Train Epoch: 1 [1400/1485 (94%)]\tLoss: 0.001070\n","Train Epoch: 1 [1410/1485 (95%)]\tLoss: 0.113320\n","Train Epoch: 1 [1420/1485 (96%)]\tLoss: 0.319975\n","Train Epoch: 1 [1430/1485 (96%)]\tLoss: 0.232817\n","Train Epoch: 1 [1440/1485 (97%)]\tLoss: 0.010757\n","Train Epoch: 1 [1450/1485 (98%)]\tLoss: 0.522856\n","Train Epoch: 1 [1460/1485 (98%)]\tLoss: 0.029153\n","Train Epoch: 1 [1470/1485 (99%)]\tLoss: 0.012800\n","Train Epoch: 1 [1480/1485 (100%)]\tLoss: 0.601069\n","[tensor(135.8353, device='cuda:0')]\n","\n","Train Epoch: 2 [10/1485 (1%)]\tLoss: 0.651482\n","Train Epoch: 2 [20/1485 (1%)]\tLoss: 0.580005\n","Train Epoch: 2 [30/1485 (2%)]\tLoss: 0.026073\n","Train Epoch: 2 [40/1485 (3%)]\tLoss: 0.531532\n","Train Epoch: 2 [50/1485 (3%)]\tLoss: 0.188133\n","Train Epoch: 2 [60/1485 (4%)]\tLoss: 0.066754\n","Train Epoch: 2 [70/1485 (5%)]\tLoss: 0.249441\n","Train Epoch: 2 [80/1485 (5%)]\tLoss: 0.165115\n","Train Epoch: 2 [90/1485 (6%)]\tLoss: 1.043621\n","Train Epoch: 2 [100/1485 (7%)]\tLoss: 0.023049\n","Train Epoch: 2 [110/1485 (7%)]\tLoss: 0.239789\n","Train Epoch: 2 [120/1485 (8%)]\tLoss: 0.007925\n","Train Epoch: 2 [130/1485 (9%)]\tLoss: 0.001104\n","Train Epoch: 2 [140/1485 (9%)]\tLoss: 0.288529\n","Train Epoch: 2 [150/1485 (10%)]\tLoss: 0.624504\n","Train Epoch: 2 [160/1485 (11%)]\tLoss: 0.027688\n","Train Epoch: 2 [170/1485 (11%)]\tLoss: 0.279399\n","Train Epoch: 2 [180/1485 (12%)]\tLoss: 0.633847\n","Train Epoch: 2 [190/1485 (13%)]\tLoss: 0.489145\n","Train Epoch: 2 [200/1485 (13%)]\tLoss: 0.019994\n","Train Epoch: 2 [210/1485 (14%)]\tLoss: 0.486239\n","Train Epoch: 2 [220/1485 (15%)]\tLoss: 0.281957\n","Train Epoch: 2 [230/1485 (15%)]\tLoss: 1.331084\n","Train Epoch: 2 [240/1485 (16%)]\tLoss: 0.408999\n","Train Epoch: 2 [250/1485 (17%)]\tLoss: 0.085896\n","Train Epoch: 2 [260/1485 (18%)]\tLoss: 0.387555\n","Train Epoch: 2 [270/1485 (18%)]\tLoss: 0.622858\n","Train Epoch: 2 [280/1485 (19%)]\tLoss: 0.014305\n","Train Epoch: 2 [290/1485 (20%)]\tLoss: 0.771451\n","Train Epoch: 2 [300/1485 (20%)]\tLoss: 0.016528\n","Train Epoch: 2 [310/1485 (21%)]\tLoss: 1.250157\n","Train Epoch: 2 [320/1485 (22%)]\tLoss: 0.068091\n","Train Epoch: 2 [330/1485 (22%)]\tLoss: 0.416579\n","Train Epoch: 2 [340/1485 (23%)]\tLoss: 0.001263\n","Train Epoch: 2 [350/1485 (24%)]\tLoss: 0.163006\n","Train Epoch: 2 [360/1485 (24%)]\tLoss: 0.063991\n","Train Epoch: 2 [370/1485 (25%)]\tLoss: 0.848355\n","Train Epoch: 2 [380/1485 (26%)]\tLoss: 0.166943\n","Train Epoch: 2 [390/1485 (26%)]\tLoss: 0.072138\n","Train Epoch: 2 [400/1485 (27%)]\tLoss: 0.306804\n","Train Epoch: 2 [410/1485 (28%)]\tLoss: 0.038845\n","Train Epoch: 2 [420/1485 (28%)]\tLoss: 0.739544\n","Train Epoch: 2 [430/1485 (29%)]\tLoss: 0.417162\n","Train Epoch: 2 [440/1485 (30%)]\tLoss: 0.462238\n","Train Epoch: 2 [450/1485 (30%)]\tLoss: 0.107014\n","Train Epoch: 2 [460/1485 (31%)]\tLoss: 0.930459\n","Train Epoch: 2 [470/1485 (32%)]\tLoss: 0.316995\n","Train Epoch: 2 [480/1485 (32%)]\tLoss: 0.009297\n","Train Epoch: 2 [490/1485 (33%)]\tLoss: 0.039607\n","Train Epoch: 2 [500/1485 (34%)]\tLoss: 0.418094\n","Train Epoch: 2 [510/1485 (34%)]\tLoss: 0.037921\n","Train Epoch: 2 [520/1485 (35%)]\tLoss: 0.226413\n","Train Epoch: 2 [530/1485 (36%)]\tLoss: 0.256416\n","Train Epoch: 2 [540/1485 (36%)]\tLoss: 0.002291\n","Train Epoch: 2 [550/1485 (37%)]\tLoss: 0.089455\n","Train Epoch: 2 [560/1485 (38%)]\tLoss: 0.069794\n","Train Epoch: 2 [570/1485 (38%)]\tLoss: 0.876529\n","Train Epoch: 2 [580/1485 (39%)]\tLoss: 0.113257\n","Train Epoch: 2 [590/1485 (40%)]\tLoss: 0.069870\n","Train Epoch: 2 [600/1485 (40%)]\tLoss: 0.085047\n","Train Epoch: 2 [610/1485 (41%)]\tLoss: 0.416818\n","Train Epoch: 2 [620/1485 (42%)]\tLoss: 0.131285\n","Train Epoch: 2 [630/1485 (42%)]\tLoss: 0.309922\n","Train Epoch: 2 [640/1485 (43%)]\tLoss: 0.024268\n","Train Epoch: 2 [650/1485 (44%)]\tLoss: 0.060208\n","Train Epoch: 2 [660/1485 (44%)]\tLoss: 0.032742\n","Train Epoch: 2 [670/1485 (45%)]\tLoss: 0.412590\n","Train Epoch: 2 [680/1485 (46%)]\tLoss: 0.230113\n","Train Epoch: 2 [690/1485 (46%)]\tLoss: 0.077809\n","Train Epoch: 2 [700/1485 (47%)]\tLoss: 0.294033\n","Train Epoch: 2 [710/1485 (48%)]\tLoss: 0.742620\n","Train Epoch: 2 [720/1485 (48%)]\tLoss: 0.007781\n","Train Epoch: 2 [730/1485 (49%)]\tLoss: 0.035165\n","Train Epoch: 2 [740/1485 (50%)]\tLoss: 0.541078\n","Train Epoch: 2 [750/1485 (51%)]\tLoss: 0.076736\n","Train Epoch: 2 [760/1485 (51%)]\tLoss: 0.482355\n","Train Epoch: 2 [770/1485 (52%)]\tLoss: 0.685810\n","Train Epoch: 2 [780/1485 (53%)]\tLoss: 0.000072\n","Train Epoch: 2 [790/1485 (53%)]\tLoss: 0.058135\n","Train Epoch: 2 [800/1485 (54%)]\tLoss: 0.033303\n","Train Epoch: 2 [810/1485 (55%)]\tLoss: 0.196139\n","Train Epoch: 2 [820/1485 (55%)]\tLoss: 1.072738\n","Train Epoch: 2 [830/1485 (56%)]\tLoss: 0.171473\n","Train Epoch: 2 [840/1485 (57%)]\tLoss: 0.223550\n","Train Epoch: 2 [850/1485 (57%)]\tLoss: 0.146960\n","Train Epoch: 2 [860/1485 (58%)]\tLoss: 0.094660\n","Train Epoch: 2 [870/1485 (59%)]\tLoss: 0.150451\n","Train Epoch: 2 [880/1485 (59%)]\tLoss: 0.030505\n","Train Epoch: 2 [890/1485 (60%)]\tLoss: 1.425650\n","Train Epoch: 2 [900/1485 (61%)]\tLoss: 0.343993\n","Train Epoch: 2 [910/1485 (61%)]\tLoss: 0.582258\n","Train Epoch: 2 [920/1485 (62%)]\tLoss: 0.082512\n","Train Epoch: 2 [930/1485 (63%)]\tLoss: 0.050273\n","Train Epoch: 2 [940/1485 (63%)]\tLoss: 0.164948\n","Train Epoch: 2 [950/1485 (64%)]\tLoss: 0.302093\n","Train Epoch: 2 [960/1485 (65%)]\tLoss: 0.122292\n","Train Epoch: 2 [970/1485 (65%)]\tLoss: 0.081941\n","Train Epoch: 2 [980/1485 (66%)]\tLoss: 0.070200\n","Train Epoch: 2 [990/1485 (67%)]\tLoss: 0.212300\n","Train Epoch: 2 [1000/1485 (67%)]\tLoss: 0.049494\n","Train Epoch: 2 [1010/1485 (68%)]\tLoss: 0.124637\n","Train Epoch: 2 [1020/1485 (69%)]\tLoss: 0.056412\n","Train Epoch: 2 [1030/1485 (69%)]\tLoss: 0.041491\n","Train Epoch: 2 [1040/1485 (70%)]\tLoss: 0.530341\n","Train Epoch: 2 [1050/1485 (71%)]\tLoss: 0.004413\n","Train Epoch: 2 [1060/1485 (71%)]\tLoss: 0.126698\n","Train Epoch: 2 [1070/1485 (72%)]\tLoss: 0.473885\n","Train Epoch: 2 [1080/1485 (73%)]\tLoss: 0.106971\n","Train Epoch: 2 [1090/1485 (73%)]\tLoss: 0.039363\n","Train Epoch: 2 [1100/1485 (74%)]\tLoss: 0.589179\n","Train Epoch: 2 [1110/1485 (75%)]\tLoss: 0.363954\n","Train Epoch: 2 [1120/1485 (75%)]\tLoss: 0.229076\n","Train Epoch: 2 [1130/1485 (76%)]\tLoss: 0.564806\n","Train Epoch: 2 [1140/1485 (77%)]\tLoss: 0.247321\n","Train Epoch: 2 [1150/1485 (77%)]\tLoss: 0.024605\n","Train Epoch: 2 [1160/1485 (78%)]\tLoss: 0.003048\n","Train Epoch: 2 [1170/1485 (79%)]\tLoss: 0.046677\n","Train Epoch: 2 [1180/1485 (79%)]\tLoss: 0.900512\n","Train Epoch: 2 [1190/1485 (80%)]\tLoss: 0.284202\n","Train Epoch: 2 [1200/1485 (81%)]\tLoss: 0.106603\n","Train Epoch: 2 [1210/1485 (81%)]\tLoss: 0.031334\n","Train Epoch: 2 [1220/1485 (82%)]\tLoss: 0.007809\n","Train Epoch: 2 [1230/1485 (83%)]\tLoss: 0.454159\n","Train Epoch: 2 [1240/1485 (84%)]\tLoss: 0.387816\n","Train Epoch: 2 [1250/1485 (84%)]\tLoss: 0.066105\n","Train Epoch: 2 [1260/1485 (85%)]\tLoss: 0.456668\n","Train Epoch: 2 [1270/1485 (86%)]\tLoss: 0.002409\n","Train Epoch: 2 [1280/1485 (86%)]\tLoss: 0.000096\n","Train Epoch: 2 [1290/1485 (87%)]\tLoss: 0.485752\n","Train Epoch: 2 [1300/1485 (88%)]\tLoss: 0.159141\n","Train Epoch: 2 [1310/1485 (88%)]\tLoss: 0.124038\n","Train Epoch: 2 [1320/1485 (89%)]\tLoss: 0.138961\n","Train Epoch: 2 [1330/1485 (90%)]\tLoss: 0.329669\n","Train Epoch: 2 [1340/1485 (90%)]\tLoss: 0.968336\n","Train Epoch: 2 [1350/1485 (91%)]\tLoss: 0.249036\n","Train Epoch: 2 [1360/1485 (92%)]\tLoss: 0.230012\n","Train Epoch: 2 [1370/1485 (92%)]\tLoss: 0.000265\n","Train Epoch: 2 [1380/1485 (93%)]\tLoss: 0.712604\n","Train Epoch: 2 [1390/1485 (94%)]\tLoss: 0.031584\n","Train Epoch: 2 [1400/1485 (94%)]\tLoss: 0.017931\n","Train Epoch: 2 [1410/1485 (95%)]\tLoss: 0.032273\n","Train Epoch: 2 [1420/1485 (96%)]\tLoss: 0.026923\n","Train Epoch: 2 [1430/1485 (96%)]\tLoss: 2.040880\n","Train Epoch: 2 [1440/1485 (97%)]\tLoss: 0.000076\n","Train Epoch: 2 [1450/1485 (98%)]\tLoss: 0.321285\n","Train Epoch: 2 [1460/1485 (98%)]\tLoss: 0.263794\n","Train Epoch: 2 [1470/1485 (99%)]\tLoss: 0.086712\n","Train Epoch: 2 [1480/1485 (100%)]\tLoss: 0.003067\n","[tensor(135.8353, device='cuda:0'), tensor(144.3386, device='cuda:0')]\n","\n","Train Epoch: 3 [10/1485 (1%)]\tLoss: 0.194593\n","Train Epoch: 3 [20/1485 (1%)]\tLoss: 0.233832\n","Train Epoch: 3 [30/1485 (2%)]\tLoss: 0.335816\n","Train Epoch: 3 [40/1485 (3%)]\tLoss: 0.320040\n","Train Epoch: 3 [50/1485 (3%)]\tLoss: 0.870363\n","Train Epoch: 3 [60/1485 (4%)]\tLoss: 0.004644\n","Train Epoch: 3 [70/1485 (5%)]\tLoss: 0.431649\n","Train Epoch: 3 [80/1485 (5%)]\tLoss: 0.285801\n","Train Epoch: 3 [90/1485 (6%)]\tLoss: 0.029775\n","Train Epoch: 3 [100/1485 (7%)]\tLoss: 0.010876\n","Train Epoch: 3 [110/1485 (7%)]\tLoss: 0.189836\n","Train Epoch: 3 [120/1485 (8%)]\tLoss: 0.645874\n","Train Epoch: 3 [130/1485 (9%)]\tLoss: 0.937313\n","Train Epoch: 3 [140/1485 (9%)]\tLoss: 0.572289\n","Train Epoch: 3 [150/1485 (10%)]\tLoss: 0.024075\n","Train Epoch: 3 [160/1485 (11%)]\tLoss: 0.959285\n","Train Epoch: 3 [170/1485 (11%)]\tLoss: 0.918948\n","Train Epoch: 3 [180/1485 (12%)]\tLoss: 0.108672\n","Train Epoch: 3 [190/1485 (13%)]\tLoss: 0.133722\n","Train Epoch: 3 [200/1485 (13%)]\tLoss: 0.124025\n","Train Epoch: 3 [210/1485 (14%)]\tLoss: 0.162397\n","Train Epoch: 3 [220/1485 (15%)]\tLoss: 0.063779\n","Train Epoch: 3 [230/1485 (15%)]\tLoss: 0.656801\n","Train Epoch: 3 [240/1485 (16%)]\tLoss: 0.019874\n","Train Epoch: 3 [250/1485 (17%)]\tLoss: 0.430596\n","Train Epoch: 3 [260/1485 (18%)]\tLoss: 0.014897\n","Train Epoch: 3 [270/1485 (18%)]\tLoss: 1.319617\n","Train Epoch: 3 [280/1485 (19%)]\tLoss: 0.008662\n","Train Epoch: 3 [290/1485 (20%)]\tLoss: 0.069900\n","Train Epoch: 3 [300/1485 (20%)]\tLoss: 0.059702\n","Train Epoch: 3 [310/1485 (21%)]\tLoss: 0.396213\n","Train Epoch: 3 [320/1485 (22%)]\tLoss: 0.500150\n","Train Epoch: 3 [330/1485 (22%)]\tLoss: 0.013971\n","Train Epoch: 3 [340/1485 (23%)]\tLoss: 0.064946\n","Train Epoch: 3 [350/1485 (24%)]\tLoss: 0.627620\n","Train Epoch: 3 [360/1485 (24%)]\tLoss: 0.019116\n","Train Epoch: 3 [370/1485 (25%)]\tLoss: 0.298778\n","Train Epoch: 3 [380/1485 (26%)]\tLoss: 0.342717\n","Train Epoch: 3 [390/1485 (26%)]\tLoss: 0.071175\n","Train Epoch: 3 [400/1485 (27%)]\tLoss: 0.000179\n","Train Epoch: 3 [410/1485 (28%)]\tLoss: 0.001442\n","Train Epoch: 3 [420/1485 (28%)]\tLoss: 0.249425\n","Train Epoch: 3 [430/1485 (29%)]\tLoss: 1.802811\n","Train Epoch: 3 [440/1485 (30%)]\tLoss: 0.182091\n","Train Epoch: 3 [450/1485 (30%)]\tLoss: 0.864894\n","Train Epoch: 3 [460/1485 (31%)]\tLoss: 0.050702\n","Train Epoch: 3 [470/1485 (32%)]\tLoss: 0.085270\n","Train Epoch: 3 [480/1485 (32%)]\tLoss: 0.014702\n","Train Epoch: 3 [490/1485 (33%)]\tLoss: 0.030070\n","Train Epoch: 3 [500/1485 (34%)]\tLoss: 0.002729\n","Train Epoch: 3 [510/1485 (34%)]\tLoss: 0.210685\n","Train Epoch: 3 [520/1485 (35%)]\tLoss: 0.013139\n","Train Epoch: 3 [530/1485 (36%)]\tLoss: 0.021761\n","Train Epoch: 3 [540/1485 (36%)]\tLoss: 0.057624\n","Train Epoch: 3 [550/1485 (37%)]\tLoss: 0.050735\n","Train Epoch: 3 [560/1485 (38%)]\tLoss: 0.151013\n","Train Epoch: 3 [570/1485 (38%)]\tLoss: 0.000892\n","Train Epoch: 3 [580/1485 (39%)]\tLoss: 0.227862\n","Train Epoch: 3 [590/1485 (40%)]\tLoss: 0.116500\n","Train Epoch: 3 [600/1485 (40%)]\tLoss: 0.193355\n","Train Epoch: 3 [610/1485 (41%)]\tLoss: 0.055285\n","Train Epoch: 3 [620/1485 (42%)]\tLoss: 0.750784\n","Train Epoch: 3 [630/1485 (42%)]\tLoss: 0.000213\n","Train Epoch: 3 [640/1485 (43%)]\tLoss: 0.007558\n","Train Epoch: 3 [650/1485 (44%)]\tLoss: 0.746750\n","Train Epoch: 3 [660/1485 (44%)]\tLoss: 1.101339\n","Train Epoch: 3 [670/1485 (45%)]\tLoss: 0.068456\n","Train Epoch: 3 [680/1485 (46%)]\tLoss: 0.173673\n","Train Epoch: 3 [690/1485 (46%)]\tLoss: 0.455208\n","Train Epoch: 3 [700/1485 (47%)]\tLoss: 0.085582\n","Train Epoch: 3 [710/1485 (48%)]\tLoss: 0.356365\n","Train Epoch: 3 [720/1485 (48%)]\tLoss: 0.085498\n","Train Epoch: 3 [730/1485 (49%)]\tLoss: 0.036428\n","Train Epoch: 3 [740/1485 (50%)]\tLoss: 0.312449\n","Train Epoch: 3 [750/1485 (51%)]\tLoss: 0.638315\n","Train Epoch: 3 [760/1485 (51%)]\tLoss: 0.130706\n","Train Epoch: 3 [770/1485 (52%)]\tLoss: 0.017809\n","Train Epoch: 3 [780/1485 (53%)]\tLoss: 0.199492\n","Train Epoch: 3 [790/1485 (53%)]\tLoss: 0.026342\n","Train Epoch: 3 [800/1485 (54%)]\tLoss: 0.101682\n","Train Epoch: 3 [810/1485 (55%)]\tLoss: 0.231725\n","Train Epoch: 3 [820/1485 (55%)]\tLoss: 0.097775\n","Train Epoch: 3 [830/1485 (56%)]\tLoss: 0.001197\n","Train Epoch: 3 [840/1485 (57%)]\tLoss: 0.089460\n","Train Epoch: 3 [850/1485 (57%)]\tLoss: 0.134864\n","Train Epoch: 3 [860/1485 (58%)]\tLoss: 0.017701\n","Train Epoch: 3 [870/1485 (59%)]\tLoss: 0.005710\n","Train Epoch: 3 [880/1485 (59%)]\tLoss: 0.195988\n","Train Epoch: 3 [890/1485 (60%)]\tLoss: 0.255226\n","Train Epoch: 3 [900/1485 (61%)]\tLoss: 0.056779\n","Train Epoch: 3 [910/1485 (61%)]\tLoss: 0.750942\n","Train Epoch: 3 [920/1485 (62%)]\tLoss: 0.374536\n","Train Epoch: 3 [930/1485 (63%)]\tLoss: 0.005233\n","Train Epoch: 3 [940/1485 (63%)]\tLoss: 0.973563\n","Train Epoch: 3 [950/1485 (64%)]\tLoss: 0.001100\n","Train Epoch: 3 [960/1485 (65%)]\tLoss: 0.010929\n","Train Epoch: 3 [970/1485 (65%)]\tLoss: 0.000040\n","Train Epoch: 3 [980/1485 (66%)]\tLoss: 0.597577\n","Train Epoch: 3 [990/1485 (67%)]\tLoss: 0.193234\n","Train Epoch: 3 [1000/1485 (67%)]\tLoss: 0.011576\n","Train Epoch: 3 [1010/1485 (68%)]\tLoss: 0.026458\n","Train Epoch: 3 [1020/1485 (69%)]\tLoss: 0.833917\n","Train Epoch: 3 [1030/1485 (69%)]\tLoss: 0.026155\n","Train Epoch: 3 [1040/1485 (70%)]\tLoss: 0.276232\n","Train Epoch: 3 [1050/1485 (71%)]\tLoss: 0.130628\n","Train Epoch: 3 [1060/1485 (71%)]\tLoss: 0.510254\n","Train Epoch: 3 [1070/1485 (72%)]\tLoss: 0.044487\n","Train Epoch: 3 [1080/1485 (73%)]\tLoss: 0.002472\n","Train Epoch: 3 [1090/1485 (73%)]\tLoss: 0.203394\n","Train Epoch: 3 [1100/1485 (74%)]\tLoss: 0.049959\n","Train Epoch: 3 [1110/1485 (75%)]\tLoss: 0.009458\n","Train Epoch: 3 [1120/1485 (75%)]\tLoss: 0.068257\n","Train Epoch: 3 [1130/1485 (76%)]\tLoss: 0.362462\n","Train Epoch: 3 [1140/1485 (77%)]\tLoss: 0.017719\n","Train Epoch: 3 [1150/1485 (77%)]\tLoss: 0.063590\n","Train Epoch: 3 [1160/1485 (78%)]\tLoss: 0.158934\n","Train Epoch: 3 [1170/1485 (79%)]\tLoss: 0.049067\n","Train Epoch: 3 [1180/1485 (79%)]\tLoss: 0.137397\n","Train Epoch: 3 [1190/1485 (80%)]\tLoss: 0.041595\n","Train Epoch: 3 [1200/1485 (81%)]\tLoss: 0.456399\n","Train Epoch: 3 [1210/1485 (81%)]\tLoss: 0.001008\n","Train Epoch: 3 [1220/1485 (82%)]\tLoss: 0.296302\n","Train Epoch: 3 [1230/1485 (83%)]\tLoss: 0.497193\n","Train Epoch: 3 [1240/1485 (84%)]\tLoss: 0.004917\n","Train Epoch: 3 [1250/1485 (84%)]\tLoss: 0.556046\n","Train Epoch: 3 [1260/1485 (85%)]\tLoss: 0.128761\n","Train Epoch: 3 [1270/1485 (86%)]\tLoss: 0.409793\n","Train Epoch: 3 [1280/1485 (86%)]\tLoss: 0.023908\n","Train Epoch: 3 [1290/1485 (87%)]\tLoss: 0.028305\n","Train Epoch: 3 [1300/1485 (88%)]\tLoss: 0.022016\n","Train Epoch: 3 [1310/1485 (88%)]\tLoss: 0.088851\n","Train Epoch: 3 [1320/1485 (89%)]\tLoss: 0.490672\n","Train Epoch: 3 [1330/1485 (90%)]\tLoss: 0.296569\n","Train Epoch: 3 [1340/1485 (90%)]\tLoss: 0.001019\n","Train Epoch: 3 [1350/1485 (91%)]\tLoss: 0.057505\n","Train Epoch: 3 [1360/1485 (92%)]\tLoss: 0.020297\n","Train Epoch: 3 [1370/1485 (92%)]\tLoss: 0.694143\n","Train Epoch: 3 [1380/1485 (93%)]\tLoss: 0.657160\n","Train Epoch: 3 [1390/1485 (94%)]\tLoss: 0.005818\n","Train Epoch: 3 [1400/1485 (94%)]\tLoss: 0.262881\n","Train Epoch: 3 [1410/1485 (95%)]\tLoss: 0.003501\n","Train Epoch: 3 [1420/1485 (96%)]\tLoss: 0.286286\n","Train Epoch: 3 [1430/1485 (96%)]\tLoss: 0.303617\n","Train Epoch: 3 [1440/1485 (97%)]\tLoss: 0.037474\n","Train Epoch: 3 [1450/1485 (98%)]\tLoss: 1.080585\n","Train Epoch: 3 [1460/1485 (98%)]\tLoss: 0.194277\n","Train Epoch: 3 [1470/1485 (99%)]\tLoss: 0.026767\n","Train Epoch: 3 [1480/1485 (100%)]\tLoss: 0.261098\n","[tensor(135.8353, device='cuda:0'), tensor(144.3386, device='cuda:0'), tensor(65.9725, device='cuda:0')]\n","\n","Train Epoch: 4 [10/1485 (1%)]\tLoss: 0.704955\n","Train Epoch: 4 [20/1485 (1%)]\tLoss: 0.397602\n","Train Epoch: 4 [30/1485 (2%)]\tLoss: 0.289319\n","Train Epoch: 4 [40/1485 (3%)]\tLoss: 0.000938\n","Train Epoch: 4 [50/1485 (3%)]\tLoss: 0.107490\n","Train Epoch: 4 [60/1485 (4%)]\tLoss: 0.179758\n","Train Epoch: 4 [70/1485 (5%)]\tLoss: 0.020365\n","Train Epoch: 4 [80/1485 (5%)]\tLoss: 0.233075\n","Train Epoch: 4 [90/1485 (6%)]\tLoss: 0.050579\n","Train Epoch: 4 [100/1485 (7%)]\tLoss: 0.383794\n","Train Epoch: 4 [110/1485 (7%)]\tLoss: 0.138522\n","Train Epoch: 4 [120/1485 (8%)]\tLoss: 0.278996\n","Train Epoch: 4 [130/1485 (9%)]\tLoss: 0.051923\n","Train Epoch: 4 [140/1485 (9%)]\tLoss: 0.000635\n","Train Epoch: 4 [150/1485 (10%)]\tLoss: 0.220541\n","Train Epoch: 4 [160/1485 (11%)]\tLoss: 0.139626\n","Train Epoch: 4 [170/1485 (11%)]\tLoss: 0.776748\n","Train Epoch: 4 [180/1485 (12%)]\tLoss: 0.221977\n","Train Epoch: 4 [190/1485 (13%)]\tLoss: 0.015073\n","Train Epoch: 4 [200/1485 (13%)]\tLoss: 0.000062\n","Train Epoch: 4 [210/1485 (14%)]\tLoss: 0.189103\n","Train Epoch: 4 [220/1485 (15%)]\tLoss: 0.018673\n","Train Epoch: 4 [230/1485 (15%)]\tLoss: 0.756862\n","Train Epoch: 4 [240/1485 (16%)]\tLoss: 0.559960\n","Train Epoch: 4 [250/1485 (17%)]\tLoss: 0.067151\n","Train Epoch: 4 [260/1485 (18%)]\tLoss: 0.277209\n","Train Epoch: 4 [270/1485 (18%)]\tLoss: 0.147049\n","Train Epoch: 4 [280/1485 (19%)]\tLoss: 0.048114\n","Train Epoch: 4 [290/1485 (20%)]\tLoss: 0.177064\n","Train Epoch: 4 [300/1485 (20%)]\tLoss: 0.355571\n","Train Epoch: 4 [310/1485 (21%)]\tLoss: 0.016848\n","Train Epoch: 4 [320/1485 (22%)]\tLoss: 0.048146\n","Train Epoch: 4 [330/1485 (22%)]\tLoss: 0.558703\n","Train Epoch: 4 [340/1485 (23%)]\tLoss: 0.286243\n","Train Epoch: 4 [350/1485 (24%)]\tLoss: 0.590437\n","Train Epoch: 4 [360/1485 (24%)]\tLoss: 0.049920\n","Train Epoch: 4 [370/1485 (25%)]\tLoss: 0.415070\n","Train Epoch: 4 [380/1485 (26%)]\tLoss: 0.020771\n","Train Epoch: 4 [390/1485 (26%)]\tLoss: 0.037891\n","Train Epoch: 4 [400/1485 (27%)]\tLoss: 0.186790\n","Train Epoch: 4 [410/1485 (28%)]\tLoss: 0.261691\n","Train Epoch: 4 [420/1485 (28%)]\tLoss: 1.028995\n","Train Epoch: 4 [430/1485 (29%)]\tLoss: 0.741406\n","Train Epoch: 4 [440/1485 (30%)]\tLoss: 1.012952\n","Train Epoch: 4 [450/1485 (30%)]\tLoss: 0.219265\n","Train Epoch: 4 [460/1485 (31%)]\tLoss: 0.097122\n","Train Epoch: 4 [470/1485 (32%)]\tLoss: 0.955913\n","Train Epoch: 4 [480/1485 (32%)]\tLoss: 0.004092\n","Train Epoch: 4 [490/1485 (33%)]\tLoss: 0.164098\n","Train Epoch: 4 [500/1485 (34%)]\tLoss: 0.653370\n","Train Epoch: 4 [510/1485 (34%)]\tLoss: 0.002202\n","Train Epoch: 4 [520/1485 (35%)]\tLoss: 0.084584\n","Train Epoch: 4 [530/1485 (36%)]\tLoss: 0.360383\n","Train Epoch: 4 [540/1485 (36%)]\tLoss: 0.578017\n","Train Epoch: 4 [550/1485 (37%)]\tLoss: 0.001751\n","Train Epoch: 4 [560/1485 (38%)]\tLoss: 0.697204\n","Train Epoch: 4 [570/1485 (38%)]\tLoss: 0.562157\n","Train Epoch: 4 [580/1485 (39%)]\tLoss: 0.521380\n","Train Epoch: 4 [590/1485 (40%)]\tLoss: 0.039577\n","Train Epoch: 4 [600/1485 (40%)]\tLoss: 0.006458\n","Train Epoch: 4 [610/1485 (41%)]\tLoss: 0.157914\n","Train Epoch: 4 [620/1485 (42%)]\tLoss: 0.192828\n","Train Epoch: 4 [630/1485 (42%)]\tLoss: 0.177957\n","Train Epoch: 4 [640/1485 (43%)]\tLoss: 0.136365\n","Train Epoch: 4 [650/1485 (44%)]\tLoss: 0.250598\n","Train Epoch: 4 [660/1485 (44%)]\tLoss: 0.055721\n","Train Epoch: 4 [670/1485 (45%)]\tLoss: 0.038247\n","Train Epoch: 4 [680/1485 (46%)]\tLoss: 0.276086\n","Train Epoch: 4 [690/1485 (46%)]\tLoss: 0.004549\n","Train Epoch: 4 [700/1485 (47%)]\tLoss: 0.002443\n","Train Epoch: 4 [710/1485 (48%)]\tLoss: 0.002809\n","Train Epoch: 4 [720/1485 (48%)]\tLoss: 0.010100\n","Train Epoch: 4 [730/1485 (49%)]\tLoss: 0.037878\n","Train Epoch: 4 [740/1485 (50%)]\tLoss: 0.077729\n","Train Epoch: 4 [750/1485 (51%)]\tLoss: 0.000960\n","Train Epoch: 4 [760/1485 (51%)]\tLoss: 0.050398\n","Train Epoch: 4 [770/1485 (52%)]\tLoss: 0.013223\n","Train Epoch: 4 [780/1485 (53%)]\tLoss: 0.331704\n","Train Epoch: 4 [790/1485 (53%)]\tLoss: 0.022563\n","Train Epoch: 4 [800/1485 (54%)]\tLoss: 0.313194\n","Train Epoch: 4 [810/1485 (55%)]\tLoss: 0.097715\n","Train Epoch: 4 [820/1485 (55%)]\tLoss: 0.295756\n","Train Epoch: 4 [830/1485 (56%)]\tLoss: 0.180063\n","Train Epoch: 4 [840/1485 (57%)]\tLoss: 0.087688\n","Train Epoch: 4 [850/1485 (57%)]\tLoss: 0.001369\n","Train Epoch: 4 [860/1485 (58%)]\tLoss: 0.068654\n","Train Epoch: 4 [870/1485 (59%)]\tLoss: 0.517334\n","Train Epoch: 4 [880/1485 (59%)]\tLoss: 0.371419\n","Train Epoch: 4 [890/1485 (60%)]\tLoss: 0.008866\n","Train Epoch: 4 [900/1485 (61%)]\tLoss: 0.255436\n","Train Epoch: 4 [910/1485 (61%)]\tLoss: 0.419408\n","Train Epoch: 4 [920/1485 (62%)]\tLoss: 0.004597\n","Train Epoch: 4 [930/1485 (63%)]\tLoss: 0.023355\n","Train Epoch: 4 [940/1485 (63%)]\tLoss: 0.002064\n","Train Epoch: 4 [950/1485 (64%)]\tLoss: 0.008213\n","Train Epoch: 4 [960/1485 (65%)]\tLoss: 0.007016\n","Train Epoch: 4 [970/1485 (65%)]\tLoss: 0.001363\n","Train Epoch: 4 [980/1485 (66%)]\tLoss: 0.225949\n","Train Epoch: 4 [990/1485 (67%)]\tLoss: 0.677448\n","Train Epoch: 4 [1000/1485 (67%)]\tLoss: 0.373187\n","Train Epoch: 4 [1010/1485 (68%)]\tLoss: 1.239451\n","Train Epoch: 4 [1020/1485 (69%)]\tLoss: 0.968865\n","Train Epoch: 4 [1030/1485 (69%)]\tLoss: 0.221692\n","Train Epoch: 4 [1040/1485 (70%)]\tLoss: 0.064312\n","Train Epoch: 4 [1050/1485 (71%)]\tLoss: 0.037930\n","Train Epoch: 4 [1060/1485 (71%)]\tLoss: 0.023025\n","Train Epoch: 4 [1070/1485 (72%)]\tLoss: 0.256346\n","Train Epoch: 4 [1080/1485 (73%)]\tLoss: 0.274961\n","Train Epoch: 4 [1090/1485 (73%)]\tLoss: 0.008671\n","Train Epoch: 4 [1100/1485 (74%)]\tLoss: 0.129310\n","Train Epoch: 4 [1110/1485 (75%)]\tLoss: 0.265794\n","Train Epoch: 4 [1120/1485 (75%)]\tLoss: 0.118320\n","Train Epoch: 4 [1130/1485 (76%)]\tLoss: 0.851350\n","Train Epoch: 4 [1140/1485 (77%)]\tLoss: 0.004040\n","Train Epoch: 4 [1150/1485 (77%)]\tLoss: 0.343280\n","Train Epoch: 4 [1160/1485 (78%)]\tLoss: 0.279056\n","Train Epoch: 4 [1170/1485 (79%)]\tLoss: 0.113965\n","Train Epoch: 4 [1180/1485 (79%)]\tLoss: 0.033294\n","Train Epoch: 4 [1190/1485 (80%)]\tLoss: 0.064019\n","Train Epoch: 4 [1200/1485 (81%)]\tLoss: 0.067329\n","Train Epoch: 4 [1210/1485 (81%)]\tLoss: 0.094229\n","Train Epoch: 4 [1220/1485 (82%)]\tLoss: 0.037848\n","Train Epoch: 4 [1230/1485 (83%)]\tLoss: 0.252095\n","Train Epoch: 4 [1240/1485 (84%)]\tLoss: 0.346184\n","Train Epoch: 4 [1250/1485 (84%)]\tLoss: 0.239499\n","Train Epoch: 4 [1260/1485 (85%)]\tLoss: 0.840074\n","Train Epoch: 4 [1270/1485 (86%)]\tLoss: 0.323853\n","Train Epoch: 4 [1280/1485 (86%)]\tLoss: 0.001555\n","Train Epoch: 4 [1290/1485 (87%)]\tLoss: 0.520095\n","Train Epoch: 4 [1300/1485 (88%)]\tLoss: 0.216605\n","Train Epoch: 4 [1310/1485 (88%)]\tLoss: 0.200219\n","Train Epoch: 4 [1320/1485 (89%)]\tLoss: 0.225260\n","Train Epoch: 4 [1330/1485 (90%)]\tLoss: 0.669519\n","Train Epoch: 4 [1340/1485 (90%)]\tLoss: 0.090941\n","Train Epoch: 4 [1350/1485 (91%)]\tLoss: 0.115696\n","Train Epoch: 4 [1360/1485 (92%)]\tLoss: 0.874779\n","Train Epoch: 4 [1370/1485 (92%)]\tLoss: 0.198203\n","Train Epoch: 4 [1380/1485 (93%)]\tLoss: 0.067487\n","Train Epoch: 4 [1390/1485 (94%)]\tLoss: 0.684936\n","Train Epoch: 4 [1400/1485 (94%)]\tLoss: 0.022657\n","Train Epoch: 4 [1410/1485 (95%)]\tLoss: 0.038972\n","Train Epoch: 4 [1420/1485 (96%)]\tLoss: 0.037794\n","Train Epoch: 4 [1430/1485 (96%)]\tLoss: 0.115766\n","Train Epoch: 4 [1440/1485 (97%)]\tLoss: 0.295366\n","Train Epoch: 4 [1450/1485 (98%)]\tLoss: 0.622858\n","Train Epoch: 4 [1460/1485 (98%)]\tLoss: 0.697680\n","Train Epoch: 4 [1470/1485 (99%)]\tLoss: 0.056608\n","Train Epoch: 4 [1480/1485 (100%)]\tLoss: 0.000489\n","[tensor(135.8353, device='cuda:0'), tensor(144.3386, device='cuda:0'), tensor(65.9725, device='cuda:0'), tensor(69.7719, device='cuda:0')]\n","\n","Train Epoch: 5 [10/1485 (1%)]\tLoss: 0.021852\n","Train Epoch: 5 [20/1485 (1%)]\tLoss: 0.039202\n","Train Epoch: 5 [30/1485 (2%)]\tLoss: 0.318659\n","Train Epoch: 5 [40/1485 (3%)]\tLoss: 0.996037\n","Train Epoch: 5 [50/1485 (3%)]\tLoss: 0.006880\n","Train Epoch: 5 [60/1485 (4%)]\tLoss: 0.261423\n","Train Epoch: 5 [70/1485 (5%)]\tLoss: 0.220564\n","Train Epoch: 5 [80/1485 (5%)]\tLoss: 0.005048\n","Train Epoch: 5 [90/1485 (6%)]\tLoss: 0.041586\n","Train Epoch: 5 [100/1485 (7%)]\tLoss: 0.004263\n","Train Epoch: 5 [110/1485 (7%)]\tLoss: 0.301051\n","Train Epoch: 5 [120/1485 (8%)]\tLoss: 0.435948\n","Train Epoch: 5 [130/1485 (9%)]\tLoss: 0.190422\n","Train Epoch: 5 [140/1485 (9%)]\tLoss: 0.046772\n","Train Epoch: 5 [150/1485 (10%)]\tLoss: 0.114260\n","Train Epoch: 5 [160/1485 (11%)]\tLoss: 0.011086\n","Train Epoch: 5 [170/1485 (11%)]\tLoss: 0.898462\n","Train Epoch: 5 [180/1485 (12%)]\tLoss: 0.002272\n","Train Epoch: 5 [190/1485 (13%)]\tLoss: 0.090473\n","Train Epoch: 5 [200/1485 (13%)]\tLoss: 0.029606\n","Train Epoch: 5 [210/1485 (14%)]\tLoss: 0.026407\n","Train Epoch: 5 [220/1485 (15%)]\tLoss: 0.013459\n","Train Epoch: 5 [230/1485 (15%)]\tLoss: 0.106233\n","Train Epoch: 5 [240/1485 (16%)]\tLoss: 0.371674\n","Train Epoch: 5 [250/1485 (17%)]\tLoss: 0.371255\n","Train Epoch: 5 [260/1485 (18%)]\tLoss: 0.161620\n","Train Epoch: 5 [270/1485 (18%)]\tLoss: 0.392747\n","Train Epoch: 5 [280/1485 (19%)]\tLoss: 0.411009\n","Train Epoch: 5 [290/1485 (20%)]\tLoss: 0.630280\n","Train Epoch: 5 [300/1485 (20%)]\tLoss: 0.015779\n","Train Epoch: 5 [310/1485 (21%)]\tLoss: 0.092531\n","Train Epoch: 5 [320/1485 (22%)]\tLoss: 0.272561\n","Train Epoch: 5 [330/1485 (22%)]\tLoss: 0.230494\n","Train Epoch: 5 [340/1485 (23%)]\tLoss: 0.005946\n","Train Epoch: 5 [350/1485 (24%)]\tLoss: 0.014122\n","Train Epoch: 5 [360/1485 (24%)]\tLoss: 0.000039\n","Train Epoch: 5 [370/1485 (25%)]\tLoss: 0.635261\n","Train Epoch: 5 [380/1485 (26%)]\tLoss: 0.008182\n","Train Epoch: 5 [390/1485 (26%)]\tLoss: 0.018059\n","Train Epoch: 5 [400/1485 (27%)]\tLoss: 0.075725\n","Train Epoch: 5 [410/1485 (28%)]\tLoss: 0.406927\n","Train Epoch: 5 [420/1485 (28%)]\tLoss: 0.013440\n","Train Epoch: 5 [430/1485 (29%)]\tLoss: 0.254510\n","Train Epoch: 5 [440/1485 (30%)]\tLoss: 0.000028\n","Train Epoch: 5 [450/1485 (30%)]\tLoss: 0.038394\n","Train Epoch: 5 [460/1485 (31%)]\tLoss: 0.208394\n","Train Epoch: 5 [470/1485 (32%)]\tLoss: 0.145814\n","Train Epoch: 5 [480/1485 (32%)]\tLoss: 0.004506\n","Train Epoch: 5 [490/1485 (33%)]\tLoss: 0.283970\n","Train Epoch: 5 [500/1485 (34%)]\tLoss: 0.005823\n","Train Epoch: 5 [510/1485 (34%)]\tLoss: 0.512452\n","Train Epoch: 5 [520/1485 (35%)]\tLoss: 0.581137\n","Train Epoch: 5 [530/1485 (36%)]\tLoss: 0.006740\n","Train Epoch: 5 [540/1485 (36%)]\tLoss: 0.028819\n","Train Epoch: 5 [550/1485 (37%)]\tLoss: 0.760656\n","Train Epoch: 5 [560/1485 (38%)]\tLoss: 0.682908\n","Train Epoch: 5 [570/1485 (38%)]\tLoss: 0.061584\n","Train Epoch: 5 [580/1485 (39%)]\tLoss: 0.000942\n","Train Epoch: 5 [590/1485 (40%)]\tLoss: 0.052625\n","Train Epoch: 5 [600/1485 (40%)]\tLoss: 0.005733\n","Train Epoch: 5 [610/1485 (41%)]\tLoss: 1.166952\n","Train Epoch: 5 [620/1485 (42%)]\tLoss: 0.028210\n","Train Epoch: 5 [630/1485 (42%)]\tLoss: 0.856640\n","Train Epoch: 5 [640/1485 (43%)]\tLoss: 0.053438\n","Train Epoch: 5 [650/1485 (44%)]\tLoss: 0.029059\n","Train Epoch: 5 [660/1485 (44%)]\tLoss: 0.030781\n","Train Epoch: 5 [670/1485 (45%)]\tLoss: 0.773600\n","Train Epoch: 5 [680/1485 (46%)]\tLoss: 0.001209\n","Train Epoch: 5 [690/1485 (46%)]\tLoss: 0.290911\n","Train Epoch: 5 [700/1485 (47%)]\tLoss: 0.156580\n","Train Epoch: 5 [710/1485 (48%)]\tLoss: 0.221242\n","Train Epoch: 5 [720/1485 (48%)]\tLoss: 0.213616\n","Train Epoch: 5 [730/1485 (49%)]\tLoss: 0.003696\n","Train Epoch: 5 [740/1485 (50%)]\tLoss: 0.001011\n","Train Epoch: 5 [750/1485 (51%)]\tLoss: 0.203512\n","Train Epoch: 5 [760/1485 (51%)]\tLoss: 0.209820\n","Train Epoch: 5 [770/1485 (52%)]\tLoss: 0.018863\n","Train Epoch: 5 [780/1485 (53%)]\tLoss: 0.158196\n","Train Epoch: 5 [790/1485 (53%)]\tLoss: 0.677409\n","Train Epoch: 5 [800/1485 (54%)]\tLoss: 1.407070\n","Train Epoch: 5 [810/1485 (55%)]\tLoss: 0.007320\n","Train Epoch: 5 [820/1485 (55%)]\tLoss: 0.005831\n","Train Epoch: 5 [830/1485 (56%)]\tLoss: 0.012548\n","Train Epoch: 5 [840/1485 (57%)]\tLoss: 0.032531\n","Train Epoch: 5 [850/1485 (57%)]\tLoss: 1.046167\n","Train Epoch: 5 [860/1485 (58%)]\tLoss: 0.142128\n","Train Epoch: 5 [870/1485 (59%)]\tLoss: 0.008031\n","Train Epoch: 5 [880/1485 (59%)]\tLoss: 0.137303\n","Train Epoch: 5 [890/1485 (60%)]\tLoss: 0.002829\n","Train Epoch: 5 [900/1485 (61%)]\tLoss: 0.736034\n","Train Epoch: 5 [910/1485 (61%)]\tLoss: 0.397208\n","Train Epoch: 5 [920/1485 (62%)]\tLoss: 0.335840\n","Train Epoch: 5 [930/1485 (63%)]\tLoss: 0.580682\n","Train Epoch: 5 [940/1485 (63%)]\tLoss: 0.200735\n","Train Epoch: 5 [950/1485 (64%)]\tLoss: 0.368145\n","Train Epoch: 5 [960/1485 (65%)]\tLoss: 0.072363\n","Train Epoch: 5 [970/1485 (65%)]\tLoss: 1.122549\n","Train Epoch: 5 [980/1485 (66%)]\tLoss: 0.864270\n","Train Epoch: 5 [990/1485 (67%)]\tLoss: 0.003732\n","Train Epoch: 5 [1000/1485 (67%)]\tLoss: 0.538122\n","Train Epoch: 5 [1010/1485 (68%)]\tLoss: 0.247108\n","Train Epoch: 5 [1020/1485 (69%)]\tLoss: 0.000771\n","Train Epoch: 5 [1030/1485 (69%)]\tLoss: 0.573794\n","Train Epoch: 5 [1040/1485 (70%)]\tLoss: 0.003345\n","Train Epoch: 5 [1050/1485 (71%)]\tLoss: 0.041395\n","Train Epoch: 5 [1060/1485 (71%)]\tLoss: 0.000861\n","Train Epoch: 5 [1070/1485 (72%)]\tLoss: 0.037772\n","Train Epoch: 5 [1080/1485 (73%)]\tLoss: 0.002852\n","Train Epoch: 5 [1090/1485 (73%)]\tLoss: 0.486287\n","Train Epoch: 5 [1100/1485 (74%)]\tLoss: 0.277853\n","Train Epoch: 5 [1110/1485 (75%)]\tLoss: 0.082413\n","Train Epoch: 5 [1120/1485 (75%)]\tLoss: 0.000365\n","Train Epoch: 5 [1130/1485 (76%)]\tLoss: 0.206392\n","Train Epoch: 5 [1140/1485 (77%)]\tLoss: 1.060649\n","Train Epoch: 5 [1150/1485 (77%)]\tLoss: 0.145282\n","Train Epoch: 5 [1160/1485 (78%)]\tLoss: 0.039800\n","Train Epoch: 5 [1170/1485 (79%)]\tLoss: 0.006438\n","Train Epoch: 5 [1180/1485 (79%)]\tLoss: 0.093140\n","Train Epoch: 5 [1190/1485 (80%)]\tLoss: 0.361908\n","Train Epoch: 5 [1200/1485 (81%)]\tLoss: 0.909863\n","Train Epoch: 5 [1210/1485 (81%)]\tLoss: 0.248919\n","Train Epoch: 5 [1220/1485 (82%)]\tLoss: 0.001852\n","Train Epoch: 5 [1230/1485 (83%)]\tLoss: 0.003355\n","Train Epoch: 5 [1240/1485 (84%)]\tLoss: 0.405632\n","Train Epoch: 5 [1250/1485 (84%)]\tLoss: 0.725862\n","Train Epoch: 5 [1260/1485 (85%)]\tLoss: 0.677971\n","Train Epoch: 5 [1270/1485 (86%)]\tLoss: 0.048211\n","Train Epoch: 5 [1280/1485 (86%)]\tLoss: 0.169697\n","Train Epoch: 5 [1290/1485 (87%)]\tLoss: 0.029019\n","Train Epoch: 5 [1300/1485 (88%)]\tLoss: 0.840587\n","Train Epoch: 5 [1310/1485 (88%)]\tLoss: 0.000093\n","Train Epoch: 5 [1320/1485 (89%)]\tLoss: 0.329638\n","Train Epoch: 5 [1330/1485 (90%)]\tLoss: 0.015661\n","Train Epoch: 5 [1340/1485 (90%)]\tLoss: 0.176996\n","Train Epoch: 5 [1350/1485 (91%)]\tLoss: 0.144741\n","Train Epoch: 5 [1360/1485 (92%)]\tLoss: 0.147437\n","Train Epoch: 5 [1370/1485 (92%)]\tLoss: 0.000325\n","Train Epoch: 5 [1380/1485 (93%)]\tLoss: 0.004188\n","Train Epoch: 5 [1390/1485 (94%)]\tLoss: 0.001373\n","Train Epoch: 5 [1400/1485 (94%)]\tLoss: 0.024603\n","Train Epoch: 5 [1410/1485 (95%)]\tLoss: 0.042397\n","Train Epoch: 5 [1420/1485 (96%)]\tLoss: 0.437945\n","Train Epoch: 5 [1430/1485 (96%)]\tLoss: 0.000166\n","Train Epoch: 5 [1440/1485 (97%)]\tLoss: 0.049643\n","Train Epoch: 5 [1450/1485 (98%)]\tLoss: 0.275358\n","Train Epoch: 5 [1460/1485 (98%)]\tLoss: 0.940518\n","Train Epoch: 5 [1470/1485 (99%)]\tLoss: 0.732568\n","Train Epoch: 5 [1480/1485 (100%)]\tLoss: 0.009854\n","[tensor(135.8353, device='cuda:0'), tensor(144.3386, device='cuda:0'), tensor(65.9725, device='cuda:0'), tensor(69.7719, device='cuda:0'), tensor(41.3994, device='cuda:0')]\n","\n","Train Epoch: 6 [10/1485 (1%)]\tLoss: 0.001195\n","Train Epoch: 6 [20/1485 (1%)]\tLoss: 0.818899\n","Train Epoch: 6 [30/1485 (2%)]\tLoss: 1.409999\n","Train Epoch: 6 [40/1485 (3%)]\tLoss: 0.000109\n","Train Epoch: 6 [50/1485 (3%)]\tLoss: 0.452143\n","Train Epoch: 6 [60/1485 (4%)]\tLoss: 0.040713\n","Train Epoch: 6 [70/1485 (5%)]\tLoss: 0.445446\n","Train Epoch: 6 [80/1485 (5%)]\tLoss: 0.547264\n","Train Epoch: 6 [90/1485 (6%)]\tLoss: 0.238834\n","Train Epoch: 6 [100/1485 (7%)]\tLoss: 0.238537\n","Train Epoch: 6 [110/1485 (7%)]\tLoss: 0.021333\n","Train Epoch: 6 [120/1485 (8%)]\tLoss: 0.029360\n","Train Epoch: 6 [130/1485 (9%)]\tLoss: 1.068189\n","Train Epoch: 6 [140/1485 (9%)]\tLoss: 0.652428\n","Train Epoch: 6 [150/1485 (10%)]\tLoss: 0.879426\n","Train Epoch: 6 [160/1485 (11%)]\tLoss: 0.706327\n","Train Epoch: 6 [170/1485 (11%)]\tLoss: 0.538295\n","Train Epoch: 6 [180/1485 (12%)]\tLoss: 0.021808\n","Train Epoch: 6 [190/1485 (13%)]\tLoss: 0.137022\n","Train Epoch: 6 [200/1485 (13%)]\tLoss: 0.018767\n","Train Epoch: 6 [210/1485 (14%)]\tLoss: 0.000720\n","Train Epoch: 6 [220/1485 (15%)]\tLoss: 0.014283\n","Train Epoch: 6 [230/1485 (15%)]\tLoss: 0.019005\n","Train Epoch: 6 [240/1485 (16%)]\tLoss: 0.522680\n","Train Epoch: 6 [250/1485 (17%)]\tLoss: 0.032034\n","Train Epoch: 6 [260/1485 (18%)]\tLoss: 0.491183\n","Train Epoch: 6 [270/1485 (18%)]\tLoss: 0.003596\n","Train Epoch: 6 [280/1485 (19%)]\tLoss: 0.007630\n","Train Epoch: 6 [290/1485 (20%)]\tLoss: 0.534094\n","Train Epoch: 6 [300/1485 (20%)]\tLoss: 0.974796\n","Train Epoch: 6 [310/1485 (21%)]\tLoss: 0.310640\n","Train Epoch: 6 [320/1485 (22%)]\tLoss: 0.502377\n","Train Epoch: 6 [330/1485 (22%)]\tLoss: 0.007124\n","Train Epoch: 6 [340/1485 (23%)]\tLoss: 0.005172\n","Train Epoch: 6 [350/1485 (24%)]\tLoss: 0.012501\n","Train Epoch: 6 [360/1485 (24%)]\tLoss: 0.319832\n","Train Epoch: 6 [370/1485 (25%)]\tLoss: 0.015154\n","Train Epoch: 6 [380/1485 (26%)]\tLoss: 0.042973\n","Train Epoch: 6 [390/1485 (26%)]\tLoss: 0.737924\n","Train Epoch: 6 [400/1485 (27%)]\tLoss: 1.236077\n","Train Epoch: 6 [410/1485 (28%)]\tLoss: 0.134555\n","Train Epoch: 6 [420/1485 (28%)]\tLoss: 0.545686\n","Train Epoch: 6 [430/1485 (29%)]\tLoss: 0.018333\n","Train Epoch: 6 [440/1485 (30%)]\tLoss: 0.469234\n","Train Epoch: 6 [450/1485 (30%)]\tLoss: 0.898538\n","Train Epoch: 6 [460/1485 (31%)]\tLoss: 0.038063\n","Train Epoch: 6 [470/1485 (32%)]\tLoss: 0.862893\n","Train Epoch: 6 [480/1485 (32%)]\tLoss: 0.694489\n","Train Epoch: 6 [490/1485 (33%)]\tLoss: 0.252645\n","Train Epoch: 6 [500/1485 (34%)]\tLoss: 0.138822\n","Train Epoch: 6 [510/1485 (34%)]\tLoss: 1.076583\n","Train Epoch: 6 [520/1485 (35%)]\tLoss: 0.022161\n","Train Epoch: 6 [530/1485 (36%)]\tLoss: 0.048630\n","Train Epoch: 6 [540/1485 (36%)]\tLoss: 0.001096\n","Train Epoch: 6 [550/1485 (37%)]\tLoss: 0.688033\n","Train Epoch: 6 [560/1485 (38%)]\tLoss: 0.010114\n","Train Epoch: 6 [570/1485 (38%)]\tLoss: 0.043748\n","Train Epoch: 6 [580/1485 (39%)]\tLoss: 0.056297\n","Train Epoch: 6 [590/1485 (40%)]\tLoss: 0.648784\n","Train Epoch: 6 [600/1485 (40%)]\tLoss: 0.103462\n","Train Epoch: 6 [610/1485 (41%)]\tLoss: 0.007335\n","Train Epoch: 6 [620/1485 (42%)]\tLoss: 0.128799\n","Train Epoch: 6 [630/1485 (42%)]\tLoss: 0.052862\n","Train Epoch: 6 [640/1485 (43%)]\tLoss: 0.012092\n","Train Epoch: 6 [650/1485 (44%)]\tLoss: 0.017936\n","Train Epoch: 6 [660/1485 (44%)]\tLoss: 0.107594\n","Train Epoch: 6 [670/1485 (45%)]\tLoss: 1.043350\n","Train Epoch: 6 [680/1485 (46%)]\tLoss: 0.240057\n","Train Epoch: 6 [690/1485 (46%)]\tLoss: 0.000401\n","Train Epoch: 6 [700/1485 (47%)]\tLoss: 0.014936\n","Train Epoch: 6 [710/1485 (48%)]\tLoss: 0.303603\n","Train Epoch: 6 [720/1485 (48%)]\tLoss: 0.008564\n","Train Epoch: 6 [730/1485 (49%)]\tLoss: 0.222291\n","Train Epoch: 6 [740/1485 (50%)]\tLoss: 0.472633\n","Train Epoch: 6 [750/1485 (51%)]\tLoss: 0.208377\n","Train Epoch: 6 [760/1485 (51%)]\tLoss: 0.785515\n","Train Epoch: 6 [770/1485 (52%)]\tLoss: 0.004880\n","Train Epoch: 6 [780/1485 (53%)]\tLoss: 0.052188\n","Train Epoch: 6 [790/1485 (53%)]\tLoss: 0.046104\n","Train Epoch: 6 [800/1485 (54%)]\tLoss: 0.298226\n","Train Epoch: 6 [810/1485 (55%)]\tLoss: 0.472573\n","Train Epoch: 6 [820/1485 (55%)]\tLoss: 0.131280\n","Train Epoch: 6 [830/1485 (56%)]\tLoss: 0.008101\n","Train Epoch: 6 [840/1485 (57%)]\tLoss: 0.067125\n","Train Epoch: 6 [850/1485 (57%)]\tLoss: 0.120189\n","Train Epoch: 6 [860/1485 (58%)]\tLoss: 0.205090\n","Train Epoch: 6 [870/1485 (59%)]\tLoss: 0.060945\n","Train Epoch: 6 [880/1485 (59%)]\tLoss: 0.101956\n","Train Epoch: 6 [890/1485 (60%)]\tLoss: 0.147663\n","Train Epoch: 6 [900/1485 (61%)]\tLoss: 0.001061\n","Train Epoch: 6 [910/1485 (61%)]\tLoss: 0.843972\n","Train Epoch: 6 [920/1485 (62%)]\tLoss: 0.010656\n","Train Epoch: 6 [930/1485 (63%)]\tLoss: 0.130724\n","Train Epoch: 6 [940/1485 (63%)]\tLoss: 0.062258\n","Train Epoch: 6 [950/1485 (64%)]\tLoss: 0.057828\n","Train Epoch: 6 [960/1485 (65%)]\tLoss: 0.022313\n","Train Epoch: 6 [970/1485 (65%)]\tLoss: 0.021865\n","Train Epoch: 6 [980/1485 (66%)]\tLoss: 0.009161\n","Train Epoch: 6 [990/1485 (67%)]\tLoss: 0.208252\n","Train Epoch: 6 [1000/1485 (67%)]\tLoss: 0.052503\n","Train Epoch: 6 [1010/1485 (68%)]\tLoss: 0.333031\n","Train Epoch: 6 [1020/1485 (69%)]\tLoss: 0.004171\n","Train Epoch: 6 [1030/1485 (69%)]\tLoss: 0.257548\n","Train Epoch: 6 [1040/1485 (70%)]\tLoss: 0.043405\n","Train Epoch: 6 [1050/1485 (71%)]\tLoss: 0.953881\n","Train Epoch: 6 [1060/1485 (71%)]\tLoss: 0.048920\n","Train Epoch: 6 [1070/1485 (72%)]\tLoss: 0.009043\n","Train Epoch: 6 [1080/1485 (73%)]\tLoss: 0.002027\n","Train Epoch: 6 [1090/1485 (73%)]\tLoss: 0.007719\n","Train Epoch: 6 [1100/1485 (74%)]\tLoss: 0.187310\n","Train Epoch: 6 [1110/1485 (75%)]\tLoss: 0.076683\n","Train Epoch: 6 [1120/1485 (75%)]\tLoss: 0.024492\n","Train Epoch: 6 [1130/1485 (76%)]\tLoss: 0.229971\n","Train Epoch: 6 [1140/1485 (77%)]\tLoss: 0.411252\n","Train Epoch: 6 [1150/1485 (77%)]\tLoss: 0.023868\n","Train Epoch: 6 [1160/1485 (78%)]\tLoss: 0.005490\n","Train Epoch: 6 [1170/1485 (79%)]\tLoss: 0.016259\n","Train Epoch: 6 [1180/1485 (79%)]\tLoss: 1.079632\n","Train Epoch: 6 [1190/1485 (80%)]\tLoss: 0.118859\n","Train Epoch: 6 [1200/1485 (81%)]\tLoss: 0.456752\n","Train Epoch: 6 [1210/1485 (81%)]\tLoss: 0.014641\n","Train Epoch: 6 [1220/1485 (82%)]\tLoss: 0.557758\n","Train Epoch: 6 [1230/1485 (83%)]\tLoss: 0.009922\n","Train Epoch: 6 [1240/1485 (84%)]\tLoss: 0.088338\n","Train Epoch: 6 [1250/1485 (84%)]\tLoss: 0.206519\n","Train Epoch: 6 [1260/1485 (85%)]\tLoss: 0.024457\n","Train Epoch: 6 [1270/1485 (86%)]\tLoss: 0.002847\n","Train Epoch: 6 [1280/1485 (86%)]\tLoss: 0.284207\n","Train Epoch: 6 [1290/1485 (87%)]\tLoss: 0.519700\n","Train Epoch: 6 [1300/1485 (88%)]\tLoss: 0.002764\n","Train Epoch: 6 [1310/1485 (88%)]\tLoss: 0.976888\n","Train Epoch: 6 [1320/1485 (89%)]\tLoss: 0.187502\n","Train Epoch: 6 [1330/1485 (90%)]\tLoss: 0.023275\n","Train Epoch: 6 [1340/1485 (90%)]\tLoss: 1.060278\n","Train Epoch: 6 [1350/1485 (91%)]\tLoss: 0.441708\n","Train Epoch: 6 [1360/1485 (92%)]\tLoss: 0.038013\n","Train Epoch: 6 [1370/1485 (92%)]\tLoss: 0.498856\n","Train Epoch: 6 [1380/1485 (93%)]\tLoss: 0.674402\n","Train Epoch: 6 [1390/1485 (94%)]\tLoss: 0.183581\n","Train Epoch: 6 [1400/1485 (94%)]\tLoss: 0.976167\n","Train Epoch: 6 [1410/1485 (95%)]\tLoss: 0.229613\n","Train Epoch: 6 [1420/1485 (96%)]\tLoss: 0.000974\n","Train Epoch: 6 [1430/1485 (96%)]\tLoss: 0.181255\n","Train Epoch: 6 [1440/1485 (97%)]\tLoss: 0.000205\n","Train Epoch: 6 [1450/1485 (98%)]\tLoss: 0.045000\n","Train Epoch: 6 [1460/1485 (98%)]\tLoss: 0.042090\n","Train Epoch: 6 [1470/1485 (99%)]\tLoss: 0.002599\n","Train Epoch: 6 [1480/1485 (100%)]\tLoss: 0.363019\n","[tensor(135.8353, device='cuda:0'), tensor(144.3386, device='cuda:0'), tensor(65.9725, device='cuda:0'), tensor(69.7719, device='cuda:0'), tensor(41.3994, device='cuda:0'), tensor(46.8058, device='cuda:0')]\n","\n","Train Epoch: 7 [10/1485 (1%)]\tLoss: 0.000585\n","Train Epoch: 7 [20/1485 (1%)]\tLoss: 0.231223\n","Train Epoch: 7 [30/1485 (2%)]\tLoss: 0.420230\n","Train Epoch: 7 [40/1485 (3%)]\tLoss: 0.234179\n","Train Epoch: 7 [50/1485 (3%)]\tLoss: 1.244569\n","Train Epoch: 7 [60/1485 (4%)]\tLoss: 0.019705\n","Train Epoch: 7 [70/1485 (5%)]\tLoss: 0.237046\n","Train Epoch: 7 [80/1485 (5%)]\tLoss: 0.533066\n","Train Epoch: 7 [90/1485 (6%)]\tLoss: 0.031265\n","Train Epoch: 7 [100/1485 (7%)]\tLoss: 0.004899\n","Train Epoch: 7 [110/1485 (7%)]\tLoss: 0.048882\n","Train Epoch: 7 [120/1485 (8%)]\tLoss: 0.193810\n","Train Epoch: 7 [130/1485 (9%)]\tLoss: 0.875848\n","Train Epoch: 7 [140/1485 (9%)]\tLoss: 0.001962\n","Train Epoch: 7 [150/1485 (10%)]\tLoss: 0.070725\n","Train Epoch: 7 [160/1485 (11%)]\tLoss: 0.030438\n","Train Epoch: 7 [170/1485 (11%)]\tLoss: 0.777391\n","Train Epoch: 7 [180/1485 (12%)]\tLoss: 0.025893\n","Train Epoch: 7 [190/1485 (13%)]\tLoss: 0.000372\n","Train Epoch: 7 [200/1485 (13%)]\tLoss: 0.294833\n","Train Epoch: 7 [210/1485 (14%)]\tLoss: 0.001389\n","Train Epoch: 7 [220/1485 (15%)]\tLoss: 0.703143\n","Train Epoch: 7 [230/1485 (15%)]\tLoss: 0.019628\n","Train Epoch: 7 [240/1485 (16%)]\tLoss: 0.180589\n","Train Epoch: 7 [250/1485 (17%)]\tLoss: 0.017985\n","Train Epoch: 7 [260/1485 (18%)]\tLoss: 0.751643\n","Train Epoch: 7 [270/1485 (18%)]\tLoss: 0.109948\n","Train Epoch: 7 [280/1485 (19%)]\tLoss: 0.000077\n","Train Epoch: 7 [290/1485 (20%)]\tLoss: 0.003616\n","Train Epoch: 7 [300/1485 (20%)]\tLoss: 0.042722\n","Train Epoch: 7 [310/1485 (21%)]\tLoss: 0.000679\n","Train Epoch: 7 [320/1485 (22%)]\tLoss: 0.387940\n","Train Epoch: 7 [330/1485 (22%)]\tLoss: 0.012674\n","Train Epoch: 7 [340/1485 (23%)]\tLoss: 0.749098\n","Train Epoch: 7 [350/1485 (24%)]\tLoss: 0.003754\n","Train Epoch: 7 [360/1485 (24%)]\tLoss: 0.442083\n","Train Epoch: 7 [370/1485 (25%)]\tLoss: 0.156265\n","Train Epoch: 7 [380/1485 (26%)]\tLoss: 0.279923\n","Train Epoch: 7 [390/1485 (26%)]\tLoss: 0.004907\n","Train Epoch: 7 [400/1485 (27%)]\tLoss: 0.278242\n","Train Epoch: 7 [410/1485 (28%)]\tLoss: 0.028406\n","Train Epoch: 7 [420/1485 (28%)]\tLoss: 0.645255\n","Train Epoch: 7 [430/1485 (29%)]\tLoss: 0.031548\n","Train Epoch: 7 [440/1485 (30%)]\tLoss: 0.007431\n","Train Epoch: 7 [450/1485 (30%)]\tLoss: 0.000233\n","Train Epoch: 7 [460/1485 (31%)]\tLoss: 0.160797\n","Train Epoch: 7 [470/1485 (32%)]\tLoss: 0.001933\n","Train Epoch: 7 [480/1485 (32%)]\tLoss: 0.004565\n","Train Epoch: 7 [490/1485 (33%)]\tLoss: 1.900919\n","Train Epoch: 7 [500/1485 (34%)]\tLoss: 0.469329\n","Train Epoch: 7 [510/1485 (34%)]\tLoss: 0.455123\n","Train Epoch: 7 [520/1485 (35%)]\tLoss: 0.452394\n","Train Epoch: 7 [530/1485 (36%)]\tLoss: 0.100119\n","Train Epoch: 7 [540/1485 (36%)]\tLoss: 0.919387\n","Train Epoch: 7 [550/1485 (37%)]\tLoss: 0.315255\n","Train Epoch: 7 [560/1485 (38%)]\tLoss: 0.031491\n","Train Epoch: 7 [570/1485 (38%)]\tLoss: 0.005743\n","Train Epoch: 7 [580/1485 (39%)]\tLoss: 0.244840\n","Train Epoch: 7 [590/1485 (40%)]\tLoss: 0.008197\n","Train Epoch: 7 [600/1485 (40%)]\tLoss: 0.351250\n","Train Epoch: 7 [610/1485 (41%)]\tLoss: 0.228981\n","Train Epoch: 7 [620/1485 (42%)]\tLoss: 0.597030\n","Train Epoch: 7 [630/1485 (42%)]\tLoss: 0.159811\n","Train Epoch: 7 [640/1485 (43%)]\tLoss: 0.025615\n","Train Epoch: 7 [650/1485 (44%)]\tLoss: 0.098993\n","Train Epoch: 7 [660/1485 (44%)]\tLoss: 0.115236\n","Train Epoch: 7 [670/1485 (45%)]\tLoss: 0.000420\n","Train Epoch: 7 [680/1485 (46%)]\tLoss: 0.328272\n","Train Epoch: 7 [690/1485 (46%)]\tLoss: 0.112345\n","Train Epoch: 7 [700/1485 (47%)]\tLoss: 0.144390\n","Train Epoch: 7 [710/1485 (48%)]\tLoss: 1.724196\n","Train Epoch: 7 [720/1485 (48%)]\tLoss: 0.013903\n","Train Epoch: 7 [730/1485 (49%)]\tLoss: 0.132102\n","Train Epoch: 7 [740/1485 (50%)]\tLoss: 0.195832\n","Train Epoch: 7 [750/1485 (51%)]\tLoss: 0.274027\n","Train Epoch: 7 [760/1485 (51%)]\tLoss: 0.130168\n","Train Epoch: 7 [770/1485 (52%)]\tLoss: 0.007274\n","Train Epoch: 7 [780/1485 (53%)]\tLoss: 0.023456\n","Train Epoch: 7 [790/1485 (53%)]\tLoss: 0.568041\n","Train Epoch: 7 [800/1485 (54%)]\tLoss: 0.015884\n","Train Epoch: 7 [810/1485 (55%)]\tLoss: 0.008692\n","Train Epoch: 7 [820/1485 (55%)]\tLoss: 0.840153\n","Train Epoch: 7 [830/1485 (56%)]\tLoss: 0.735348\n","Train Epoch: 7 [840/1485 (57%)]\tLoss: 1.072142\n","Train Epoch: 7 [850/1485 (57%)]\tLoss: 0.527659\n","Train Epoch: 7 [860/1485 (58%)]\tLoss: 0.413712\n","Train Epoch: 7 [870/1485 (59%)]\tLoss: 0.016449\n","Train Epoch: 7 [880/1485 (59%)]\tLoss: 0.018944\n","Train Epoch: 7 [890/1485 (60%)]\tLoss: 0.349079\n","Train Epoch: 7 [900/1485 (61%)]\tLoss: 0.615007\n","Train Epoch: 7 [910/1485 (61%)]\tLoss: 0.306517\n","Train Epoch: 7 [920/1485 (62%)]\tLoss: 0.042286\n","Train Epoch: 7 [930/1485 (63%)]\tLoss: 0.010344\n","Train Epoch: 7 [940/1485 (63%)]\tLoss: 0.057548\n","Train Epoch: 7 [950/1485 (64%)]\tLoss: 0.956867\n","Train Epoch: 7 [960/1485 (65%)]\tLoss: 0.026214\n","Train Epoch: 7 [970/1485 (65%)]\tLoss: 0.001281\n","Train Epoch: 7 [980/1485 (66%)]\tLoss: 0.759890\n","Train Epoch: 7 [990/1485 (67%)]\tLoss: 1.745074\n","Train Epoch: 7 [1000/1485 (67%)]\tLoss: 0.029773\n","Train Epoch: 7 [1010/1485 (68%)]\tLoss: 0.468628\n","Train Epoch: 7 [1020/1485 (69%)]\tLoss: 0.686697\n","Train Epoch: 7 [1030/1485 (69%)]\tLoss: 0.018416\n","Train Epoch: 7 [1040/1485 (70%)]\tLoss: 0.235673\n","Train Epoch: 7 [1050/1485 (71%)]\tLoss: 0.000915\n","Train Epoch: 7 [1060/1485 (71%)]\tLoss: 0.017023\n","Train Epoch: 7 [1070/1485 (72%)]\tLoss: 0.152748\n","Train Epoch: 7 [1080/1485 (73%)]\tLoss: 0.007063\n","Train Epoch: 7 [1090/1485 (73%)]\tLoss: 0.000268\n","Train Epoch: 7 [1100/1485 (74%)]\tLoss: 0.026235\n","Train Epoch: 7 [1110/1485 (75%)]\tLoss: 0.000782\n","Train Epoch: 7 [1120/1485 (75%)]\tLoss: 0.094350\n","Train Epoch: 7 [1130/1485 (76%)]\tLoss: 0.001779\n","Train Epoch: 7 [1140/1485 (77%)]\tLoss: 0.217773\n","Train Epoch: 7 [1150/1485 (77%)]\tLoss: 0.011656\n","Train Epoch: 7 [1160/1485 (78%)]\tLoss: 0.016083\n","Train Epoch: 7 [1170/1485 (79%)]\tLoss: 0.155832\n","Train Epoch: 7 [1180/1485 (79%)]\tLoss: 0.029306\n","Train Epoch: 7 [1190/1485 (80%)]\tLoss: 0.243513\n","Train Epoch: 7 [1200/1485 (81%)]\tLoss: 0.605898\n","Train Epoch: 7 [1210/1485 (81%)]\tLoss: 0.177969\n","Train Epoch: 7 [1220/1485 (82%)]\tLoss: 0.116539\n","Train Epoch: 7 [1230/1485 (83%)]\tLoss: 0.299945\n","Train Epoch: 7 [1240/1485 (84%)]\tLoss: 0.085682\n","Train Epoch: 7 [1250/1485 (84%)]\tLoss: 0.004946\n","Train Epoch: 7 [1260/1485 (85%)]\tLoss: 1.190145\n","Train Epoch: 7 [1270/1485 (86%)]\tLoss: 0.009679\n","Train Epoch: 7 [1280/1485 (86%)]\tLoss: 0.063826\n","Train Epoch: 7 [1290/1485 (87%)]\tLoss: 0.009970\n","Train Epoch: 7 [1300/1485 (88%)]\tLoss: 0.956221\n","Train Epoch: 7 [1310/1485 (88%)]\tLoss: 0.682462\n","Train Epoch: 7 [1320/1485 (89%)]\tLoss: 0.000691\n","Train Epoch: 7 [1330/1485 (90%)]\tLoss: 0.001097\n","Train Epoch: 7 [1340/1485 (90%)]\tLoss: 0.664070\n","Train Epoch: 7 [1350/1485 (91%)]\tLoss: 0.034452\n","Train Epoch: 7 [1360/1485 (92%)]\tLoss: 0.000293\n","Train Epoch: 7 [1370/1485 (92%)]\tLoss: 0.121698\n","Train Epoch: 7 [1380/1485 (93%)]\tLoss: 0.001787\n","Train Epoch: 7 [1390/1485 (94%)]\tLoss: 0.053756\n","Train Epoch: 7 [1400/1485 (94%)]\tLoss: 0.023412\n","Train Epoch: 7 [1410/1485 (95%)]\tLoss: 0.385953\n","Train Epoch: 7 [1420/1485 (96%)]\tLoss: 0.134371\n","Train Epoch: 7 [1430/1485 (96%)]\tLoss: 0.036706\n","Train Epoch: 7 [1440/1485 (97%)]\tLoss: 0.165912\n","Train Epoch: 7 [1450/1485 (98%)]\tLoss: 0.016949\n","Train Epoch: 7 [1460/1485 (98%)]\tLoss: 0.000324\n","Train Epoch: 7 [1470/1485 (99%)]\tLoss: 0.453497\n","Train Epoch: 7 [1480/1485 (100%)]\tLoss: 0.069862\n","[tensor(135.8353, device='cuda:0'), tensor(144.3386, device='cuda:0'), tensor(65.9725, device='cuda:0'), tensor(69.7719, device='cuda:0'), tensor(41.3994, device='cuda:0'), tensor(46.8058, device='cuda:0'), tensor(57.7030, device='cuda:0')]\n","\n","Train Epoch: 8 [10/1485 (1%)]\tLoss: 0.000669\n","Train Epoch: 8 [20/1485 (1%)]\tLoss: 0.030913\n","Train Epoch: 8 [30/1485 (2%)]\tLoss: 0.270027\n","Train Epoch: 8 [40/1485 (3%)]\tLoss: 0.171396\n","Train Epoch: 8 [50/1485 (3%)]\tLoss: 0.008413\n","Train Epoch: 8 [60/1485 (4%)]\tLoss: 0.025966\n","Train Epoch: 8 [70/1485 (5%)]\tLoss: 0.206261\n","Train Epoch: 8 [80/1485 (5%)]\tLoss: 0.720445\n","Train Epoch: 8 [90/1485 (6%)]\tLoss: 0.017329\n","Train Epoch: 8 [100/1485 (7%)]\tLoss: 0.037382\n","Train Epoch: 8 [110/1485 (7%)]\tLoss: 1.354070\n","Train Epoch: 8 [120/1485 (8%)]\tLoss: 0.236975\n","Train Epoch: 8 [130/1485 (9%)]\tLoss: 0.013185\n","Train Epoch: 8 [140/1485 (9%)]\tLoss: 0.032093\n","Train Epoch: 8 [150/1485 (10%)]\tLoss: 0.777771\n","Train Epoch: 8 [160/1485 (11%)]\tLoss: 0.079504\n","Train Epoch: 8 [170/1485 (11%)]\tLoss: 1.465001\n","Train Epoch: 8 [180/1485 (12%)]\tLoss: 0.021613\n","Train Epoch: 8 [190/1485 (13%)]\tLoss: 0.001099\n","Train Epoch: 8 [200/1485 (13%)]\tLoss: 0.295198\n","Train Epoch: 8 [210/1485 (14%)]\tLoss: 0.076754\n","Train Epoch: 8 [220/1485 (15%)]\tLoss: 0.025105\n","Train Epoch: 8 [230/1485 (15%)]\tLoss: 0.005913\n","Train Epoch: 8 [240/1485 (16%)]\tLoss: 0.000095\n","Train Epoch: 8 [250/1485 (17%)]\tLoss: 1.176567\n","Train Epoch: 8 [260/1485 (18%)]\tLoss: 0.042490\n","Train Epoch: 8 [270/1485 (18%)]\tLoss: 0.002116\n","Train Epoch: 8 [280/1485 (19%)]\tLoss: 0.068366\n","Train Epoch: 8 [290/1485 (20%)]\tLoss: 0.031633\n","Train Epoch: 8 [300/1485 (20%)]\tLoss: 0.802359\n","Train Epoch: 8 [310/1485 (21%)]\tLoss: 0.197529\n","Train Epoch: 8 [320/1485 (22%)]\tLoss: 0.002086\n","Train Epoch: 8 [330/1485 (22%)]\tLoss: 0.640670\n","Train Epoch: 8 [340/1485 (23%)]\tLoss: 0.040920\n","Train Epoch: 8 [350/1485 (24%)]\tLoss: 0.161048\n","Train Epoch: 8 [360/1485 (24%)]\tLoss: 0.003901\n","Train Epoch: 8 [370/1485 (25%)]\tLoss: 0.108809\n","Train Epoch: 8 [380/1485 (26%)]\tLoss: 0.460535\n","Train Epoch: 8 [390/1485 (26%)]\tLoss: 0.006365\n","Train Epoch: 8 [400/1485 (27%)]\tLoss: 0.019860\n","Train Epoch: 8 [410/1485 (28%)]\tLoss: 0.476282\n","Train Epoch: 8 [420/1485 (28%)]\tLoss: 0.010326\n","Train Epoch: 8 [430/1485 (29%)]\tLoss: 0.796849\n","Train Epoch: 8 [440/1485 (30%)]\tLoss: 0.000314\n","Train Epoch: 8 [450/1485 (30%)]\tLoss: 0.313981\n","Train Epoch: 8 [460/1485 (31%)]\tLoss: 0.003907\n","Train Epoch: 8 [470/1485 (32%)]\tLoss: 0.480976\n","Train Epoch: 8 [480/1485 (32%)]\tLoss: 0.108400\n","Train Epoch: 8 [490/1485 (33%)]\tLoss: 0.000000\n","Train Epoch: 8 [500/1485 (34%)]\tLoss: 0.002482\n","Train Epoch: 8 [510/1485 (34%)]\tLoss: 0.150258\n","Train Epoch: 8 [520/1485 (35%)]\tLoss: 0.340605\n","Train Epoch: 8 [530/1485 (36%)]\tLoss: 0.153316\n","Train Epoch: 8 [540/1485 (36%)]\tLoss: 0.226447\n","Train Epoch: 8 [550/1485 (37%)]\tLoss: 1.046231\n","Train Epoch: 8 [560/1485 (38%)]\tLoss: 0.243207\n","Train Epoch: 8 [570/1485 (38%)]\tLoss: 0.000312\n","Train Epoch: 8 [580/1485 (39%)]\tLoss: 0.413581\n","Train Epoch: 8 [590/1485 (40%)]\tLoss: 0.002183\n","Train Epoch: 8 [600/1485 (40%)]\tLoss: 0.638760\n","Train Epoch: 8 [610/1485 (41%)]\tLoss: 1.138485\n","Train Epoch: 8 [620/1485 (42%)]\tLoss: 0.007745\n","Train Epoch: 8 [630/1485 (42%)]\tLoss: 0.003235\n","Train Epoch: 8 [640/1485 (43%)]\tLoss: 0.000641\n","Train Epoch: 8 [650/1485 (44%)]\tLoss: 0.003284\n","Train Epoch: 8 [660/1485 (44%)]\tLoss: 0.278220\n","Train Epoch: 8 [670/1485 (45%)]\tLoss: 0.000017\n","Train Epoch: 8 [680/1485 (46%)]\tLoss: 0.000134\n","Train Epoch: 8 [690/1485 (46%)]\tLoss: 0.161929\n","Train Epoch: 8 [700/1485 (47%)]\tLoss: 0.164450\n","Train Epoch: 8 [710/1485 (48%)]\tLoss: 0.191913\n","Train Epoch: 8 [720/1485 (48%)]\tLoss: 0.257178\n","Train Epoch: 8 [730/1485 (49%)]\tLoss: 0.001582\n","Train Epoch: 8 [740/1485 (50%)]\tLoss: 0.043105\n","Train Epoch: 8 [750/1485 (51%)]\tLoss: 0.000313\n","Train Epoch: 8 [760/1485 (51%)]\tLoss: 0.888200\n","Train Epoch: 8 [770/1485 (52%)]\tLoss: 0.012825\n","Train Epoch: 8 [780/1485 (53%)]\tLoss: 0.142254\n","Train Epoch: 8 [790/1485 (53%)]\tLoss: 0.277587\n","Train Epoch: 8 [800/1485 (54%)]\tLoss: 0.038195\n","Train Epoch: 8 [810/1485 (55%)]\tLoss: 0.169911\n","Train Epoch: 8 [820/1485 (55%)]\tLoss: 0.000298\n","Train Epoch: 8 [830/1485 (56%)]\tLoss: 0.044361\n","Train Epoch: 8 [840/1485 (57%)]\tLoss: 0.713016\n","Train Epoch: 8 [850/1485 (57%)]\tLoss: 0.004495\n","Train Epoch: 8 [860/1485 (58%)]\tLoss: 0.096954\n","Train Epoch: 8 [870/1485 (59%)]\tLoss: 0.114280\n","Train Epoch: 8 [880/1485 (59%)]\tLoss: 0.000592\n","Train Epoch: 8 [890/1485 (60%)]\tLoss: 0.009844\n","Train Epoch: 8 [900/1485 (61%)]\tLoss: 0.150309\n","Train Epoch: 8 [910/1485 (61%)]\tLoss: 0.429359\n","Train Epoch: 8 [920/1485 (62%)]\tLoss: 0.015421\n","Train Epoch: 8 [930/1485 (63%)]\tLoss: 0.151966\n","Train Epoch: 8 [940/1485 (63%)]\tLoss: 0.003013\n","Train Epoch: 8 [950/1485 (64%)]\tLoss: 0.282696\n","Train Epoch: 8 [960/1485 (65%)]\tLoss: 0.157518\n","Train Epoch: 8 [970/1485 (65%)]\tLoss: 0.095782\n","Train Epoch: 8 [980/1485 (66%)]\tLoss: 0.107935\n","Train Epoch: 8 [990/1485 (67%)]\tLoss: 0.007100\n","Train Epoch: 8 [1000/1485 (67%)]\tLoss: 0.002017\n","Train Epoch: 8 [1010/1485 (68%)]\tLoss: 0.000023\n","Train Epoch: 8 [1020/1485 (69%)]\tLoss: 0.002154\n","Train Epoch: 8 [1030/1485 (69%)]\tLoss: 0.006919\n","Train Epoch: 8 [1040/1485 (70%)]\tLoss: 0.034747\n","Train Epoch: 8 [1050/1485 (71%)]\tLoss: 0.150553\n","Train Epoch: 8 [1060/1485 (71%)]\tLoss: 0.004588\n","Train Epoch: 8 [1070/1485 (72%)]\tLoss: 0.000073\n","Train Epoch: 8 [1080/1485 (73%)]\tLoss: 0.047746\n","Train Epoch: 8 [1090/1485 (73%)]\tLoss: 0.047411\n","Train Epoch: 8 [1100/1485 (74%)]\tLoss: 0.697725\n","Train Epoch: 8 [1110/1485 (75%)]\tLoss: 0.952277\n","Train Epoch: 8 [1120/1485 (75%)]\tLoss: 0.007482\n","Train Epoch: 8 [1130/1485 (76%)]\tLoss: 0.023441\n","Train Epoch: 8 [1140/1485 (77%)]\tLoss: 0.000334\n","Train Epoch: 8 [1150/1485 (77%)]\tLoss: 0.199198\n","Train Epoch: 8 [1160/1485 (78%)]\tLoss: 1.156330\n","Train Epoch: 8 [1170/1485 (79%)]\tLoss: 0.005859\n","Train Epoch: 8 [1180/1485 (79%)]\tLoss: 1.534580\n","Train Epoch: 8 [1190/1485 (80%)]\tLoss: 0.110868\n","Train Epoch: 8 [1200/1485 (81%)]\tLoss: 0.155841\n","Train Epoch: 8 [1210/1485 (81%)]\tLoss: 0.081604\n","Train Epoch: 8 [1220/1485 (82%)]\tLoss: 0.163392\n","Train Epoch: 8 [1230/1485 (83%)]\tLoss: 0.063711\n","Train Epoch: 8 [1240/1485 (84%)]\tLoss: 0.033206\n","Train Epoch: 8 [1250/1485 (84%)]\tLoss: 0.051322\n","Train Epoch: 8 [1260/1485 (85%)]\tLoss: 0.214285\n","Train Epoch: 8 [1270/1485 (86%)]\tLoss: 0.029979\n","Train Epoch: 8 [1280/1485 (86%)]\tLoss: 0.193151\n","Train Epoch: 8 [1290/1485 (87%)]\tLoss: 0.016111\n","Train Epoch: 8 [1300/1485 (88%)]\tLoss: 0.698583\n","Train Epoch: 8 [1310/1485 (88%)]\tLoss: 0.439041\n","Train Epoch: 8 [1320/1485 (89%)]\tLoss: 0.486352\n","Train Epoch: 8 [1330/1485 (90%)]\tLoss: 0.295311\n","Train Epoch: 8 [1340/1485 (90%)]\tLoss: 0.002171\n","Train Epoch: 8 [1350/1485 (91%)]\tLoss: 0.138227\n","Train Epoch: 8 [1360/1485 (92%)]\tLoss: 0.439681\n","Train Epoch: 8 [1370/1485 (92%)]\tLoss: 0.241938\n","Train Epoch: 8 [1380/1485 (93%)]\tLoss: 0.000181\n","Train Epoch: 8 [1390/1485 (94%)]\tLoss: 0.000152\n","Train Epoch: 8 [1400/1485 (94%)]\tLoss: 0.000315\n","Train Epoch: 8 [1410/1485 (95%)]\tLoss: 0.255581\n","Train Epoch: 8 [1420/1485 (96%)]\tLoss: 0.565400\n","Train Epoch: 8 [1430/1485 (96%)]\tLoss: 0.790608\n","Train Epoch: 8 [1440/1485 (97%)]\tLoss: 0.000020\n","Train Epoch: 8 [1450/1485 (98%)]\tLoss: 0.150324\n","Train Epoch: 8 [1460/1485 (98%)]\tLoss: 0.051419\n","Train Epoch: 8 [1470/1485 (99%)]\tLoss: 0.012962\n","Train Epoch: 8 [1480/1485 (100%)]\tLoss: 0.004507\n","[tensor(135.8353, device='cuda:0'), tensor(144.3386, device='cuda:0'), tensor(65.9725, device='cuda:0'), tensor(69.7719, device='cuda:0'), tensor(41.3994, device='cuda:0'), tensor(46.8058, device='cuda:0'), tensor(57.7030, device='cuda:0'), tensor(41.1194, device='cuda:0')]\n","\n","Train Epoch: 9 [10/1485 (1%)]\tLoss: 0.759725\n","Train Epoch: 9 [20/1485 (1%)]\tLoss: 0.029507\n","Train Epoch: 9 [30/1485 (2%)]\tLoss: 0.000718\n","Train Epoch: 9 [40/1485 (3%)]\tLoss: 0.115124\n","Train Epoch: 9 [50/1485 (3%)]\tLoss: 0.012337\n","Train Epoch: 9 [60/1485 (4%)]\tLoss: 0.208956\n","Train Epoch: 9 [70/1485 (5%)]\tLoss: 0.102956\n","Train Epoch: 9 [80/1485 (5%)]\tLoss: 0.292421\n","Train Epoch: 9 [90/1485 (6%)]\tLoss: 0.035979\n","Train Epoch: 9 [100/1485 (7%)]\tLoss: 0.005289\n","Train Epoch: 9 [110/1485 (7%)]\tLoss: 0.352693\n","Train Epoch: 9 [120/1485 (8%)]\tLoss: 0.130385\n","Train Epoch: 9 [130/1485 (9%)]\tLoss: 0.848096\n","Train Epoch: 9 [140/1485 (9%)]\tLoss: 0.000792\n","Train Epoch: 9 [150/1485 (10%)]\tLoss: 0.015078\n","Train Epoch: 9 [160/1485 (11%)]\tLoss: 0.610032\n","Train Epoch: 9 [170/1485 (11%)]\tLoss: 0.048852\n","Train Epoch: 9 [180/1485 (12%)]\tLoss: 0.010548\n","Train Epoch: 9 [190/1485 (13%)]\tLoss: 0.057188\n","Train Epoch: 9 [200/1485 (13%)]\tLoss: 0.025752\n","Train Epoch: 9 [210/1485 (14%)]\tLoss: 1.005018\n","Train Epoch: 9 [220/1485 (15%)]\tLoss: 0.054942\n","Train Epoch: 9 [230/1485 (15%)]\tLoss: 0.165542\n","Train Epoch: 9 [240/1485 (16%)]\tLoss: 0.079735\n","Train Epoch: 9 [250/1485 (17%)]\tLoss: 0.426274\n","Train Epoch: 9 [260/1485 (18%)]\tLoss: 0.022812\n","Train Epoch: 9 [270/1485 (18%)]\tLoss: 0.045867\n","Train Epoch: 9 [280/1485 (19%)]\tLoss: 0.321677\n","Train Epoch: 9 [290/1485 (20%)]\tLoss: 0.000141\n","Train Epoch: 9 [300/1485 (20%)]\tLoss: 0.675514\n","Train Epoch: 9 [310/1485 (21%)]\tLoss: 0.137832\n","Train Epoch: 9 [320/1485 (22%)]\tLoss: 0.109911\n","Train Epoch: 9 [330/1485 (22%)]\tLoss: 0.920488\n","Train Epoch: 9 [340/1485 (23%)]\tLoss: 0.335684\n","Train Epoch: 9 [350/1485 (24%)]\tLoss: 0.292188\n","Train Epoch: 9 [360/1485 (24%)]\tLoss: 0.035539\n","Train Epoch: 9 [370/1485 (25%)]\tLoss: 0.900360\n","Train Epoch: 9 [380/1485 (26%)]\tLoss: 0.094984\n","Train Epoch: 9 [390/1485 (26%)]\tLoss: 0.921279\n","Train Epoch: 9 [400/1485 (27%)]\tLoss: 0.022266\n","Train Epoch: 9 [410/1485 (28%)]\tLoss: 1.019009\n","Train Epoch: 9 [420/1485 (28%)]\tLoss: 1.287853\n","Train Epoch: 9 [430/1485 (29%)]\tLoss: 0.108969\n","Train Epoch: 9 [440/1485 (30%)]\tLoss: 0.297240\n","Train Epoch: 9 [450/1485 (30%)]\tLoss: 0.346900\n","Train Epoch: 9 [460/1485 (31%)]\tLoss: 2.609262\n","Train Epoch: 9 [470/1485 (32%)]\tLoss: 0.013133\n","Train Epoch: 9 [480/1485 (32%)]\tLoss: 0.000011\n","Train Epoch: 9 [490/1485 (33%)]\tLoss: 0.004758\n","Train Epoch: 9 [500/1485 (34%)]\tLoss: 0.005963\n","Train Epoch: 9 [510/1485 (34%)]\tLoss: 0.053052\n","Train Epoch: 9 [520/1485 (35%)]\tLoss: 2.421569\n","Train Epoch: 9 [530/1485 (36%)]\tLoss: 0.053023\n","Train Epoch: 9 [540/1485 (36%)]\tLoss: 0.094669\n","Train Epoch: 9 [550/1485 (37%)]\tLoss: 0.000200\n","Train Epoch: 9 [560/1485 (38%)]\tLoss: 0.001369\n","Train Epoch: 9 [570/1485 (38%)]\tLoss: 0.257029\n","Train Epoch: 9 [580/1485 (39%)]\tLoss: 0.913067\n","Train Epoch: 9 [590/1485 (40%)]\tLoss: 0.617309\n","Train Epoch: 9 [600/1485 (40%)]\tLoss: 0.447153\n","Train Epoch: 9 [610/1485 (41%)]\tLoss: 0.007839\n","Train Epoch: 9 [620/1485 (42%)]\tLoss: 0.465513\n","Train Epoch: 9 [630/1485 (42%)]\tLoss: 0.023446\n","Train Epoch: 9 [640/1485 (43%)]\tLoss: 0.000194\n","Train Epoch: 9 [650/1485 (44%)]\tLoss: 0.097883\n","Train Epoch: 9 [660/1485 (44%)]\tLoss: 0.270913\n","Train Epoch: 9 [670/1485 (45%)]\tLoss: 0.072327\n","Train Epoch: 9 [680/1485 (46%)]\tLoss: 0.043570\n","Train Epoch: 9 [690/1485 (46%)]\tLoss: 0.331594\n","Train Epoch: 9 [700/1485 (47%)]\tLoss: 0.244573\n","Train Epoch: 9 [710/1485 (48%)]\tLoss: 0.544527\n","Train Epoch: 9 [720/1485 (48%)]\tLoss: 0.004815\n","Train Epoch: 9 [730/1485 (49%)]\tLoss: 0.064970\n","Train Epoch: 9 [740/1485 (50%)]\tLoss: 0.001486\n","Train Epoch: 9 [750/1485 (51%)]\tLoss: 0.000240\n","Train Epoch: 9 [760/1485 (51%)]\tLoss: 0.048784\n","Train Epoch: 9 [770/1485 (52%)]\tLoss: 0.132954\n","Train Epoch: 9 [780/1485 (53%)]\tLoss: 0.029357\n","Train Epoch: 9 [790/1485 (53%)]\tLoss: 0.692243\n","Train Epoch: 9 [800/1485 (54%)]\tLoss: 1.540041\n","Train Epoch: 9 [810/1485 (55%)]\tLoss: 0.734910\n","Train Epoch: 9 [820/1485 (55%)]\tLoss: 0.183574\n","Train Epoch: 9 [830/1485 (56%)]\tLoss: 0.407677\n","Train Epoch: 9 [840/1485 (57%)]\tLoss: 0.020672\n","Train Epoch: 9 [850/1485 (57%)]\tLoss: 0.154971\n","Train Epoch: 9 [860/1485 (58%)]\tLoss: 0.000804\n","Train Epoch: 9 [870/1485 (59%)]\tLoss: 0.041859\n","Train Epoch: 9 [880/1485 (59%)]\tLoss: 0.000130\n","Train Epoch: 9 [890/1485 (60%)]\tLoss: 0.000120\n","Train Epoch: 9 [900/1485 (61%)]\tLoss: 0.000223\n","Train Epoch: 9 [910/1485 (61%)]\tLoss: 0.012724\n","Train Epoch: 9 [920/1485 (62%)]\tLoss: 0.088232\n","Train Epoch: 9 [930/1485 (63%)]\tLoss: 0.436667\n","Train Epoch: 9 [940/1485 (63%)]\tLoss: 0.000237\n","Train Epoch: 9 [950/1485 (64%)]\tLoss: 0.536547\n","Train Epoch: 9 [960/1485 (65%)]\tLoss: 0.000050\n","Train Epoch: 9 [970/1485 (65%)]\tLoss: 0.003433\n","Train Epoch: 9 [980/1485 (66%)]\tLoss: 0.144510\n","Train Epoch: 9 [990/1485 (67%)]\tLoss: 0.806492\n","Train Epoch: 9 [1000/1485 (67%)]\tLoss: 0.000001\n","Train Epoch: 9 [1010/1485 (68%)]\tLoss: 0.000011\n","Train Epoch: 9 [1020/1485 (69%)]\tLoss: 0.482593\n","Train Epoch: 9 [1030/1485 (69%)]\tLoss: 0.090900\n","Train Epoch: 9 [1040/1485 (70%)]\tLoss: 0.022295\n","Train Epoch: 9 [1050/1485 (71%)]\tLoss: 0.229184\n","Train Epoch: 9 [1060/1485 (71%)]\tLoss: 0.000000\n","Train Epoch: 9 [1070/1485 (72%)]\tLoss: 0.000262\n","Train Epoch: 9 [1080/1485 (73%)]\tLoss: 0.105508\n","Train Epoch: 9 [1090/1485 (73%)]\tLoss: 0.023565\n","Train Epoch: 9 [1100/1485 (74%)]\tLoss: 0.666376\n","Train Epoch: 9 [1110/1485 (75%)]\tLoss: 0.027561\n","Train Epoch: 9 [1120/1485 (75%)]\tLoss: 0.003767\n","Train Epoch: 9 [1130/1485 (76%)]\tLoss: 0.017533\n","Train Epoch: 9 [1140/1485 (77%)]\tLoss: 0.000912\n","Train Epoch: 9 [1150/1485 (77%)]\tLoss: 0.072844\n","Train Epoch: 9 [1160/1485 (78%)]\tLoss: 0.230543\n","Train Epoch: 9 [1170/1485 (79%)]\tLoss: 0.013919\n","Train Epoch: 9 [1180/1485 (79%)]\tLoss: 0.053302\n","Train Epoch: 9 [1190/1485 (80%)]\tLoss: 0.020679\n","Train Epoch: 9 [1200/1485 (81%)]\tLoss: 0.017881\n","Train Epoch: 9 [1210/1485 (81%)]\tLoss: 1.198223\n","Train Epoch: 9 [1220/1485 (82%)]\tLoss: 0.018330\n","Train Epoch: 9 [1230/1485 (83%)]\tLoss: 0.005201\n","Train Epoch: 9 [1240/1485 (84%)]\tLoss: 0.048398\n","Train Epoch: 9 [1250/1485 (84%)]\tLoss: 0.073033\n","Train Epoch: 9 [1260/1485 (85%)]\tLoss: 0.045065\n","Train Epoch: 9 [1270/1485 (86%)]\tLoss: 0.005166\n","Train Epoch: 9 [1280/1485 (86%)]\tLoss: 0.594128\n","Train Epoch: 9 [1290/1485 (87%)]\tLoss: 0.663956\n","Train Epoch: 9 [1300/1485 (88%)]\tLoss: 0.002344\n","Train Epoch: 9 [1310/1485 (88%)]\tLoss: 0.002335\n","Train Epoch: 9 [1320/1485 (89%)]\tLoss: 0.067371\n","Train Epoch: 9 [1330/1485 (90%)]\tLoss: 0.000630\n","Train Epoch: 9 [1340/1485 (90%)]\tLoss: 0.134301\n","Train Epoch: 9 [1350/1485 (91%)]\tLoss: 0.026144\n","Train Epoch: 9 [1360/1485 (92%)]\tLoss: 0.008324\n","Train Epoch: 9 [1370/1485 (92%)]\tLoss: 0.000605\n","Train Epoch: 9 [1380/1485 (93%)]\tLoss: 0.256755\n","Train Epoch: 9 [1390/1485 (94%)]\tLoss: 0.130131\n","Train Epoch: 9 [1400/1485 (94%)]\tLoss: 0.232664\n","Train Epoch: 9 [1410/1485 (95%)]\tLoss: 0.131611\n","Train Epoch: 9 [1420/1485 (96%)]\tLoss: 0.410341\n","Train Epoch: 9 [1430/1485 (96%)]\tLoss: 0.178693\n","Train Epoch: 9 [1440/1485 (97%)]\tLoss: 0.051968\n","Train Epoch: 9 [1450/1485 (98%)]\tLoss: 0.240722\n","Train Epoch: 9 [1460/1485 (98%)]\tLoss: 0.090143\n","Train Epoch: 9 [1470/1485 (99%)]\tLoss: 0.007267\n","Train Epoch: 9 [1480/1485 (100%)]\tLoss: 0.000167\n","[tensor(135.8353, device='cuda:0'), tensor(144.3386, device='cuda:0'), tensor(65.9725, device='cuda:0'), tensor(69.7719, device='cuda:0'), tensor(41.3994, device='cuda:0'), tensor(46.8058, device='cuda:0'), tensor(57.7030, device='cuda:0'), tensor(41.1194, device='cuda:0'), tensor(45.9083, device='cuda:0')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48Tm89ie68aZ","executionInfo":{"status":"ok","timestamp":1621153577830,"user_tz":-60,"elapsed":4933377,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"da05ae04-38e8-4a68-ab45-2be8fec21854"},"source":["evaluate(model, test_dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Acc 0.975\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.9752066115702479"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eA8sosU368aa","executionInfo":{"status":"ok","timestamp":1621153600269,"user_tz":-60,"elapsed":4954235,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"86f0ccfb-b60c-4f20-94d4-3130141d0d69"},"source":["evaluate(model, hard_test_dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Acc 0.728\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.7277836318932209"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXrkJaRDgCCq","executionInfo":{"status":"ok","timestamp":1621153872133,"user_tz":-60,"elapsed":764,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"66873861-1bc3-48d0-8caf-8a4f78f23c6f"},"source":["precisions_difference"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor(135.8353, device='cuda:0'),\n"," tensor(144.3386, device='cuda:0'),\n"," tensor(65.9725, device='cuda:0'),\n"," tensor(69.7719, device='cuda:0'),\n"," tensor(41.3994, device='cuda:0'),\n"," tensor(46.8058, device='cuda:0'),\n"," tensor(57.7030, device='cuda:0'),\n"," tensor(41.1194, device='cuda:0'),\n"," tensor(45.9083, device='cuda:0')]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"0ITNrAgJ68aa"},"source":["precs_roberta_large = optimizer_vadam_last_layer.get_weight_precs()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vyNf-Jnle46X"},"source":["#Save models\n","#f = open(\"variational_training_rerelease_roberta_large_model.pkl\",\"wb\")\n","#pickle.dump(model,f)\n","#f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BNmg56h7e46c"},"source":["#Save precisions\n","#f = open(\"precisions_weights_biases_rerelease_roberta_large.pkl\",\"wb\")\n","#pickle.dump(precs_roberta_large,f)\n","#f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFL4HLzh68ab"},"source":["std_weights = torch.sqrt(1./precs_roberta_large[0][0][0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gE2s7RiJ68ab"},"source":["std_bias = torch.sqrt(1./precs_roberta_large[0][1][0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PzEC1Tqy68ag"},"source":["results_roberta_rerelease = variational_inference_uncertainties_roberta(model, std_weights, std_bias, test_dataloader, mc_samples = 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WK2UPhwp_MSF"},"source":["results_roberta_hard_rerelease = variational_inference_uncertainties_roberta(model, std_weights, std_bias, hard_test_dataloader, mc_samples = 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gLsgM6fJBzZH"},"source":["results_roberta_unmatched = variational_inference_uncertainties_roberta(model, std_weights, std_bias, unmatched_test_dataloader, mc_samples = 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7CLvNHzQgnbD"},"source":["conf, acc, bins, num_in_bins = split_in_bins(results_roberta_rerelease['predictions'], results_roberta_rerelease['confidence'])\n","conf_hard, acc_hard, bins_hard, num_in_bins_hard = split_in_bins(results_roberta_hard_rerelease['predictions'], results_roberta_hard_rerelease['confidence'])\n","conf_unm, acc_unm, bins_unm, num_in_bins_unm = split_in_bins(results_roberta_unmatched['predictions'], results_roberta_unmatched['confidence'])\n","ece_easy = get_ECE(conf, acc, num_in_bins)\n","print(f\"ECE easy test dataset: {ece_easy}\")\n","ece_hard = get_ECE(conf_hard, acc_hard, num_in_bins_hard)\n","print(f\"ECE hard test dataset: {ece_hard}\")\n","ece_unmatched = get_ECE(conf_unm, acc_unm, num_in_bins_unm)\n","plot_reliability_diagram_rerelease(acc, bins, acc_hard, bins_hard, acc_unm, bins_unm, \"variational_rerlease_roberta\")\n","print(f\"ECE unmatched test dataset: {ece_unmatched}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zoxP_iJdIvS_","executionInfo":{"status":"ok","timestamp":1622247941306,"user_tz":-60,"elapsed":312,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"8b40eba7-051c-44c9-f7ec-18113dc8573a"},"source":["np.mean(results_roberta_rerelease['predictions'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9742148760330579"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bSrnaDZ0gyxG","executionInfo":{"status":"ok","timestamp":1622248181361,"user_tz":-60,"elapsed":333,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"61cfada6-8100-492d-d683-a6bc8c6e4827"},"source":["np.mean(results_roberta_hard_rerelease['predictions'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7281348788198103"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ikHeGrD0huzP","executionInfo":{"status":"ok","timestamp":1622248207547,"user_tz":-60,"elapsed":307,"user":{"displayName":"Alvaro Ortega Gonzalez","photoUrl":"","userId":"08434550588964522515"}},"outputId":"58a45eba-08a0-468c-9c99-792130e7a7f3"},"source":["np.mean(results_roberta_unmatched['predictions'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.49968671679197996"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"rbvXRQYXoGpd"},"source":["#Save results\n","#f = open(\"results_variational_roberta_large_test_rerelease_final.pkl\",\"wb\")\n","#pickle.dump(results_roberta_large_test,f)\n","#f.close()\n","\n","#f = open(\"results_variational_roberta_large_hard_test_rerelease_final.pkl\",\"wb\")\n","#pickle.dump(results_roberta_large_hard_test,f)\n","#f.close()"],"execution_count":null,"outputs":[]}]}