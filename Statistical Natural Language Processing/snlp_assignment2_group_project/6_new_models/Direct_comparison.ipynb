{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Direct_comparison.ipynb","provenance":[],"collapsed_sections":["VONXJ5RHrNwN","BTm78N2mqqlN","uHnjZpReqs79","30419KWGsLsp","LUC_j-niszy8","uJWg6WOGu1zw","u8OyXMqxwXTU","YdoENCnRxbzs","zdnflC4tkuQp","RGNEpSYWk7VF","couCkdZBnr7x"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a3b169340b2645f983a027dba5333b9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d0fec89f66c1463c83654ffc485a1f91","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8a3f06ec8aa64ab3958835ded25e2b78","IPY_MODEL_89573aefdef9402e9fb672860314cbaf"]}},"d0fec89f66c1463c83654ffc485a1f91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a3f06ec8aa64ab3958835ded25e2b78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e08b7eea81044793ac611bd1bc866a7d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":482,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":482,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2f825225db3743ccb5e6b172a6bdff2a"}},"89573aefdef9402e9fb672860314cbaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3160d3f5b3694bc194d839798b494ff4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 482/482 [00:00&lt;00:00, 866B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_20e7200940d0477993f898d60b93453d"}},"e08b7eea81044793ac611bd1bc866a7d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2f825225db3743ccb5e6b172a6bdff2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3160d3f5b3694bc194d839798b494ff4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"20e7200940d0477993f898d60b93453d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ed855024cfe4658a8dd31b3a7ce5729":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_33f5e008bb3c4fc89bc9d88bb001c818","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7915ad5def7d44ab87e7588a4721dead","IPY_MODEL_598dfbef51d643f586f0cb2a26ffd183"]}},"33f5e008bb3c4fc89bc9d88bb001c818":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7915ad5def7d44ab87e7588a4721dead":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_800bd70d131a47bb8073f82ea96d85fa","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ebdf892f5b004472a30ab315bca0a0d1"}},"598dfbef51d643f586f0cb2a26ffd183":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_276111a9cc43491e80626cc4effac86f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:02&lt;00:00, 414kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fef06c78554444c8868cf92fba4996f8"}},"800bd70d131a47bb8073f82ea96d85fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ebdf892f5b004472a30ab315bca0a0d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"276111a9cc43491e80626cc4effac86f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fef06c78554444c8868cf92fba4996f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4cb47ea57cea4e169b083580730b4bdb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_72dcd20210854d65aed8821d865074a8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_edb8b8e317274349a39ca706ea29b04e","IPY_MODEL_3889d35259094ea6a6d747d9537fb257"]}},"72dcd20210854d65aed8821d865074a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"edb8b8e317274349a39ca706ea29b04e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c43b223edc444e28af7f2eab7e1d22bf","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30ce1f6e7ae74aa6874fb60d1eec68c3"}},"3889d35259094ea6a6d747d9537fb257":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_84e8a43806a648f2b8397aa0eda84d0f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:01&lt;00:00, 375kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_acf33a4056834b3db975cbf02ce971bb"}},"c43b223edc444e28af7f2eab7e1d22bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"30ce1f6e7ae74aa6874fb60d1eec68c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"84e8a43806a648f2b8397aa0eda84d0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"acf33a4056834b3db975cbf02ce971bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9ca2263d07e4135979261861ea6ffe6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0be061c28a874b4caad09adee5a95cba","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_da09bb008bd8426db678562a2efeda94","IPY_MODEL_e385697aeb9942cc9b370d561f563d2f"]}},"0be061c28a874b4caad09adee5a95cba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da09bb008bd8426db678562a2efeda94":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_481a620d924b47a9ae88266df9d60787","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1de3950a664a45e2bbf4066e4d555c9b"}},"e385697aeb9942cc9b370d561f563d2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b8e05d5cb76e4e8c9c0a1215446d424b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:01&lt;00:00, 931kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bcbc88404aea4900aabc2c46b7213ac9"}},"481a620d924b47a9ae88266df9d60787":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1de3950a664a45e2bbf4066e4d555c9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8e05d5cb76e4e8c9c0a1215446d424b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bcbc88404aea4900aabc2c46b7213ac9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b60da9b7a3e848ccb59962e9a9275de5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_44589c98786749259e5f7d2ec163dd4e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_117af9155cc749c69e0687379faad51c","IPY_MODEL_996b6e59e65e45dbbe6dccbbb077657a"]}},"44589c98786749259e5f7d2ec163dd4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"117af9155cc749c69e0687379faad51c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_094b8892ed424086a7d53456361422d1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1425941629,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1425941629,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7c07d68ca2f146c0af583e43d17a6799"}},"996b6e59e65e45dbbe6dccbbb077657a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4fdab47943cf4dbe965b215ffbb93cc0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.43G/1.43G [00:28&lt;00:00, 50.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d7e934ffc5e14fe78721bb2621bc436b"}},"094b8892ed424086a7d53456361422d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7c07d68ca2f146c0af583e43d17a6799":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4fdab47943cf4dbe965b215ffbb93cc0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d7e934ffc5e14fe78721bb2621bc436b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"VONXJ5RHrNwN"},"source":["# Set up / imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":870,"referenced_widgets":["a3b169340b2645f983a027dba5333b9f","d0fec89f66c1463c83654ffc485a1f91","8a3f06ec8aa64ab3958835ded25e2b78","89573aefdef9402e9fb672860314cbaf","e08b7eea81044793ac611bd1bc866a7d","2f825225db3743ccb5e6b172a6bdff2a","3160d3f5b3694bc194d839798b494ff4","20e7200940d0477993f898d60b93453d","6ed855024cfe4658a8dd31b3a7ce5729","33f5e008bb3c4fc89bc9d88bb001c818","7915ad5def7d44ab87e7588a4721dead","598dfbef51d643f586f0cb2a26ffd183","800bd70d131a47bb8073f82ea96d85fa","ebdf892f5b004472a30ab315bca0a0d1","276111a9cc43491e80626cc4effac86f","fef06c78554444c8868cf92fba4996f8","4cb47ea57cea4e169b083580730b4bdb","72dcd20210854d65aed8821d865074a8","edb8b8e317274349a39ca706ea29b04e","3889d35259094ea6a6d747d9537fb257","c43b223edc444e28af7f2eab7e1d22bf","30ce1f6e7ae74aa6874fb60d1eec68c3","84e8a43806a648f2b8397aa0eda84d0f","acf33a4056834b3db975cbf02ce971bb","b9ca2263d07e4135979261861ea6ffe6","0be061c28a874b4caad09adee5a95cba","da09bb008bd8426db678562a2efeda94","e385697aeb9942cc9b370d561f563d2f","481a620d924b47a9ae88266df9d60787","1de3950a664a45e2bbf4066e4d555c9b","b8e05d5cb76e4e8c9c0a1215446d424b","bcbc88404aea4900aabc2c46b7213ac9"]},"id":"KRnLhNDYq-6B","cellView":"form","executionInfo":{"status":"ok","timestamp":1622508213774,"user_tz":-60,"elapsed":19405,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}},"outputId":"153a146c-ae3b-4799-f795-82e83ac74a5a"},"source":["#@title Setup (imports and downloads)\n","\n","!pip install transformers\n","!pip install gdown\n","\n","import torch\n","import gdown\n","import os\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import pandas as pd\n","from torch.nn import functional as F\n","import torch.nn as nn\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, AdamW\n","\n","from tqdm import tqdm\n","\n","import pickle\n","import matplotlib.pyplot as plt\n","\n","path_original_dataset_model = '6_new_models/DC_original_dataset.pt'\n","path_rerelease_dataset_model = '6_new_models/DC_rerelease_dataset.pt'\n","\n","# Set model\n","model_name = 'roberta-large' #roberta-large, roberta-base, bert-base-uncased\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 13.9MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 48.9MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 46.5MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n","Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3b169340b2645f983a027dba5333b9f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ed855024cfe4658a8dd31b3a7ce5729","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4cb47ea57cea4e169b083580730b4bdb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9ca2263d07e4135979261861ea6ffe6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nH_BZdO9d6J7"},"source":["# Setting\n","\n","**Set path to root directory in the following cell.**"]},{"cell_type":"code","metadata":{"id":"mzNaWDUH_nXZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622508245410,"user_tz":-60,"elapsed":29315,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}},"outputId":"a98ffd4d-124b-4493-de77-d114da625ba7"},"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# change to directory containing relevant files\n","%cd '/content/drive/MyDrive/Uni/NLP_CW2/github/'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1g3JCgH-awK6a0hTXlBoIT3NgyxvgLv_M/NLP_CW2/github\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"cellView":"form","id":"8cxYQKTDGtd1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622508245847,"user_tz":-60,"elapsed":446,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}},"outputId":"46fb0fde-df40-4087-8cf0-19c5ad365cf5"},"source":["#@title Run to check we're in the correct directory\n","\n","try:\n","    f = open(\"check_directory.txt\")\n","    print('Success :)')\n","except IOError:\n","    print(\"Wrong directory, please try again\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Success :)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R_5A7ZE7A_Rq"},"source":["**Select which actions to run in the notebook**"]},{"cell_type":"code","metadata":{"id":"2sD-244qd3rX","executionInfo":{"status":"ok","timestamp":1622508245849,"user_tz":-60,"elapsed":20,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["# Training settings\n","run_training = False # If you want to run training, set to True\n","training_dataset = 'original' # either 'original' or 'rerelease'\n","training_save_path = 'PATH.pt'\n","\n","# Evaluation setting\n","run_evaluation = True\n","evaluation_dataset = 'rerelease'  # either 'original' or 'rerelease'\n","\n","# Uncertainty estimates setting\n","run_uncertainty_estimates = False\n","uncertainty_dataset = 'original' # either 'original' or 'rerelease'"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BTm78N2mqqlN"},"source":["# Data loading"]},{"cell_type":"markdown","metadata":{"id":"uHnjZpReqs79"},"source":["## Data loading functions"]},{"cell_type":"code","metadata":{"id":"U60QlUNmqrwC","executionInfo":{"status":"ok","timestamp":1622508245850,"user_tz":-60,"elapsed":20,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["def load_util_sentences_aspairs(path=\"util_train\"):\n","    df = pd.read_csv(\"{}.csv\".format(path), header=None)\n","    first_sentences = []\n","    second_sentences = []\n","    labels = []\n","    for i in range(df.shape[0]):\n","\n","        swap = np.random.binomial(n=1, p=0.5)\n","\n","        if swap:\n","            second_sentences.append(df.iloc[i, 0])\n","            first_sentences.append(df.iloc[i, 1])\n","            labels.append(1)\n","        else:\n","            first_sentences.append(df.iloc[i, 0])\n","            second_sentences.append(df.iloc[i, 1])\n","            labels.append(0)\n","\n","    first_sentences = [\"[CLS] \" + s for s in first_sentences]\n","    second_sentences = [\"[SEP] \" + s for s in second_sentences]\n","\n","    return first_sentences, second_sentences, labels"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"LgOYtZEUqym8","executionInfo":{"status":"ok","timestamp":1622508245851,"user_tz":-60,"elapsed":19,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["class UTILdata(torch.utils.data.Dataset):\n","    '''\n","    Utilitarianims dataset\n","    '''\n","    def __init__(self, first_sentences, second_sentences, labels, max_length=50):\n","        super(UTILdata, self).__init__()\n","\n","        self.first = tokenizer(first_sentences)['input_ids']\n","        self.second = tokenizer(second_sentences)['input_ids']\n","        self.labels = labels\n","\n","        self.instances = []\n","        \n","        for idx, _ in enumerate(self.first):\n","\n","            if len(self.first[idx]) <= max_length and len(self.second[idx]) <= max_length:\n","\n","                self.instances += [{'sentence_A': self.first[idx],\n","                                    'sentence_B': self.second[idx],\n","                                    'label': self.labels[idx],\n","                                    'original_A': first_sentences[idx][6:],\n","                                    'original_B': second_sentences[idx][6:]}]\n","        \n","\n","    def __getitem__(self, index):\n","        return self.instances[index]\n","\n","    def __len__(self):\n","        return len(self.instances)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"rjGIjw2CrTWZ","executionInfo":{"status":"ok","timestamp":1622508245852,"user_tz":-60,"elapsed":18,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["def collate(batch):\n","    batch_size = len(batch)\n","\n","    max_length = 50\n","\n","    sentences_A, sentences_B = [], []\n","    original_A, original_B = [], []\n","    masks_A, masks_B = [], []\n","\n","    # Pad all instances to match longest\n","    for i, instance in enumerate(batch):\n","\n","        length_A, length_B = len(instance['sentence_A']), len(instance['sentence_B'])\n","\n","        if length_A > max_length or length_B > max_length:  # If either of the sentences exceeds the max, skip\n","            continue\n","        original_A.append(instance['original_A'])\n","        original_B.append(instance['original_B'])\n","\n","        mask_A, mask_B = torch.ones(max_length), torch.ones(max_length)\n","        mask_A[length_A:], mask_B[length_B:] = 0, 0\n","\n","        # Pad and add sentence A\n","        if length_A < max_length:\n","            pad_length = max_length - length_A\n","            padding = torch.zeros((pad_length), dtype=torch.int)\n","            #print(instance['sentence_A'])\n","            a = torch.IntTensor(instance['sentence_A'])\n","            #print(f'\\n {a}')\n","            padded_A = torch.cat((torch.IntTensor(instance['sentence_A']), padding), dim=0)\n","            \n","            sentences_A.append(padded_A)\n","            masks_A.append(mask_A)\n","        else:\n","            sentences_A.append(torch.IntTensor(instance['sentence_A']))\n","            masks_A.append(mask_A)\n","        # Pad and add sentence B\n","        if length_B < max_length:\n","            pad_length = max_length - length_B\n","            padding = torch.zeros((pad_length), dtype=torch.int)\n","            padded_B = torch.cat((torch.IntTensor(instance['sentence_B']), padding), dim=0)\n","            \n","            sentences_B.append(padded_B)\n","            masks_B.append(mask_B)\n","        else:\n","            sentences_B.append(torch.IntTensor(instance['sentence_B']))\n","            masks_B.append(mask_B)\n","\n","    labels = [instance['label'] for instance in batch]\n","    batch_labels = torch.LongTensor(labels)\n","\n","    batch_sentences_A, batch_sentences_B = torch.stack(sentences_A, dim=0), torch.stack(sentences_B, dim=0)\n","\n","    batch_sentences = torch.cat([batch_sentences_A, batch_sentences_B], dim=1)\n","    #print(a[0])\n","    batch_masks_A, batch_masks_B = torch.stack(masks_A, dim=0), torch.stack(masks_B, dim=0)\n","    batch_masks = torch.cat([batch_masks_A, batch_masks_B], dim=1)\n","\n","\n","    batch = {\n","        'sentences': batch_sentences,\n","        'masks': batch_masks,\n","        'label': batch_labels,\n","        'original_A': original_A,\n","        'original_B': original_B\n","    }\n","    \n","\n","    return batch"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"INiY5WeVrrGg"},"source":["## Load data\n","\n","Choose whether to load the original or new dataset"]},{"cell_type":"markdown","metadata":{"id":"30419KWGsLsp"},"source":["### Load original dataset\n","Creates dataloaders.\n","\n","**For training:**\n","- `original_train_loader`\n","- `original_val_loader`\n","\n","**For testing:**\n","- `original_easy_test_loader`\n","- `original_hard_test_loader`"]},{"cell_type":"code","metadata":{"id":"uwc90imyrsW-","executionInfo":{"status":"ok","timestamp":1622508249768,"user_tz":-60,"elapsed":3642,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["#############\n","# Loads the training set, and splits it into training and validation\n","##########\n","path_data_orig_train = '1_original_study_datasets/util_train'\n","first_sent, sec_sent, labels = load_util_sentences_aspairs(path=path_data_orig_train)\n","train_set = UTILdata(first_sent, sec_sent, labels)\n","\n","# Creating data indices for training and validation splits:\n","validation_split = 0.2\n","dataset_size = len(train_set)\n","indices = list(range(dataset_size))\n","split = int(np.floor(validation_split * dataset_size))\n","np.random.seed(0)\n","np.random.shuffle(indices)\n","train_indices, val_indices = indices[split:], indices[:split]\n","\n","# Creating PT data samplers and loaders:\n","train_sampler = SubsetRandomSampler(train_indices)\n","valid_sampler = SubsetRandomSampler(val_indices)\n","\n","\n","# Final training and validation loaders\n","original_train_loader = DataLoader(dataset = train_set,\n","                    batch_size = 20,\n","                    collate_fn=collate,\n","                    sampler = train_sampler)\n","\n","original_val_loader = DataLoader(dataset = train_set,\n","                    batch_size = 20,\n","                    collate_fn=collate,\n","                    sampler = valid_sampler)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"DZh3uRpmsp1F","executionInfo":{"status":"ok","timestamp":1622508252071,"user_tz":-60,"elapsed":2310,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["#############\n","# Loads the easy and hard test sets into dataloaders\n","##########\n","path_data_orig_test_easy = '1_original_study_datasets/util_test'\n","first_sent, sec_sent, labels = load_util_sentences_aspairs(path=path_data_orig_test_easy)\n","test_set = UTILdata(first_sent, sec_sent, labels)\n","\n","original_easy_test_loader = DataLoader(dataset = test_set,\n","                    batch_size = 20,\n","                    shuffle = False,\n","                    collate_fn=collate)\n","\n","path_data_orig_test_hard = '1_original_study_datasets/util_test_hard'\n","first_sent, sec_sent, labels = load_util_sentences_aspairs(path=path_data_orig_test_hard)\n","hard_test_set = UTILdata(first_sent, sec_sent, labels)\n","\n","original_hard_test_loader = DataLoader(dataset = hard_test_set,\n","                    batch_size = 20,\n","                    shuffle = False,\n","                    collate_fn=collate)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LUC_j-niszy8"},"source":["### Load New Datasets\n","Creates dataloaders.\n","\n","**For training:**\n","- `new_train_loader`\n","- `new_val_loader`\n","\n","**For testing:**\n","- `new_easy_test_loader`\n","- `new_hard_test_loader`\n","- `new_unmatched_test_loader`"]},{"cell_type":"code","metadata":{"id":"ur3smfj8s15y","executionInfo":{"status":"ok","timestamp":1622508254551,"user_tz":-60,"elapsed":2483,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["#############\n","# Loads the training set, and splits it into training and validation\n","##########\n","path_data_new_train = '4_reformulated_datasets/util_train_no_test_overlap'\n","first_sent, sec_sent, labels = load_util_sentences_aspairs(path=path_data_new_train)\n","train_set = UTILdata(first_sent, sec_sent, labels)\n","\n","# Creating data indices for training and validation splits:\n","validation_split = 0.2\n","dataset_size = len(train_set)\n","indices = list(range(dataset_size))\n","split = int(np.floor(validation_split * dataset_size))\n","np.random.seed(0)\n","np.random.shuffle(indices)\n","train_indices, val_indices = indices[split:], indices[:split]\n","\n","# Creating PT data samplers and loaders:\n","train_sampler = SubsetRandomSampler(train_indices)\n","valid_sampler = SubsetRandomSampler(val_indices)\n","\n","new_train_loader = DataLoader(dataset = train_set,\n","                    batch_size = 20,\n","                    collate_fn=collate,\n","                    sampler = train_sampler)\n","new_val_loader = DataLoader(dataset = train_set,\n","                    batch_size = 20,\n","                    collate_fn=collate,\n","                    sampler = valid_sampler)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"f52PJNG5tafA","executionInfo":{"status":"ok","timestamp":1622508258749,"user_tz":-60,"elapsed":4209,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["# Re-release test sets\n","\n","# Matched easy\n","path_data_new_test_easy = '4_reformulated_datasets/util_test_easy_matched'\n","first_sent, sec_sent, labels = load_util_sentences_aspairs(path=path_data_new_test_easy)\n","test_easy_matched = UTILdata(first_sent, sec_sent, labels)\n","\n","new_easy_test_loader = DataLoader(dataset = test_easy_matched,\n","                    batch_size = 20,\n","                    shuffle = False,\n","                    collate_fn=collate)\n","\n","# Matched hard\n","path_data_new_test_hard = '4_reformulated_datasets/util_test_hard_matched'\n","first_sent, sec_sent, labels = load_util_sentences_aspairs(path=path_data_new_test_hard)\n","test_hard_matched = UTILdata(first_sent, sec_sent, labels)\n","\n","new_hard_test_loader = DataLoader(dataset = test_hard_matched,\n","                    batch_size = 20,\n","                    shuffle = False,\n","                    collate_fn=collate)\n","# Unmatched\n","path_data_new_test_unmatched = '4_reformulated_datasets/test_combined_unmatched'\n","first_sent, sec_sent, labels = load_util_sentences_aspairs(path=path_data_new_test_unmatched)\n","test_unmatched = UTILdata(first_sent, sec_sent, labels)\n","\n","new_unmatched_test_loader = DataLoader(dataset = test_unmatched,\n","                    batch_size = 20,\n","                    shuffle = False,\n","                    collate_fn=collate)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uJWg6WOGu1zw"},"source":["# Model training"]},{"cell_type":"markdown","metadata":{"id":"u8OyXMqxwXTU"},"source":["## Training/evaluation functions"]},{"cell_type":"code","metadata":{"id":"_CO7Pj2NwdVU","executionInfo":{"status":"ok","timestamp":1622508258751,"user_tz":-60,"elapsed":139,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["def train(model, optimizer, train_dataloader, validation_loader, epochs, save_path):\n","    # Set model to training mode\n","    device = 'cuda'\n","    model.train()\n","    model.to(device)\n","    criterion = torch.nn.BCEWithLogitsLoss()\n","    sig = nn.Sigmoid()\n","\n","    loss_fun = nn.CrossEntropyLoss()\n","    #loss_fun = torch.nn.BCEWithLogitsLoss()\n","\n","    best_loss = 10000\n","\n","    for epoch in range(epochs):\n","\n","        tot_correct = 0\n","        total = 0\n","        tot_loss = 0\n","\n","        with tqdm(train_dataloader, unit=\"batch\") as tepoch:\n","            # Loop over each batch from the training set\n","            for batch in tepoch:\n","\n","                # Unpack the inputs from our dataloader\n","                inputs = batch['sentences']\n","                targets = batch['label']\n","                masks = batch['masks']\n","\n","                #print(\"\\n\")\n","                #print(inputs.shape)\n","\n","                # Send to device\n","                inputs, targets, masks = inputs.to(device), targets.to(device), masks.to(device)\n","\n","                # Zero gradient buffers\n","                optimizer.zero_grad()\n","\n","                ######### ASSUMING 2 OUTPUTS ######## -> cross entropy # Need to set targets to be a LongTensor\n","                # Forward pass\n","                output = model(inputs, attention_mask = masks)\n","                softmax_output = F.softmax(output.logits, dim=1)\n","\n","                #print(len(output.logits.squeeze()))\n","                #print(len(targets))\n","                # Loss\n","                loss = loss_fun(output.logits.squeeze(), targets)\n","                loss.backward()\n","                optimizer.step()\n","\n","                tot_loss += loss.item()\n","\n","                # Calculate accuracy\n","                y = torch.argmax(softmax_output, dim=1) # Prediction (max probability)\n","                correct = (y == targets).sum() # Correct predictions\n","                # print(f'Softmax output: {softmax_output}')\n","                # print(f'y: {y}')\n","                # print(f'Confidence: {torch.gather(softmax_output, 1, y.view(-1,1))}')\n","                \n","\n","                # del loss, output, softmax_output, inputs, targets, masks\n","                # return\n","\n","                tot_correct += correct.item() # Accumulate correct predictions\n","                total += len(targets) # Accumulate number of examples seen\n","\n","                del loss, output, softmax_output, inputs, targets, masks\n","\n","                tepoch.set_postfix(loss=tot_loss/total, accuracy=100*tot_correct/total)\n","\n","        val_loss, val_correct = train_eval(model, validation_loader)\n","\n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'loss': val_loss,\n","                }, save_path)\n","\n","        print(f'\\r \\nValidation loss: {val_loss}, validation accuracy: {val_correct}')\n","\n","    return model"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKvDRZtrwiGt","executionInfo":{"status":"ok","timestamp":1622508258775,"user_tz":-60,"elapsed":156,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["def train_eval(model, test_dataloader):\n","    device = 'cuda'\n","    model.eval()\n","    #model.to(device)\n","    tot_correct = 0\n","    total = 0\n","    tot_loss = 0\n","\n","    loss_fun = nn.CrossEntropyLoss()\n","\n","    for i, batch in enumerate(test_dataloader):\n","        # Unpack the inputs from our dataloader\n","        inputs = batch['sentences']\n","        targets = batch['label']\n","        masks = batch['masks']\n","\n","        # Send to device\n","        inputs, targets, masks = inputs.to(device), targets.to(device), masks.to(device)\n","\n","        # Forward pass\n","        output = model(inputs, attention_mask = masks)\n","        softmax_output = F.softmax(output.logits, dim=1)\n","\n","        # Loss\n","        loss = loss_fun(output.logits.squeeze(), targets)\n","        tot_loss += loss.item()\n","\n","        # Calculate accuracy\n","        y = torch.argmax(softmax_output, dim=1) # Prediction (max probability)\n","        correct = (y == targets).sum() # Correct predictions\n","\n","        tot_correct += correct.item() # Accumulate correct predictions\n","        total += len(targets)\n","\n","        del loss, output, softmax_output, inputs, targets, masks\n","\n","    return tot_loss/total, tot_correct/total"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"v2B-WJJowjAZ","executionInfo":{"status":"ok","timestamp":1622508258782,"user_tz":-60,"elapsed":158,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["def eval(model, test_dataloader):\n","    device = 'cuda'\n","    model.eval()\n","    model.to(device)\n","    tot_correct = 0\n","    total = 0\n","    tot_loss = 0\n","\n","    input_sentences_A = []\n","    input_sentences_B = []\n","    predictions = []\n","    prediction_results = [] # True = correct, False = incorrect\n","\n","    loss_fun = nn.CrossEntropyLoss()\n","\n","    with tqdm(test_dataloader, unit=\"batch\") as tepoch:\n","        # Loop over each batch from the training set\n","        for batch in tepoch:\n","\n","            # Unpack the inputs from our dataloader\n","            inputs = batch['sentences']\n","            targets = batch['label']\n","            masks = batch['masks']\n","\n","            # For comparison between model results\n","            sentences_A = batch['original_A']\n","            sentences_B = batch['original_B']\n","            input_sentences_A.extend(sentences_A)\n","            input_sentences_B.extend(sentences_B)\n","\n","            # Send to device\n","            inputs, targets, masks = inputs.to(device), targets.to(device), masks.to(device)\n","\n","            # Forward pass\n","            output = model(inputs, attention_mask = masks)\n","            softmax_output = F.softmax(output.logits, dim=1)\n","\n","            # Loss\n","            loss = loss_fun(output.logits.squeeze(), targets)\n","            tot_loss += loss.item()\n","\n","            # Calculate accuracy\n","            y = torch.argmax(softmax_output, dim=1) # Prediction (max probability)\n","            correct = (y == targets).sum() # Correct predictions\n","\n","            # For model comparisons\n","            pred_correct = (y==targets).tolist()\n","            prediction_results.extend(pred_correct)\n","            predictions.extend(y.tolist())\n","\n","            tot_correct += correct.item() # Accumulate correct predictions\n","            total += len(targets)\n","\n","    return tot_loss/total, tot_correct/total, input_sentences_A, input_sentences_B, predictions, prediction_results"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a3xCAYARwZvT"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"8AKooXKdtpvM","executionInfo":{"status":"ok","timestamp":1622508258784,"user_tz":-60,"elapsed":151,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["if training_dataset == 'original':\n","    train_loader = original_train_loader\n","    val_loader = original_val_loader\n","elif training_dataset == 'rerelease':\n","    train_loader = new_train_loader\n","    val_loader = new_val_loader    \n","\n","if run_training:    \n","    # Create new model to train\n","    config = AutoConfig.from_pretrained(model_name, num_labels=2)\n","    model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    no_decay = ['bias', 'LayerNorm.weight']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","\n","    # Select optimizer\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"2eelvlDevVJM","executionInfo":{"status":"ok","timestamp":1622508258789,"user_tz":-60,"elapsed":133,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["if run_training:\n","    # Trains model, and saves the best weights to PATH (according to validation accuracy)\n","    model = train(model, optimizer, train_loader, val_loader, epochs=4, save_path=training_save_path)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4INLeQOUJHXr","executionInfo":{"status":"ok","timestamp":1622508258790,"user_tz":-60,"elapsed":130,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}},"outputId":"a8881926-bc18-4e81-a813-e464587e167c"},"source":["a = torch.Tensor([[1,2], [3,2], [-2, 3], [7, 4], [4, 5]])\n","b = torch.tensor([0, 0, 1, 0, 1], dtype=torch.long)\n","print(a)\n","print(b)\n","print(torch.gather(a, 1, b.view(-1,1)))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["tensor([[ 1.,  2.],\n","        [ 3.,  2.],\n","        [-2.,  3.],\n","        [ 7.,  4.],\n","        [ 4.,  5.]])\n","tensor([0, 0, 1, 0, 1])\n","tensor([[1.],\n","        [3.],\n","        [3.],\n","        [7.],\n","        [5.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YdoENCnRxbzs"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"zdnflC4tkuQp"},"source":["## Evaluation function"]},{"cell_type":"code","metadata":{"id":"7QjYhhkVkthY","executionInfo":{"status":"ok","timestamp":1622508258792,"user_tz":-60,"elapsed":115,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["def eval(model, test_dataloader):\n","    device = 'cuda'\n","    model.eval()\n","    model.to(device)\n","    tot_correct = 0\n","    total = 0\n","    tot_loss = 0\n","\n","    input_sentences_A = []\n","    input_sentences_B = []\n","    predictions = []\n","    prediction_results = [] # True = correct, False = incorrect\n","    prediction_confidence = []\n","\n","    loss_fun = nn.CrossEntropyLoss()\n","\n","    with tqdm(test_dataloader, unit=\"batch\") as tepoch:\n","        # Loop over each batch from the training set\n","        for batch in tepoch:\n","\n","            # Unpack the inputs from our dataloader\n","            inputs = batch['sentences']\n","            targets = batch['label']\n","            masks = batch['masks']\n","\n","            # For comparison between model results\n","            sentences_A = batch['original_A']\n","            sentences_B = batch['original_B']\n","            input_sentences_A.extend(sentences_A)\n","            input_sentences_B.extend(sentences_B)\n","\n","            # Send to device\n","            inputs, targets, masks = inputs.to(device), targets.to(device), masks.to(device)\n","\n","            # Forward pass\n","            output = model(inputs, attention_mask = masks)\n","            softmax_output = F.softmax(output.logits, dim=1)\n","\n","            # Loss\n","            loss = loss_fun(output.logits.squeeze(), targets)\n","            tot_loss += loss.item()\n","\n","            # Calculate accuracy\n","            y = torch.argmax(softmax_output, dim=1) # Prediction (max probability)\n","            correct = (y == targets).sum() # Correct predictions\n","\n","            # print(f'Softmax output: {softmax_output}')\n","            # print(f'y: {y}')\n","            confidence = torch.gather(softmax_output, 1, y.view(-1,1))\n","            confidence = confidence.squeeze()\n","            # print(f'Confidence: {confidence}')\n","            # print(f'Correct pred: {y==targets}')\n","            \n","            # return\n","\n","            # For model comparisons\n","            pred_correct = (y==targets).tolist()\n","            prediction_results.extend(pred_correct)\n","            predictions.extend(y.tolist())\n","            prediction_confidence.extend(confidence.tolist())\n","\n","            tot_correct += correct.item() # Accumulate correct predictions\n","            total += len(targets)\n","        \n","    prediction_confidence = torch.FloatTensor(prediction_confidence)\n","\n","    prediction_confidence = np.array(prediction_confidence)\n","    prediction_results = np.array(prediction_results)\n","\n","    return tot_loss/total, tot_correct/total, input_sentences_A, input_sentences_B, predictions, prediction_results, prediction_confidence"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I2CAywmXxfWk"},"source":["## Load and evaluate trained model"]},{"cell_type":"code","metadata":{"id":"4RxRXb__C-yx","colab":{"base_uri":"https://localhost:8080/","height":170,"referenced_widgets":["b60da9b7a3e848ccb59962e9a9275de5","44589c98786749259e5f7d2ec163dd4e","117af9155cc749c69e0687379faad51c","996b6e59e65e45dbbe6dccbbb077657a","094b8892ed424086a7d53456361422d1","7c07d68ca2f146c0af583e43d17a6799","4fdab47943cf4dbe965b215ffbb93cc0","d7e934ffc5e14fe78721bb2621bc436b"]},"executionInfo":{"status":"ok","timestamp":1622508319104,"user_tz":-60,"elapsed":60417,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}},"outputId":"8fc9b224-6f22-4c44-b91e-c32b325f6db6"},"source":["if run_evaluation:\n","    if evaluation_dataset == 'original':\n","        trained_model = torch.load(path_original_dataset_model)\n","        easy_test_loader = original_easy_test_loader\n","        hard_test_loader = original_hard_test_loader\n","    elif evaluation_dataset == 'rerelease':\n","        trained_model = torch.load(path_rerelease_dataset_model)\n","        easy_test_loader = new_easy_test_loader\n","        hard_test_loader = new_hard_test_loader\n","        # new_unmatched_test_loader also available to evaluate\n","\n","    config = AutoConfig.from_pretrained('roberta-large', num_labels=2)\n","    DC_model = AutoModelForSequenceClassification.from_pretrained('roberta-large', config=config)\n","    DC_model.load_state_dict(trained_model)\n","    del trained_model"],"execution_count":19,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b60da9b7a3e848ccb59962e9a9275de5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425941629.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"09c172UXxe3I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622508337202,"user_tz":-60,"elapsed":18140,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}},"outputId":"f50f6215-4eda-412d-e05a-f702648298dd"},"source":["if run_evaluation:\n","    loss, acc, _, _, _, pred_easy, conf_easy = eval(DC_model, easy_test_loader)\n","    print(\"\\n\")\n","    print('Easy test set results')\n","    print(f'Loss: {loss}')\n","    print(f'Accuracy: {acc}')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["100%|██████████| 151/151 [00:17<00:00,  8.48batch/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Easy test set results\n","Loss: 0.00520090780721264\n","Accuracy: 0.9611037234042553\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bMngWDwiZux","executionInfo":{"status":"ok","timestamp":1622508354069,"user_tz":-60,"elapsed":16887,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}},"outputId":"2a514031-3c4a-4385-955c-a97630f1748b"},"source":["if run_evaluation:\n","    loss, acc, _, _, _, pred_hard, conf_hard  = eval(DC_model, hard_test_loader)\n","    print(\"\\n\")\n","    print('Hard test set results')\n","    print(f'Loss: {loss}')\n","    print(f'Accuracy: {acc}')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["100%|██████████| 142/142 [00:16<00:00,  8.49batch/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Hard test set results\n","Loss: 0.041839520815199455\n","Accuracy: 0.648141592920354\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufL7zp4zjcCI","executionInfo":{"status":"ok","timestamp":1622508372981,"user_tz":-60,"elapsed":18944,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}},"outputId":"3ead577b-c17f-4d9c-dfb3-026c60e60491"},"source":["if run_evaluation and evaluation_dataset == 'rerelease':\n","    loss, acc, _, _, _, pred_unm, conf_unm  = eval(DC_model, new_unmatched_test_loader)\n","    print(\"\\n\")\n","    print('Unmatched test set results')\n","    print(f'Loss: {loss}')\n","    print(f'Accuracy: {acc}')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["100%|██████████| 159/159 [00:18<00:00,  8.46batch/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Unmatched test set results\n","Loss: 0.05313535392265596\n","Accuracy: 0.5531378114159571\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"RGNEpSYWk7VF"},"source":["# Uncertainty estimates (MC)"]},{"cell_type":"code","metadata":{"id":"F1qIfQ_IkIj2","executionInfo":{"status":"ok","timestamp":1622508372983,"user_tz":-60,"elapsed":67,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["if run_uncertainty_estimates:\n","    if uncertainty_dataset == 'original':\n","        trained_model = torch.load(path_original_dataset_model)\n","        easy_test_loader = original_easy_test_loader\n","        hard_test_loader = original_hard_test_loader\n","    elif uncertainty_dataset == 'rerelease':\n","        trained_model = torch.load(path_rerelease_dataset_model)\n","        easy_test_loader = new_easy_test_loader\n","        hard_test_loader = new_hard_test_loader\n","        # new_unmatched_test_loader also available to evaluate\n","\n","    config = AutoConfig.from_pretrained('roberta-large', num_labels=2)\n","    DC_model = AutoModelForSequenceClassification.from_pretrained('roberta-large', config=config)\n","    DC_model.load_state_dict(trained_model)\n","    del trained_model"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"couCkdZBnr7x"},"source":["## Functions"]},{"cell_type":"code","metadata":{"id":"uDAGkRBeodxv","executionInfo":{"status":"ok","timestamp":1622508372983,"user_tz":-60,"elapsed":61,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["def enable_dropout(model):\n","    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n","    for m in model.modules():\n","        if m.__class__.__name__.startswith('Dropout'):\n","            m.train()"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"H1h-iD_vnuzP","executionInfo":{"status":"ok","timestamp":1622508372986,"user_tz":-60,"elapsed":62,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["def MC_dropout(model, dataloader, forward_passes):\n","    '''\n","    Inputs:\n","    - model\n","    - dataloader\n","    - forward_passes: int\n","\n","    Ouputs:\n","    - predictions: numpy.ndarray, (num_samples,)\n","    - confidence: numpy.ndarray, (num_samples,)\n","    - mean, variance: numpy.ndarray\n","    - avg_correct_variance, avg_wrong_variance: numpy.float64\n","    '''\n","\n","    device = 'cuda'\n","    model.eval()\n","    enable_dropout(model)\n","    model.to(device)\n","    tot_correct = 0\n","    total = 0\n","    tot_loss = 0\n","\n","    input_sentences_A = []\n","    input_sentences_B = []\n","    predictions = []\n","    prediction_results = [] # True = correct, False = incorrect\n","\n","    drop_pred = []\n","\n","    loss_fun = nn.CrossEntropyLoss()\n","\n","    with tqdm(dataloader, unit=\"batch\") as tepoch:\n","        # Loop over each batch from the training set\n","        for batch in tepoch:\n","            #print(f'A batch!')\n","\n","            # Unpack the inputs from our dataloader\n","            inputs = batch['sentences']\n","            targets = batch['label']\n","            masks = batch['masks']\n","\n","            # For comparison between model results\n","            sentences_A = batch['original_A']\n","            sentences_B = batch['original_B']\n","            input_sentences_A.extend(sentences_A)\n","            input_sentences_B.extend(sentences_B)\n","\n","            # Send to device\n","            inputs, targets, masks = inputs.to(device), targets.to(device), masks.to(device)\n","\n","            num_samples = len(targets)\n","\n","            # Forward pass\n","            dropout_predictions = np.zeros((forward_passes, num_samples))\n","\n","            for i in range(forward_passes):\n","                #print(f'Pass: {i}')\n","                output = model(inputs, attention_mask = masks)\n","                softmax_output = F.softmax(output.logits, dim=1)\n","\n","                # Calculate accuracy\n","                y = torch.argmax(softmax_output, dim=1) # Prediction (max probability)\n","                #print(f'Predictions: {y}')\n","                #print(f'Target: {targets}')\n","                correct = y == targets # Correct predictions\n","                #print(f'Correct: {correct}')\n","                correct = correct.to('cpu')\n","                #print(f'Correct: {correct}')\n","\n","                dropout_predictions[i,:] = correct\n","\n","                del output, softmax_output, y, correct\n","            drop_pred.append(dropout_predictions)\n","\n","            del inputs, targets, masks\n","    drop_pred = np.concatenate(drop_pred, axis=1)\n","    mean = np.mean(drop_pred, axis=0)\n","    \n","    # Get binary predictions\n","    predictions = np.copy(mean)\n","    predictions[mean>=0.5] = 1\n","    predictions[mean<0.5] = 0\n","\n","\n","    # Calculate the confidence in each prediction  \n","    confidence = np.copy(mean)\n","    confidence[mean<0.5] = 1 - confidence[mean<0.5] # For the instances where we're classifying as 0, the confidence is the opposite\n","\n","    return predictions, confidence"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"8OEPA7A66Ty1","executionInfo":{"status":"ok","timestamp":1622508372989,"user_tz":-60,"elapsed":60,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["def split_in_bins(predictions, confidence):\n","    num_bins = 5\n","    l = np.linspace(0.5,1,num_bins+1)\n","    bins = np.linspace(0.5,.9,num_bins)+.05\n","\n","    conf = []\n","    acc = []\n","    num_in_bins = []\n","\n","    for ind, (lower,upper) in enumerate(zip(l[:-1], l[1:])):\n","        indxs = np.where((confidence<=upper) & (confidence>lower)) # B_m\n","\n","        this_bin_pred = predictions[indxs]\n","        this_bin_conf = confidence[indxs]\n","\n","        #print(this_bin_conf.size)\n","        #print(type(this_bin_conf))\n","        # Get average confidence\n","        if this_bin_conf.size != 0:\n","            avg_conf = np.mean(this_bin_conf)\n","        else:\n","            avg_conf = None\n","\n","        # Get average accuracy\n","        if this_bin_pred.size != 0:\n","            avg_acc = np.mean(this_bin_pred)\n","        else:\n","            avg_acc = None\n","        conf.append(avg_conf)\n","        acc.append(avg_acc)\n","        num_in_bins.append(len(this_bin_pred))\n","    \n","    return conf, acc, bins, num_in_bins"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"7wdqcKl-6WkC","executionInfo":{"status":"ok","timestamp":1622508372990,"user_tz":-60,"elapsed":60,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["def get_ECE(confidence, accuracy, num_in_bins):\n","  '''\n","  condifence: list of conf(B_m)\n","  accuracy: list of acc(B_m)\n","\n","  num_in_bins: number of samples in each bin\n","  '''\n","  assert len(confidence) == len(accuracy)\n","\n","  num_in_bins = np.asarray(num_in_bins)\n","  n = num_in_bins.sum() # Tot number of samples\n","  ECE = 0\n","  for i in range(len(confidence)):\n","    if accuracy[i] and confidence[i]:\n","        ECE += (num_in_bins[i]/(n)) * np.abs(accuracy[i] - confidence[i])\n","\n","  return ECE"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ap5NWlQ36ZXt","executionInfo":{"status":"ok","timestamp":1622508372991,"user_tz":-60,"elapsed":59,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["def plot_reliability_diagram(accuracy, bins):\n","    for i in range(len(accuracy)):\n","        if accuracy[i] == None:\n","            accuracy[i] = 0\n","\n","    width=0.1\n","    fig, ax = plt.subplots(figsize=(5,5))\n","    ax.bar(bins, accuracy, width=width, edgecolor='black', color='black', label=\"Model uncert.\")\n","    ax.plot(np.linspace(0.5,1,6),np.linspace(0.5,1,6),linestyle='--',label='Perfect uncert.', color='red')\n","    ax.set_ylabel(\"Accuracy\")\n","    ax.set_xlabel(\"Model certainty\")\n","    plt.legend(loc='lower left')\n","    plt.savefig(f\"dc_newdataset_unmatched_v2\", dpi=250)\n","    plt.show()"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eWzAlVyKntjn"},"source":["## Running"]},{"cell_type":"markdown","metadata":{"id":"85ZGPXxE-Bko"},"source":["## Original"]},{"cell_type":"code","metadata":{"id":"4yVyknikkRr6","executionInfo":{"status":"ok","timestamp":1622508372992,"user_tz":-60,"elapsed":58,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["# Original easy\n","if run_uncertainty_estimates and uncertainty_dataset == 'original':\n","    pred, conf = MC_dropout(DC_model, easy_test_loader, forward_passes=20)\n","    print(f'\\nMC dropout accuracy: {pred.mean()}')\n","    easy_conf, easy_acc, bins, num_in_bins = split_in_bins(pred,conf)\n","\n","    print(f'ECE: {get_ECE(easy_conf, easy_acc, num_in_bins)}')\n","    plot_reliability_diagram(easy_acc, bins)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"CBoIJWBSnJwc","executionInfo":{"status":"ok","timestamp":1622508372993,"user_tz":-60,"elapsed":58,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["# Original hard\n","if run_uncertainty_estimates and uncertainty_dataset == 'original':\n","    pred, conf = MC_dropout(DC_model, hard_test_loader, forward_passes=20)\n","    print(f'\\nMC dropout accuracy: {pred.mean()}')\n","    hard_conf, hard_acc, bins, num_in_bins = split_in_bins(pred,conf)\n","\n","    print(f'ECE: {get_ECE(hard_conf, hard_acc, num_in_bins)}')\n","    plot_reliability_diagram(hard_acc, bins)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"oj70J7ZYWzhV","executionInfo":{"status":"ok","timestamp":1622508372994,"user_tz":-60,"elapsed":58,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":[""],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qhf52jY50Ird"},"source":["## Rerelease"]},{"cell_type":"code","metadata":{"id":"d2taxcRw0Q3m","executionInfo":{"status":"ok","timestamp":1622508372994,"user_tz":-60,"elapsed":55,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["# Easy matched\n","if run_uncertainty_estimates and uncertainty_dataset == 'rerelease':\n","    pred, conf = MC_dropout(DC_model, easy_test_loader, forward_passes=30)\n","    print(f'\\nMC dropout accuracy: {pred.mean()}')\n","    conf, acc, bins, num_in_bins = split_in_bins(pred,conf)\n","\n","    print(f'ECE: {get_ECE(conf, acc, num_in_bins)}')\n","    plot_reliability_diagram(acc, bins)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3aNU37u0y4L","executionInfo":{"status":"ok","timestamp":1622508372998,"user_tz":-60,"elapsed":58,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["# Hard matched\n","if run_uncertainty_estimates and uncertainty_dataset == 'rerelease':\n","    pred, conf = MC_dropout(DC_model, hard_test_loader, forward_passes=20)\n","    print(f'\\nMC dropout accuracy: {pred.mean()}')\n","    conf, acc, bins, num_in_bins = split_in_bins(pred,conf)\n","\n","    print(f'ECE: {get_ECE(conf, acc, num_in_bins)}')\n","    plot_reliability_diagram(acc, bins)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGt2nMaPXMza","executionInfo":{"status":"ok","timestamp":1622508373000,"user_tz":-60,"elapsed":59,"user":{"displayName":"Chiara Campagnola","photoUrl":"https://lh3.googleusercontent.com/-eOaa25y85rQ/AAAAAAAAAAI/AAAAAAAAAdM/nGbbBm3mduM/s64/photo.jpg","userId":"09192097665912370728"}}},"source":["# Hard matched\n","if run_uncertainty_estimates and uncertainty_dataset == 'rerelease':\n","    pred, conf = MC_dropout(DC_model, new_unmatched_test_loader, forward_passes=20)\n","    print(f'\\nMC dropout accuracy: {pred.mean()}')\n","    conf, acc, bins, num_in_bins = split_in_bins(pred,conf)\n","\n","    print(f'ECE: {get_ECE(conf, acc, num_in_bins)}')\n","    plot_reliability_diagram(acc, bins)"],"execution_count":33,"outputs":[]}]}